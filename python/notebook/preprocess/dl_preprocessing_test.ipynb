{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL 전처리 파이프라인 테스트\n",
    "\n",
    "이 노트북은 `src/DL/preprocessing.py`의 전처리 과정을 단계별로 실행하고 확인합니다.\n",
    "\n",
    "## 전처리 단계\n",
    "1. 데이터 로드\n",
    "2. 시간축 정합 (1분 간격)\n",
    "3. 결측치 처리 (단기: ffill, 중기: EWMA, 장기: EWMA)\n",
    "4. 이상치 처리 (EWMA로 대체)\n",
    "5. 리샘플링 (1시간)\n",
    "6. 특성 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 모듈 임포트 완료\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# 프로젝트 루트 추가\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.DL.preprocessing import (\n",
    "    impute_missing, \n",
    "    handle_outliers, \n",
    "    resample_data,\n",
    "    ImputationConfig, \n",
    "    OutlierConfig\n",
    ")\n",
    "from src.DL.data_loader import load_raw_data, set_datetime_index\n",
    "from src.DL.features import create_features\n",
    "\n",
    "# 한글 폰트 설정\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"✓ 모듈 임포트 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로드된 파일: ['flow', 'tms', 'aws_368', 'aws_541', 'aws_569']\n",
      "  flow: (130732, 6)\n",
      "  tms: (514551, 7)\n",
      "  aws_368: (781875, 10)\n",
      "  aws_541: (830880, 10)\n",
      "  aws_569: (780790, 10)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 디렉토리\n",
    "data_dir = project_root / \"data\" / \"actual\"\n",
    "\n",
    "# 원본 데이터 로드\n",
    "dfs = load_raw_data(data_dir)\n",
    "\n",
    "print(f\"로드된 파일: {list(dfs.keys())}\")\n",
    "for name, df in dfs.items():\n",
    "    print(f\"  {name}: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in dfs.items():\n",
    "    if name == \"flow\" :\n",
    "        dfs[name] = df.drop(columns=[\"data_save_dt\"])\n",
    "    if name.startswith(\"aws_\"):\n",
    "        cols_to_drop = [\"YYMMDDHHMI_368\",\"YYMMDDHHMI_541\",\"YYMMDDHHMI_569\",\"STN_368\",\"STN_541\",\"STN_569\"]\n",
    "        dfs[name] = df.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   flow_TankA  flow_TankB  level_TankA  level_TankB          SYS_TIME\n",
      "0    230.4000    230.2500      3.55225      3.54900  2025-09-02 23:53\n",
      "1    229.9875    230.1000      3.54700      3.54575  2025-09-02 23:54\n",
      "2    229.5000    230.0625      3.54825      3.54475  2025-09-02 23:55\n",
      "3    229.8375    230.4750      3.54125      3.54250  2025-09-02 23:56\n",
      "4    229.9125    230.0250      3.54050      3.54050  2025-09-02 23:57\n",
      "           SYS_TIME  TOC_VU  PH_VU  SS_VU  FLUX_VU   TN_VU  TP_VU\n",
      "0  2024-08-26 15:09     4.1    7.2    0.9   3912.0  11.923  0.039\n",
      "1  2024-08-26 15:10     4.1    7.2    0.8   3917.0  11.923  0.039\n",
      "2  2024-08-26 15:11     4.1    7.1    0.9   3923.0  11.923  0.039\n",
      "3  2024-08-26 15:12     4.1    7.1    0.9   3927.0  11.923  0.039\n",
      "4  2024-08-26 15:13     4.1    7.1    2.2   3932.0  11.923  0.039\n",
      "   TA_368  RN_15m_368  RN_60m_368  RN_12H_368  RN_DAY_368  HM_368  TD_368  \\\n",
      "0    28.3         0.0         0.0         0.0         0.0    72.8    23.0   \n",
      "1    28.3         0.0         0.0         0.0         0.0    72.8    23.0   \n",
      "2    28.2         0.0         0.0         0.0         0.0    72.8    22.9   \n",
      "3    28.2         0.0         0.0         0.0         0.0    72.8    22.9   \n",
      "4    28.3         0.0         0.0         0.0         0.0    72.8    23.0   \n",
      "\n",
      "          datetime  \n",
      "0  2024-08-01 0:00  \n",
      "1  2024-08-01 0:01  \n",
      "2  2024-08-01 0:02  \n",
      "3  2024-08-01 0:03  \n",
      "4  2024-08-01 0:04  \n",
      "   TA_541  RN_15m_541  RN_60m_541  RN_12H_541  RN_DAY_541  HM_541  TD_541  \\\n",
      "0    28.1         0.0         0.0         0.0         0.0    78.1    23.9   \n",
      "1    28.1         0.0         0.0         0.0         0.0    77.9    23.9   \n",
      "2    28.0         0.0         0.0         0.0         0.0    78.4    23.9   \n",
      "3    28.0         0.0         0.0         0.0         0.0    78.6    23.9   \n",
      "4    27.9         0.0         0.0         0.0         0.0    79.2    24.0   \n",
      "\n",
      "          datetime  \n",
      "0  2024-08-01 0:00  \n",
      "1  2024-08-01 0:01  \n",
      "2  2024-08-01 0:02  \n",
      "3  2024-08-01 0:03  \n",
      "4  2024-08-01 0:04  \n",
      "   TA_569  RN_15m_569  RN_60m_569  RN_12H_569  RN_DAY_569  HM_569  TD_569  \\\n",
      "0    27.0         0.0         0.0         0.0         0.0    80.9    23.4   \n",
      "1    27.0         0.0         0.0         0.0         0.0    80.7    23.4   \n",
      "2    27.0         0.0         0.0         0.0         0.0    80.9    23.4   \n",
      "3    27.0         0.0         0.0         0.0         0.0    80.9    23.4   \n",
      "4    27.0         0.0         0.0         0.0         0.0    80.9    23.4   \n",
      "\n",
      "          datetime  \n",
      "0  2024-08-01 0:00  \n",
      "1  2024-08-01 0:01  \n",
      "2  2024-08-01 0:02  \n",
      "3  2024-08-01 0:03  \n",
      "4  2024-08-01 0:04  \n"
     ]
    }
   ],
   "source": [
    "for df in dfs.values():\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 시간축 정합 (1분 간격)\n",
    "\n",
    "각 데이터를 DatetimeIndex로 설정하고 1분 간격으로 정합합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flow: (131687, 4)\n",
      "tms: (573975, 6)\n",
      "aws_368: (781921, 7)\n",
      "aws_541: (830880, 7)\n",
      "aws_569: (780790, 7)\n",
      "\n",
      "✓ 시간축 정합 완료\n"
     ]
    }
   ],
   "source": [
    "# 시간 컬럼 매핑\n",
    "time_col_map = {\n",
    "    \"flow\": \"SYS_TIME\",\n",
    "    \"tms\": \"SYS_TIME\",\n",
    "    \"aws_368\": \"datetime\",\n",
    "    \"aws_541\": \"datetime\",\n",
    "    \"aws_569\": \"datetime\"\n",
    "}\n",
    "\n",
    "# DatetimeIndex 설정\n",
    "aligned_dfs = {}\n",
    "for name, df in dfs.items():\n",
    "    if name in time_col_map:\n",
    "        time_col = time_col_map[name]\n",
    "        df_aligned = set_datetime_index(df, time_col)\n",
    "        \n",
    "        # 1분 간격으로 리샘플링 (시간 정합)\n",
    "        df_aligned = df_aligned.resample(\"1min\").mean()\n",
    "        \n",
    "        aligned_dfs[name] = df_aligned\n",
    "        print(f\"{name}: {df_aligned.shape}\")\n",
    "\n",
    "print(\"\\n✓ 시간축 정합 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Q_in 생성 완료\n"
     ]
    }
   ],
   "source": [
    "# FLOW 데이터에 Q_in 생성\n",
    "if \"flow\" in aligned_dfs:\n",
    "    df_flow = aligned_dfs[\"flow\"]\n",
    "    if \"flow_TankA\" in df_flow.columns and \"flow_TankB\" in df_flow.columns:\n",
    "        df_flow[\"Q_in\"] = df_flow[\"flow_TankA\"] + df_flow[\"flow_TankB\"]\n",
    "        print(\"✓ Q_in 생성 완료\")\n",
    "\n",
    "# 모델별로 데이터 병합\n",
    "merged_dfs = {}\n",
    "\n",
    "# flow 모델: flow + aws 3개\n",
    "merged_dfs[\"flow\"] = pd.concat([\n",
    "    aligned_dfs[\"flow\"], \n",
    "    aligned_dfs[\"aws_368\"], \n",
    "    aligned_dfs[\"aws_541\"], \n",
    "    aligned_dfs[\"aws_569\"]\n",
    "], axis=1, sort=False)\n",
    "\n",
    "# modelA: tms + aws_368\n",
    "merged_dfs[\"modelA\"] = pd.concat([\n",
    "    aligned_dfs[\"tms\"], \n",
    "    aligned_dfs[\"aws_368\"], \n",
    "    aligned_dfs[\"aws_541\"], \n",
    "    aligned_dfs[\"aws_569\"]\n",
    "], axis=1, sort=False)\n",
    "\n",
    "# modelB: tms + aws_541\n",
    "merged_dfs[\"modelB\"] = pd.concat([\n",
    "    aligned_dfs[\"tms\"], \n",
    "    aligned_dfs[\"aws_368\"], \n",
    "    aligned_dfs[\"aws_541\"], \n",
    "    aligned_dfs[\"aws_569\"]\n",
    "], axis=1, sort=False)\n",
    "\n",
    "# modelC: tms + aws_569\n",
    "merged_dfs[\"modelC\"] = pd.concat([\n",
    "    aligned_dfs[\"tms\"], \n",
    "    aligned_dfs[\"aws_368\"], \n",
    "    aligned_dfs[\"aws_541\"], \n",
    "    aligned_dfs[\"aws_569\"]\n",
    "], axis=1, sort=False)\n",
    "\n",
    "print(\"\\n병합된 데이터 shape:\")\n",
    "for model_name, df in merged_dfs.items():\n",
    "    print(f\"  {model_name}: {df.shape}\")\n",
    "    print(f\"    컬럼: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 결측치 처리\n",
    "\n",
    "- 단기 (1-3시간): Forward Fill\n",
    "- 중기 (4-12시간): EWMA (span=6)\n",
    "- 장기 (12시간+): EWMA (span=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 처리 설정\n",
    "config_impute = ImputationConfig(\n",
    "    short_term_hours=3,\n",
    "    medium_term_hours=12,\n",
    "    long_term_hours=48,\n",
    "    ewma_span=6\n",
    ")\n",
    "\n",
    "# 각 모델별로 결측치 처리\n",
    "imputed_dfs = {}\n",
    "mask_imputed_dfs = {}\n",
    "\n",
    "for model_name, df in merged_dfs.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{model_name} 결측치 처리\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"결측치 처리 전:\")\n",
    "    print(f\"  총 결측치: {df.isna().sum().sum()}\")\n",
    "    print(f\"  결측치 있는 컬럼: {(df.isna().sum() > 0).sum()}개\")\n",
    "    \n",
    "    df_imputed, mask_imputed = impute_missing(\n",
    "        df,\n",
    "        freq=\"1min\",\n",
    "        config=config_impute\n",
    "    )\n",
    "    \n",
    "    imputed_dfs[model_name] = df_imputed\n",
    "    mask_imputed_dfs[model_name] = mask_imputed\n",
    "    \n",
    "    print(f\"\\n결측치 처리 후:\")\n",
    "    print(f\"  총 결측치: {df_imputed.isna().sum().sum()}\")\n",
    "    print(f\"  데이터 shape: {df_imputed.shape}\")\n",
    "    print(f\"  마스크 shape: {mask_imputed.shape}\")\n",
    "\n",
    "print(\"\\n✓ 모든 모델 결측치 처리 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측치 처리 요약 (결측치가 있었던 컬럼만):\n",
      "     column  original_missing  ffill  ewma  long_ewma\n",
      " flow_TankA            700148   1135     0     699013\n",
      " flow_TankB            700148   1135     0     699013\n",
      "level_TankA            700148   1135     0     699013\n",
      "level_TankB            700148   1135     0     699013\n",
      "       Q_in            700148   1135     0     699013\n",
      "     TA_368             59899  10387   607      48905\n",
      " RN_15m_368             61641  11128  1608      48905\n",
      " RN_60m_368             61902  11299  1698      48905\n",
      " RN_12H_368             66868  11510  3080      52278\n",
      " RN_DAY_368             61556  11067  1584      48905\n",
      "     HM_368             59899  10387   607      48905\n",
      "     TD_368             59899  10387   607      48905\n",
      "     TA_541             61634   2337   831      58466\n",
      " RN_15m_541             67564   3581  2398      61585\n",
      " RN_60m_541             67953   3628  2533      61792\n",
      " RN_12H_541             74259   4617  1252      68390\n",
      " RN_DAY_541             67290   3425  2362      61503\n",
      "     HM_541             60775   2148   553      58074\n",
      "     TD_541             61634   2337   831      58466\n",
      "     TA_569             50182    272     0      49910\n",
      " RN_15m_569             55723   1728  3109      50886\n",
      " RN_60m_569             56124   1769  1877      52478\n",
      " RN_12H_569             60885   1940     0      58945\n",
      " RN_DAY_569             55607   1708  3037      50862\n",
      "     HM_569             50178    268     0      49910\n",
      "     TD_569             50182    272     0      49910\n"
     ]
    }
   ],
   "source": [
    "# 결측치 처리 요약\n",
    "imputation_summary = []\n",
    "for col in df_merged.columns:\n",
    "    if col in df_imputed.columns:\n",
    "        summary = {\n",
    "            'column': col,\n",
    "            'original_missing': mask_imputed.get(f'{col}_is_missing', pd.Series(0)).sum(),\n",
    "            'ffill': mask_imputed.get(f'{col}_imputed_ffill', pd.Series(0)).sum(),\n",
    "            'ewma': mask_imputed.get(f'{col}_imputed_ewma', pd.Series(0)).sum(),\n",
    "            'long_ewma': mask_imputed.get(f'{col}_imputed_long_ewma', pd.Series(0)).sum()\n",
    "        }\n",
    "        imputation_summary.append(summary)\n",
    "\n",
    "df_imputation_summary = pd.DataFrame(imputation_summary)\n",
    "df_imputation_summary = df_imputation_summary[df_imputation_summary['original_missing'] > 0]\n",
    "\n",
    "print(\"결측치 처리 요약 (결측치가 있었던 컬럼만):\")\n",
    "print(df_imputation_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 이상치 처리\n",
    "\n",
    "- 탐지: 도메인 지식 + 통계적 방법 (IQR)\n",
    "- 대체: EWMA (span=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이상치 처리 후:\n",
      "  데이터 shape: (830880, 27)\n",
      "  마스크 shape: (830880, 83)\n",
      "\n",
      "✓ 이상치 처리 완료\n"
     ]
    }
   ],
   "source": [
    "# 이상치 처리\n",
    "config_outlier = OutlierConfig(\n",
    "    method=\"iqr\",\n",
    "    iqr_threshold=1.5,\n",
    "    zscore_threshold=3.0,\n",
    "    require_both=True\n",
    ")\n",
    "\n",
    "df_outlier_handled, mask_outlier = handle_outliers(\n",
    "    df_imputed,\n",
    "    config=config_outlier,\n",
    "    ewma_span=12\n",
    ")\n",
    "\n",
    "print(f\"이상치 처리 후:\")\n",
    "print(f\"  데이터 shape: {df_outlier_handled.shape}\")\n",
    "print(f\"  마스크 shape: {mask_outlier.shape}\")\n",
    "\n",
    "print(\"\\n✓ 이상치 처리 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상치 처리 요약\n",
    "outlier_summary = []\n",
    "for col in df_imputed.columns:\n",
    "    if f'{col}_outlier_final' in mask_outlier.columns:\n",
    "        summary = {\n",
    "            'column': col,\n",
    "            'domain': mask_outlier.get(f'{col}_outlier_domain', pd.Series(0)).sum(),\n",
    "            'statistical': mask_outlier.get(f'{col}_outlier_statistical', pd.Series(0)).sum(),\n",
    "            'final': mask_outlier[f'{col}_outlier_final'].sum(),\n",
    "            'replaced_ewma': mask_outlier.get(f'{col}_outlier_replaced_ewma', pd.Series(0)).sum()\n",
    "        }\n",
    "        outlier_summary.append(summary)\n",
    "\n",
    "df_outlier_summary = pd.DataFrame(outlier_summary)\n",
    "df_outlier_summary = df_outlier_summary[df_outlier_summary['final'] > 0]\n",
    "\n",
    "print(\"이상치 처리 요약 (이상치가 있었던 컬럼만):\")\n",
    "print(df_outlier_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 리샘플링 (1시간)\n",
    "\n",
    "1분 간격 데이터를 1시간 간격으로 리샘플링합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리샘플링\n",
    "df_resampled = resample_data(\n",
    "    df_outlier_handled,\n",
    "    freq=\"1h\",\n",
    "    agg=\"mean\"\n",
    ")\n",
    "\n",
    "print(f\"리샘플링 후:\")\n",
    "print(f\"  shape: {df_resampled.shape}\")\n",
    "print(f\"  시간 범위: {df_resampled.index.min()} ~ {df_resampled.index.max()}\")\n",
    "print(f\"  총 시간: {(df_resampled.index.max() - df_resampled.index.min()).days}일\")\n",
    "\n",
    "print(\"\\n✓ 리샘플링 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 특성 생성 (Flow 모델)\n",
    "\n",
    "Flow 모델용 특성을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 가능한 컬럼 확인\n",
    "print(\"사용 가능한 컬럼:\")\n",
    "print(f\"  총 {len(df_resampled.columns)}개\")\n",
    "print(f\"  컬럼 목록: {df_resampled.columns.tolist()}\")\n",
    "\n",
    "# TMS 컬럼 확인\n",
    "tms_cols = [\"TOC_VU\", \"PH_VU\", \"SS_VU\", \"FLUX_VU\", \"TN_VU\", \"TP_VU\"]\n",
    "has_tms = [col for col in tms_cols if col in df_resampled.columns]\n",
    "print(f\"\\nTMS 컬럼: {has_tms if has_tms else '없음'}\")\n",
    "\n",
    "# FLOW 컬럼 확인\n",
    "flow_cols = [\"level_TankA\", \"level_TankB\", \"Q_in\"]\n",
    "has_flow = [col for col in flow_cols if col in df_resampled.columns]\n",
    "print(f\"FLOW 컬럼: {has_flow if has_flow else '없음'}\")\n",
    "\n",
    "# 강수 컬럼 확인\n",
    "rain_cols = [f\"RN_15m_{sid}\" for sid in [\"368\", \"541\", \"569\"]]\n",
    "has_rain = [col for col in rain_cols if col in df_resampled.columns]\n",
    "print(f\"강수 컬럼: {has_rain if has_rain else '없음'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 생성 (Flow 모델)\n",
    "model_mode = \"flow\"\n",
    "target_cols = [\"Q_in\"]\n",
    "\n",
    "print(f\"\\n특성 생성 시작: {model_mode} 모드\")\n",
    "print(f\"타겟 컬럼: {target_cols}\")\n",
    "\n",
    "df_features = create_features(\n",
    "    df_resampled,\n",
    "    model_mode=model_mode,\n",
    "    target_cols=target_cols,\n",
    "    add_time=True,\n",
    "    add_sin_cos=True,\n",
    "    lag_hours=[1, 2, 3, 6, 12, 24],\n",
    "    rolling_windows=[3, 6, 12, 24],\n",
    "    rolling_stats=[\"mean\", \"std\"]\n",
    ")\n",
    "\n",
    "print(f\"\\n특성 생성 후:\")\n",
    "print(f\"  shape: {df_features.shape}\")\n",
    "print(f\"  생성된 특성 수: {len(df_features.columns) - len(df_resampled.columns)}개\")\n",
    "\n",
    "print(\"\\n✓ 특성 생성 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN 확인\n",
    "nan_counts = df_features.isna().sum()\n",
    "cols_with_nan = nan_counts[nan_counts > 0]\n",
    "\n",
    "print(f\"\\nNaN 확인:\")\n",
    "print(f\"  NaN이 있는 컬럼: {len(cols_with_nan)}개\")\n",
    "print(f\"  총 NaN 개수: {nan_counts.sum()}\")\n",
    "\n",
    "if len(cols_with_nan) > 0:\n",
    "    print(f\"\\n  상위 10개 컬럼:\")\n",
    "    for col, count in cols_with_nan.head(10).items():\n",
    "        print(f\"    {col}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 시각화\n",
    "\n",
    "전처리 전후 데이터를 시각화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q_in 시각화 (있는 경우)\n",
    "if \"Q_in\" in df_features.columns:\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(15, 10))\n",
    "    \n",
    "    # 원본 (리샘플링 후)\n",
    "    if \"Q_in\" in df_resampled.columns:\n",
    "        axes[0].plot(df_resampled.index, df_resampled[\"Q_in\"], alpha=0.7)\n",
    "        axes[0].set_title(\"Q_in - 리샘플링 후 (1시간)\")\n",
    "        axes[0].set_ylabel(\"Q_in\")\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 특성 생성 후\n",
    "    axes[1].plot(df_features.index, df_features[\"Q_in\"], alpha=0.7, color='orange')\n",
    "    axes[1].set_title(\"Q_in - 특성 생성 후\")\n",
    "    axes[1].set_ylabel(\"Q_in\")\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 분포 비교\n",
    "    if \"Q_in\" in df_resampled.columns:\n",
    "        axes[2].hist(df_resampled[\"Q_in\"].dropna(), bins=50, alpha=0.5, label='리샘플링 후')\n",
    "    axes[2].hist(df_features[\"Q_in\"].dropna(), bins=50, alpha=0.5, label='특성 생성 후', color='orange')\n",
    "    axes[2].set_title(\"Q_in 분포 비교\")\n",
    "    axes[2].set_xlabel(\"Q_in\")\n",
    "    axes[2].set_ylabel(\"빈도\")\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Q_in 컬럼이 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 최종 데이터 저장 (선택사항)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리된 데이터 저장\n",
    "save_path = project_root / \"data\" / \"processed\" / \"flow_preprocessed.csv\"\n",
    "\n",
    "# 저장 여부 확인\n",
    "save_data = False  # True로 변경하면 저장됨\n",
    "\n",
    "if save_data:\n",
    "    df_features.to_csv(save_path)\n",
    "    print(f\"✓ 데이터 저장 완료: {save_path}\")\n",
    "else:\n",
    "    print(\"데이터 저장 안 함 (save_data=False)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 요약\n",
    "\n",
    "전처리 파이프라인이 성공적으로 완료되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"전처리 파이프라인 요약\")\n",
    "print(\"=\"*60)\n",
    "print(f\"1. 데이터 로드: {len(dfs)}개 파일\")\n",
    "print(f\"2. 시간축 정합: {df_merged.shape}\")\n",
    "print(f\"3. 결측치 처리: {df_imputed.shape}\")\n",
    "print(f\"4. 이상치 처리: {df_outlier_handled.shape}\")\n",
    "print(f\"5. 리샘플링: {df_resampled.shape}\")\n",
    "print(f\"6. 특성 생성: {df_features.shape}\")\n",
    "print(f\"\\n최종 특성 수: {len(df_features.columns)}개\")\n",
    "print(f\"최종 샘플 수: {len(df_features)}개\")\n",
    "print(f\"NaN이 있는 컬럼: {len(cols_with_nan)}개\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
