"""
Improved ML Baseline V2 for WWTP Prediction
ì£¼ìš” ê°œì„ ì‚¬í•­:
1. ê²°ì¸¡ì¹˜ ë³´ê°„ (ì„ í˜•, KNN, Forward Fill)
2. ë„ë©”ì¸ í”¼ì²˜ ì¶”ê°€ (ìƒí˜¸ì‘ìš©, ë¹„ìœ¨, ì°¨ë¶„)
3. ì •ê·œí™” ê°•í™” (alpha ì¦ê°€, max_depth ì œí•œ)
"""

import math
import warnings
from dataclasses import dataclass
import numpy as np
import pandas as pd

from sklearn.preprocessing import StandardScaler
from sklearn.multioutput import MultiOutputRegressor
from sklearn.linear_model import Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor
from sklearn.model_selection import GridSearchCV, TimeSeriesSplit
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_percentage_error
import xgboost as xgb

import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # ë°±ê·¸ë¼ìš´ë“œ ëª¨ë“œ (GUI ì—†ìŒ)
import os

warnings.filterwarnings("ignore")

# ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
RESULTS_DIR = "../../../../results/ML/v2"
os.makedirs(RESULTS_DIR, exist_ok=True)

# =========================
# 0) Target config
# =========================
TARGETS_FLOW = ["Q_in"]
TARGETS_TMS = ["TOC_VU", "PH_VU", "SS_VU", "FLUX_VU", "TN_VU", "TP_VU"]
TARGETS_ALL = TARGETS_FLOW + TARGETS_TMS

def get_target_cols(mode):
    mode = mode.lower().strip()
    if mode == "flow":
        return TARGETS_FLOW
    if mode == "tms":
        return TARGETS_TMS
    if mode == "all":
        return TARGETS_ALL
    raise ValueError("mode must be one of: 'flow', 'tms', 'all'")

# =========================
# 1) Time index & merge
# =========================
def set_datetime_index(df, time_col, tz=None):
    out = df.copy()
    out[time_col] = pd.to_datetime(out[time_col], errors="coerce")
    out = out.dropna(subset=[time_col]).set_index(time_col).sort_index()
    return out

def merge_sources_on_time(dfs, how="outer"):
    items = [df.copy() for df in dfs.values() if df is not None and len(df) > 0]
    if not items:
        raise ValueError("No non-empty dataframes to merge.")
    # ì „ì²˜ë¦¬ëœ ë°ì´í„°ëŠ” ì´ë¯¸ ë³‘í•©ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì²« ë²ˆì§¸ ë°ì´í„°í”„ë ˆì„ë§Œ ë°˜í™˜
    if len(items) == 1:
        return items[0].sort_index()
    out = items[0]
    for nxt in items[1:]:
        out = out.join(nxt, how=how)
    out = out.sort_index()
    return out
# =========================
# 2) ë¦¬ìƒ˜í”Œë§
# =========================
def resample_hourly(df, rule="1h", agg="mean"):
    if not isinstance(df.index, pd.DatetimeIndex):
        raise ValueError("df must have a DatetimeIndex for resampling.")
    out = df.copy()
    if isinstance(agg, str):
        return out.resample(rule).agg(agg)
    return out.resample(rule).agg(agg)

# =========================
# 3) ë„ë©”ì¸ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (ê°œì„ !)
# =========================
def add_time_features(df, add_sin_cos=True):
    out = df.copy()
    idx = out.index
    if not isinstance(idx, pd.DatetimeIndex):
        raise ValueError("df must have a DatetimeIndex for time features.")
    
    out["hour"] = idx.hour
    out["dayofweek"] = idx.dayofweek
    out["month"] = idx.month
    out["is_weekend"] = (idx.dayofweek >= 5).astype(int)
    out["is_night"] = ((idx.hour >= 22) | (idx.hour <= 6)).astype(int)
    
    # Season
    m = out["month"]
    season_map = {12:0, 1:0, 2:0, 3:1, 4:1, 5:1, 6:2, 7:2, 8:2, 9:3, 10:3, 11:3}
    out["season"] = m.map(season_map).astype(int)
    
    if add_sin_cos:
        out["sin_hour"] = np.sin(2 * np.pi * out["hour"] / 24.0)
        out["cos_hour"] = np.cos(2 * np.pi * out["hour"] / 24.0)
        out["sin_dow"] = np.sin(2 * np.pi * out["dayofweek"] / 7.0)
        out["cos_dow"] = np.cos(2 * np.pi * out["dayofweek"] / 7.0)
        out["sin_month"] = np.sin(2 * np.pi * out["month"] / 12.0)
        out["cos_month"] = np.cos(2 * np.pi * out["month"] / 12.0)
    
    return out

def add_domain_features(df, target_cols):
    """ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ í”¼ì²˜ ì¶”ê°€"""
    out = df.copy()
    print("\në„ë©”ì¸ í”¼ì²˜ ìƒì„± ì¤‘...")
    
    # 1. ê°•ìˆ˜ëŸ‰ ê´€ë ¨ í”¼ì²˜
    if 'RN_60m' in out.columns and 'RN_DAY' in out.columns:
        out['rain_intensity'] = out['RN_60m'] / (out['RN_DAY'] + 1)  # ê°•ìˆ˜ ê°•ë„
        out['is_raining'] = (out['RN_60m'] > 0).astype(int)
        print("  âœ“ ê°•ìˆ˜ëŸ‰ í”¼ì²˜ ì¶”ê°€")
    
    # 2. ì˜¨ë„-ìŠµë„ ê´€ë ¨ í”¼ì²˜
    if 'TA' in out.columns and 'HM' in out.columns:
        out['temp_humidity_idx'] = out['TA'] * out['HM'] / 100  # ë¶ˆì¾Œì§€ìˆ˜ ê·¼ì‚¬
        out['temp_range'] = out['TA'].rolling(24, min_periods=1).max() - out['TA'].rolling(24, min_periods=1).min()
        print("  âœ“ ì˜¨ë„-ìŠµë„ í”¼ì²˜ ì¶”ê°€")
    
    # 3. íƒ±í¬ ìˆ˜ìœ„ ê´€ë ¨ í”¼ì²˜
    if 'level_TankA' in out.columns and 'level_TankB' in out.columns:
        out['tank_total_level'] = out['level_TankA'] + out['level_TankB']
        out['tank_level_diff'] = abs(out['level_TankA'] - out['level_TankB'])
        out['tank_level_ratio'] = out['level_TankA'] / (out['level_TankB'] + 0.01)
        print("  âœ“ íƒ±í¬ ìˆ˜ìœ„ í”¼ì²˜ ì¶”ê°€")
    
    # 4. ìˆ˜ì§ˆ ë³€ìˆ˜ ê°„ ìƒí˜¸ì‘ìš© (TMS ì˜ˆì¸¡ ì‹œ)
    if 'TOC_VU' in out.columns and 'TN_VU' in out.columns:
        out['TOC_TN_ratio'] = out['TOC_VU'] / (out['TN_VU'] + 0.01)
        print("  âœ“ TOC/TN ë¹„ìœ¨ ì¶”ê°€")
    
    if 'SS_VU' in out.columns and 'TP_VU' in out.columns:
        out['SS_TP_ratio'] = out['SS_VU'] / (out['TP_VU'] + 0.01)
        print("  âœ“ SS/TP ë¹„ìœ¨ ì¶”ê°€")
    
    # 5. ì°¨ë¶„ í”¼ì²˜ (ë³€í™”ìœ¨)
    for col in ['TA', 'HM', 'level_TankA', 'level_TankB']:
        if col in out.columns:
            out[f'{col}_diff1'] = out[col].diff(1)  # 1ì‹œê°„ ë³€í™”
            out[f'{col}_diff24'] = out[col].diff(24)  # 24ì‹œê°„ ë³€í™”
    
    print(f"  ì´ {len(out.columns) - len(df.columns)}ê°œ ë„ë©”ì¸ í”¼ì²˜ ì¶”ê°€ë¨")
    
    return out

def add_lag_features(df, base_cols, lags):
    out = df.copy()
    for c in base_cols:
        if c not in out.columns:
            continue
        for k in lags:
            out[f"{c}_lag{k}"] = out[c].shift(k)
    return out

def add_rolling_features(df, base_cols, windows, stats=["mean"]):
    out = df.copy()
    for c in base_cols:
        if c not in out.columns:
            continue
        for w in windows:
            r = out[c].rolling(window=w, min_periods=max(1, w//2))  # min_periods ì™„í™”
            if "mean" in stats:
                out[f"{c}_r{w}_mean"] = r.mean()
            if "std" in stats:
                out[f"{c}_r{w}_std"] = r.std()
    return out

@dataclass
class FeatureConfig:
    add_time = True
    add_sin_cos = True
    add_domain = True  # ë„ë©”ì¸ í”¼ì²˜ ì¶”ê°€
    lag_hours = None
    roll_hours = None
    
    def __post_init__(self):
        if self.lag_hours is None:
            self.lag_hours = [1, 3, 6, 12]  # 24 ì œê±° (ê³¼ì í•© ë°©ì§€)
        if self.roll_hours is None:
            self.roll_hours = [3, 6, 12]  # ë” ì§§ì€ ìœˆë„ìš°

def build_features(df_hourly, target_cols, feature_base_cols=None, cfg=FeatureConfig()):
    out = df_hourly.copy()
    
    if cfg.add_time:
        out = add_time_features(out, add_sin_cos=cfg.add_sin_cos)
    
    if cfg.add_domain:
        out = add_domain_features(out, target_cols)
    
    if feature_base_cols is None:
        numeric_cols = out.select_dtypes(include=[np.number]).columns.tolist()
        feature_base_cols = [c for c in numeric_cols if c not in target_cols]
    
    out = add_lag_features(out, base_cols=feature_base_cols, lags=cfg.lag_hours)
    out = add_rolling_features(out, base_cols=feature_base_cols, windows=cfg.roll_hours)
    return out

def make_supervised_dataset(df, target_cols):
    """ê²°ì¸¡ì¹˜ ì œê±° (ë³´ê°„ í›„ì´ë¯€ë¡œ ìµœì†Œí™”ë¨)"""
    missing = [c for c in target_cols if c not in df.columns]
    if missing:
        raise ValueError(f"target_cols not found in df: {missing}")
    
    y = df[target_cols].copy()
    X = df.drop(columns=target_cols).copy()
    X = X.select_dtypes(include=[np.number])
    
    # ê²°ì¸¡ì¹˜ ì œê±°
    keep = X.notna().all(axis=1) & y.notna().all(axis=1)
    X_clean = X.loc[keep]
    y_clean = y.loc[keep]
    
    print(f"\nìµœì¢… ë°ì´í„°ì…‹: {len(X)} â†’ {len(X_clean)} ({len(X_clean)/len(X)*100:.1f}%)")
    
    return X_clean, y_clean

# =========================
# 4) Split (time-based)
# =========================
@dataclass
class SplitConfig:
    train_ratio = 0.6
    valid_ratio = 0.2
    test_ratio = 0.2

def time_split(X, y, cfg=SplitConfig()):
    n = len(X)
    if n == 0:
        raise ValueError("Empty dataset after preprocessing/feature generation.")
    
    n_train = int(n * cfg.train_ratio)
    n_valid = int(n * cfg.valid_ratio)
    
    X_train, y_train = X.iloc[:n_train], y.iloc[:n_train]
    X_valid, y_valid = X.iloc[n_train:n_train+n_valid], y.iloc[n_train:n_train+n_valid]
    X_test, y_test = X.iloc[n_train+n_valid:], y.iloc[n_train+n_valid:]
    
    return {
        "train": (X_train, y_train),
        "valid": (X_valid, y_valid),
        "test": (X_test, y_test),
    }

# =========================
# 5) Feature Selection
# =========================
def select_top_features(X_train, y_train, n_features=30):
    """RandomForestë¡œ í”¼ì²˜ ì¤‘ìš”ë„ ê³„ì‚° í›„ ìƒìœ„ nê°œ ì„ íƒ (V2: ë” ì ì€ í”¼ì²˜)"""
    print(f"\ní”¼ì²˜ ì„ íƒ ì¤‘... (ì´ {X_train.shape[1]}ê°œ â†’ ìƒìœ„ {n_features}ê°œ)")
    
    # ë‹¨ì¼ íƒ€ê²Ÿì¸ ê²½ìš°
    if len(y_train.shape) == 1 or y_train.shape[1] == 1:
        rf = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)
        rf.fit(X_train, y_train.values.ravel() if hasattr(y_train, 'values') else y_train)
        importances = rf.feature_importances_
    else:
        # ë‹¤ì¤‘ íƒ€ê²Ÿì¸ ê²½ìš° í‰ê·  ì¤‘ìš”ë„ ì‚¬ìš©
        rf = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1))
        rf.fit(X_train, y_train)
        importances = np.mean([est.feature_importances_ for est in rf.estimators_], axis=0)
    
    # ìƒìœ„ nê°œ í”¼ì²˜ ì„ íƒ
    top_indices = np.argsort(importances)[-n_features:]
    top_features = X_train.columns[top_indices].tolist()
    
    print(f"ì„ íƒëœ ìƒìœ„ 10ê°œ í”¼ì²˜: {top_features[-10:]}")
    
    return top_features

# =========================
# 6) Models with GridSearch (V2: ê°•í™”ëœ ì •ê·œí™”)
# =========================
def build_model_zoo_with_gridsearch(n_targets=1, cv=3):
    """GridSearchCVë¥¼ í¬í•¨í•œ ëª¨ë¸ ì •ì˜ (V2: ì •ê·œí™” ê°•í™”)"""
    
    tscv = TimeSeriesSplit(n_splits=cv)
    
    # Ridge (V2: alpha ì¦ê°€)
    ridge_params = {
        'alpha': [100, 1000, 10000]  # V1: [0.1, 1.0, 10.0, 100.0]
    }
    ridge = GridSearchCV(
        Ridge(random_state=42),
        ridge_params,
        cv=tscv,
        scoring='neg_mean_squared_error',
        n_jobs=-1
    )
    
    # Lasso (V2: alpha ì¦ê°€)
    lasso_params = {
        'alpha': [1.0, 10.0, 100.0]  # V1: [0.001, 0.01, 0.1, 1.0]
    }
    lasso = GridSearchCV(
        Lasso(random_state=42, max_iter=5000),
        lasso_params,
        cv=tscv,
        scoring='neg_mean_squared_error',
        n_jobs=-1
    )
    
    # RandomForest (V2: max_depth ì œí•œ, min_samples_leaf ì¶”ê°€)
    rf_params = {
        'n_estimators': [100, 200, 300],
        'max_depth': [5, 10, 15],  # V1: [10, 20, None] - None ì œê±°
        'min_samples_split': [2, 5],
        'min_samples_leaf': [5, 10, 20]  # V2: ì¶”ê°€
    }
    rf = GridSearchCV(
        RandomForestRegressor(random_state=42, n_jobs=-1),
        rf_params,
        cv=tscv,
        scoring='neg_mean_squared_error',
        n_jobs=-1,
        verbose=1
    )

    
    # HistGradientBoosting (V2: ë” ê°•í•œ ì •ê·œí™”)
    hgb_params = {
        'learning_rate': [0.01, 0.05],  # V1: [0.01, 0.05, 0.1]
        'max_iter': [500],
        'max_depth': [5, 10],  # V1: [5, 10, 20]
        'min_samples_leaf': [20, 30],  # V2: ì¶”ê°€
        'early_stopping': [True],
        'n_iter_no_change': [20],
        'validation_fraction': [0.2]
    }
    hgb = GridSearchCV(
        HistGradientBoostingRegressor(random_state=42),
        hgb_params,
        cv=tscv,
        scoring='neg_mean_squared_error',
        n_jobs=-1,
        verbose=1
    )
    
    # XGBoost (V2: ì •ê·œí™” íŒŒë¼ë¯¸í„° ì¶”ê°€)
    xgb_params = {
        'n_estimators': [100, 200, 300],
        'learning_rate': [0.01, 0.05],  # V1: [0.01, 0.05, 0.1]
        'max_depth': [3, 5],  # V1: [3, 5, 7]
        'subsample': [0.8],  # V1: [0.8, 1.0]
        'min_child_weight': [3, 5, 7],  # V2: ì¶”ê°€
        'gamma': [0, 0.1, 0.2]  # V2: ì¶”ê°€
    }
    xgb_model = GridSearchCV(
        xgb.XGBRegressor(random_state=42, n_jobs=-1),
        xgb_params,
        cv=tscv,
        scoring='neg_mean_squared_error',
        n_jobs=-1,
        verbose=1
    )
    
    zoo = {
        "Ridge": ridge,
        "Lasso": lasso,
        "RandomForest": rf,
        "HistGBR": hgb,
        "XGBoost": xgb_model,
    }
    
    return zoo

# =========================
# 7) Metrics & Evaluation
# =========================
def compute_metrics(y_true, y_pred):
    yt = np.asarray(y_true)
    yp = np.asarray(y_pred)
    if yt.ndim == 1:
        yt = yt.reshape(-1, 1)
    if yp.ndim == 1:
        yp = yp.reshape(-1, 1)
    
    r2s, rmses, mapes = [], [], []
    for j in range(yt.shape[1]):
        r2s.append(r2_score(yt[:, j], yp[:, j]))
        rmses.append(math.sqrt(mean_squared_error(yt[:, j], yp[:, j])))
        mapes.append(mean_absolute_percentage_error(yt[:, j], yp[:, j]) * 100.0)
    
    return {
        "R2_mean": float(np.mean(r2s)),
        "RMSE_mean": float(np.mean(rmses)),
        "MAPE_mean(%)": float(np.mean(mapes)),
        "R2_by_target": r2s,
        "RMSE_by_target": rmses,
        "MAPE_by_target(%)": mapes,
    }

def plot_learning_curve(model, model_name, mode, save_dir=RESULTS_DIR):
    """í•™ìŠµ ê³¡ì„  ì‹œê°í™” (XGBoost, HistGBR)"""
    
    # XGBoost
    if 'XGB' in model_name:
        if isinstance(model, xgb.XGBRegressor):
            estimator = model
        elif isinstance(model, MultiOutputRegressor):
            estimator = model.estimators_[0]
        elif isinstance(model, GridSearchCV):
            estimator = model.best_estimator_
        else:
            return False
        
        if hasattr(estimator, 'evals_result'):
            results = estimator.evals_result()
            if results and 'validation_0' in results:
                train_metric = results['validation_0']['rmse']
                valid_metric = results['validation_1']['rmse'] if 'validation_1' in results else None
                
                plt.figure(figsize=(10, 6))
                plt.plot(train_metric, label='Train RMSE', linewidth=2)
                if valid_metric:
                    plt.plot(valid_metric, label='Valid RMSE', linewidth=2)
                    if hasattr(estimator, 'best_iteration'):
                        plt.axvline(x=estimator.best_iteration, color='r', linestyle='--', 
                                   label=f'Best Iteration ({estimator.best_iteration})', alpha=0.7)

                
                plt.xlabel('Iterations', fontsize=12)
                plt.ylabel('RMSE', fontsize=12)
                plt.title(f'{model_name} Learning Curve - {mode.upper()}', fontsize=14, fontweight='bold')
                plt.legend(fontsize=11)
                plt.grid(True, alpha=0.3)
                plt.tight_layout()
                
                save_path = os.path.join(save_dir, f'{mode}_{model_name}_learning_curve.png')
                plt.savefig(save_path, dpi=150, bbox_inches='tight')
                print(f"  ğŸ“Š Learning curve saved: {save_path}")
                plt.close()
                return True
    
    # HistGradientBoosting
    elif 'HistGBR' in model_name:
        if isinstance(model, MultiOutputRegressor):
            estimator = model.estimators_[0]
        elif isinstance(model, GridSearchCV):
            estimator = model.best_estimator_
        else:
            estimator = model
        
        if hasattr(estimator, 'train_score_'):
            train_scores = estimator.train_score_
            valid_scores = estimator.validation_score_ if hasattr(estimator, 'validation_score_') else None
            
            plt.figure(figsize=(10, 6))
            plt.plot(train_scores, label='Train Score', linewidth=2)
            if valid_scores is not None:
                plt.plot(valid_scores, label='Valid Score', linewidth=2)
            plt.xlabel('Iterations', fontsize=12)
            plt.ylabel('Score', fontsize=12)
            plt.title(f'{model_name} Learning Curve - {mode.upper()}', fontsize=14, fontweight='bold')
            plt.legend(fontsize=11)
            plt.grid(True, alpha=0.3)
            plt.tight_layout()
            
            save_path = os.path.join(save_dir, f'{mode}_{model_name}_learning_curve.png')
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            print(f"  ğŸ“Š Learning curve saved: {save_path}")
            plt.close()
            return True
    
    return False

def plot_r2_comparison(results, mode, save_dir=RESULTS_DIR):
    """ëª¨ë“  ëª¨ë¸ì˜ RÂ² ë¹„êµ ì‹œê°í™”"""
    models = list(results.keys())
    train_r2 = [results[m]['train']['R2_mean'] for m in models]
    valid_r2 = [results[m]['valid']['R2_mean'] for m in models]
    test_r2 = [results[m]['test']['R2_mean'] for m in models]
    
    x = np.arange(len(models))
    width = 0.25
    
    fig, ax = plt.subplots(figsize=(12, 6))
    ax.bar(x - width, train_r2, width, label='Train', alpha=0.8)
    ax.bar(x, valid_r2, width, label='Valid', alpha=0.8)
    ax.bar(x + width, test_r2, width, label='Test', alpha=0.8)
    
    ax.set_xlabel('Models', fontsize=12)
    ax.set_ylabel('RÂ² Score', fontsize=12)
    ax.set_title(f'RÂ² Comparison - {mode.upper()} (V2)', fontsize=14, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels(models, rotation=45, ha='right')
    ax.legend(fontsize=11)
    ax.grid(True, alpha=0.3, axis='y')
    ax.axhline(y=0, color='r', linestyle='--', linewidth=1, alpha=0.5)
    
    plt.tight_layout()
    save_path = os.path.join(save_dir, f'{mode}_r2_comparison.png')
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"\nğŸ“Š RÂ² comparison saved: {save_path}")
    plt.close()

def plot_metric_table(result_by_model, split="test"):
    rows = []
    for model_name, res in result_by_model.items():
        m = res[split]
        rows.append([model_name, m["R2_mean"], m["RMSE_mean"], m["MAPE_mean(%)"]])
    tbl = pd.DataFrame(rows, columns=["model", "R2_mean", "RMSE_mean", "MAPE_mean(%)"])
    return tbl.sort_values(by="R2_mean", ascending=False)

def fit_and_evaluate(model, splits, scaler=None, model_name="", mode="", target_cols=None):
    """StandardScaler ì ìš© ë° í‰ê°€ (ê° íƒ€ê²Ÿë³„ ê°œë³„ í•™ìŠµ)"""
    X_train, y_train = splits["train"]
    X_valid, y_valid = splits["valid"]
    X_test, y_test = splits["test"]
    
    # Scaling
    if scaler is None:
        scaler = StandardScaler()
    
    X_train_scaled = scaler.fit_transform(X_train)
    X_valid_scaled = scaler.transform(X_valid)
    X_test_scaled = scaler.transform(X_test)
    
    # ë‹¤ì¤‘ íƒ€ê²Ÿì¸ ê²½ìš° ê°ê° ê°œë³„ í•™ìŠµ
    n_targets = y_train.shape[1] if len(y_train.shape) > 1 else 1
    
    if n_targets > 1:
        print(f"  Training {n_targets} individual models for each target...")
        fitted_models = {}
        all_results = {"train": [], "valid": [], "test": []}
        
        for i, target_name in enumerate(target_cols):
            print(f"\n  [{i+1}/{n_targets}] Training for {target_name}...")
            
            y_train_single = y_train.iloc[:, i] if hasattr(y_train, 'iloc') else y_train[:, i]
            y_valid_single = y_valid.iloc[:, i] if hasattr(y_valid, 'iloc') else y_valid[:, i]
            y_test_single = y_test.iloc[:, i] if hasattr(y_test, 'iloc') else y_test[:, i]
            
            # ëª¨ë¸ ë³µì‚¬
            if isinstance(model, GridSearchCV):
                single_model = type(model)(
                    estimator=type(model.estimator)(**model.estimator.get_params()),
                    param_grid=model.param_grid,
                    cv=model.cv,
                    scoring=model.scoring,
                    n_jobs=model.n_jobs,
                    verbose=0
                )
            else:
                single_model = type(model)(**model.get_params())
            
            # í•™ìŠµ
            if isinstance(single_model, GridSearchCV):
                single_model.fit(X_train_scaled, y_train_single)
                print(f"    Best params: {single_model.best_params_}")
                
                # XGBoost Early Stopping
                if 'XGB' in model_name:
                    best_params = single_model.best_params_.copy()
                    best_params['n_estimators'] = 500
                    
                    final_model = xgb.XGBRegressor(
                        **best_params,
                        early_stopping_rounds=20,
                        random_state=42,
                        n_jobs=-1
                    )
                    
                    final_model.fit(
                        X_train_scaled, y_train_single,
                        eval_set=[(X_train_scaled, y_train_single), (X_valid_scaled, y_valid_single)],
                        verbose=False
                    )
                    
                    if hasattr(final_model, 'best_iteration'):
                        print(f"    Early stopping at iteration: {final_model.best_iteration}")
                    single_model = final_model

                
                elif 'HistGBR' in model_name:
                    if hasattr(single_model.best_estimator_, 'n_iter_'):
                        print(f"    Iterations: {single_model.best_estimator_.n_iter_}")
            else:
                single_model.fit(X_train_scaled, y_train_single)
            
            fitted_models[target_name] = single_model
            
            # ì˜ˆì¸¡
            pred_train = single_model.predict(X_train_scaled)
            pred_valid = single_model.predict(X_valid_scaled)
            pred_test = single_model.predict(X_test_scaled)
            
            # ë©”íŠ¸ë¦­ ê³„ì‚°
            all_results["train"].append(compute_metrics(y_train_single, pred_train))
            all_results["valid"].append(compute_metrics(y_valid_single, pred_valid))
            all_results["test"].append(compute_metrics(y_test_single, pred_test))
        
        # í‰ê·  ë©”íŠ¸ë¦­ ê³„ì‚°
        out = {}
        for split in ["train", "valid", "test"]:
            out[split] = {
                "R2_mean": float(np.mean([r["R2_mean"] for r in all_results[split]])),
                "RMSE_mean": float(np.mean([r["RMSE_mean"] for r in all_results[split]])),
                "MAPE_mean(%)": float(np.mean([r["MAPE_mean(%)"] for r in all_results[split]])),
                "R2_by_target": [r["R2_mean"] for r in all_results[split]],
                "RMSE_by_target": [r["RMSE_mean"] for r in all_results[split]],
                "MAPE_by_target(%)": [r["MAPE_mean(%)"] for r in all_results[split]],
            }
        
        # Learning curveëŠ” ì²« ë²ˆì§¸ íƒ€ê²Ÿ ëª¨ë¸ë§Œ ì‹œê°í™”
        first_model = fitted_models[target_cols[0]]
        plot_learning_curve(first_model, model_name, mode)
        
        return out, scaler, fitted_models
    
    else:
        # ë‹¨ì¼ íƒ€ê²Ÿ
        print(f"  Training single target model...")
        
        if isinstance(model, GridSearchCV):
            model.fit(X_train_scaled, y_train)
            print(f"  Best params: {model.best_params_}")
            
            # XGBoost Early Stopping
            if 'XGB' in model_name:
                best_params = model.best_params_.copy()
                best_params['n_estimators'] = 500
                
                final_model = xgb.XGBRegressor(
                    **best_params,
                    early_stopping_rounds=20,
                    random_state=42,
                    n_jobs=-1
                )

                
                final_model.fit(
                    X_train_scaled, y_train,
                    eval_set=[(X_train_scaled, y_train), (X_valid_scaled, y_valid)],
                    verbose=False
                )
                
                if hasattr(final_model, 'best_iteration'):
                    print(f"  Early stopping at iteration: {final_model.best_iteration}")
                model = final_model
            
            elif 'HistGBR' in model_name:
                if hasattr(model.best_estimator_, 'n_iter_'):
                    print(f"  Iterations: {model.best_estimator_.n_iter_}")
        else:
            model.fit(X_train_scaled, y_train)
        
        # Evaluation
        out = {}
        pred_train = model.predict(X_train_scaled)
        pred_valid = model.predict(X_valid_scaled)
        pred_test = model.predict(X_test_scaled)
        
        out["train"] = compute_metrics(y_train.to_numpy(), pred_train)
        out["valid"] = compute_metrics(y_valid.to_numpy(), pred_valid)
        out["test"] = compute_metrics(y_test.to_numpy(), pred_test)
        
        # Learning curve ì‹œê°í™”
        plot_learning_curve(model, model_name, mode)
        
        return out, scaler, model

# =========================
# 8) Pipeline Runner
# =========================
def run_improved_pipeline_v2(
    dfs,
    mode,
    time_col_map=None,
    tz=None,
    resample_rule="1h",
    resample_agg="mean",
    feature_cfg=FeatureConfig(),
    split_cfg=SplitConfig(),
    n_top_features=30,  # V2: ë” ì ì€ í”¼ì²˜
    cv_splits=3,
    random_state=42
):
    """ê°œì„ ëœ íŒŒì´í”„ë¼ì¸ V2 (ì „ì²˜ë¦¬ëœ ë°ì´í„° ì‚¬ìš© - ë³´ê°„ ì™„ë£Œ)"""
    
    print(f"\n{'='*60}")
    print(f"Mode: {mode.upper()} (V2)")
    print(f"{'='*60}")
    
    target_cols = get_target_cols(mode)
    
    # 1) ë°ì´í„° ì¸ë±ì‹±
    dfs_indexed = {}
    for name, df in dfs.items():
        if df is None or len(df) == 0:
            dfs_indexed[name] = df
            continue
        
        if isinstance(df.index, pd.DatetimeIndex):
            dfs_indexed[name] = df.sort_index()
        else:
            if time_col_map is None or name not in time_col_map:
                raise ValueError(f"{name} has no DatetimeIndex and no time_col_map provided.")
            dfs_indexed[name] = set_datetime_index(df, time_col=time_col_map[name], tz=tz)
    
    # 2) ë³‘í•© (ì „ì²˜ë¦¬ëœ ë°ì´í„°ëŠ” ì´ë¯¸ ë³‘í•©ë˜ì–´ ìˆìŒ)
    df_all = merge_sources_on_time(dfs_indexed, how="outer")
    
    # 3) ë¦¬ìƒ˜í”Œë§ (ì „ì²˜ë¦¬ëœ ë°ì´í„°ëŠ” ì´ë¯¸ 1ë¶„ ê°„ê²©ì´ë¯€ë¡œ ì‹œê°„ ë‹¨ìœ„ë¡œ ë¦¬ìƒ˜í”Œë§)
    df_hourly = resample_hourly(df_all, rule=resample_rule, agg=resample_agg)
    
    # 4) í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (V2: ë„ë©”ì¸ í”¼ì²˜ í¬í•¨)
    df_feat = build_features(
        df_hourly=df_hourly,
        target_cols=target_cols,
        feature_base_cols=None,
        cfg=feature_cfg
    )
    
    # 5) ì§€ë„í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„± (ì „ì²˜ë¦¬ëœ ë°ì´í„°ì´ë¯€ë¡œ ê²°ì¸¡ì¹˜ ìµœì†Œ)
    X, y = make_supervised_dataset(df_feat, target_cols=target_cols)
    
    # 6) ë¶„í• 
    splits = time_split(X, y, cfg=split_cfg)
    X_train, y_train = splits["train"]
    
    # 7) í”¼ì²˜ ì„ íƒ (V2: ë” ì ì€ í”¼ì²˜)
    top_features = select_top_features(X_train, y_train, n_features=n_top_features)
    X_train_selected = X_train[top_features]
    X_valid_selected = splits["valid"][0][top_features]
    X_test_selected = splits["test"][0][top_features]
    
    splits_selected = {
        "train": (X_train_selected, y_train),
        "valid": (X_valid_selected, splits["valid"][1]),
        "test": (X_test_selected, splits["test"][1])
    }
    
    # 8) ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ (V2: ê°•í™”ëœ ì •ê·œí™”)
    zoo = build_model_zoo_with_gridsearch(n_targets=y_train.shape[1], cv=cv_splits)
    
    results = {}
    fitted_models = {}
    scalers = {}
    
    for model_name, base_model in zoo.items():
        print(f"\n{'='*60}")
        print(f"Training: {model_name}")
        print(f"{'='*60}")
        
        res, scaler, fitted_model = fit_and_evaluate(
            base_model, splits_selected, 
            model_name=model_name, 
            mode=mode,
            target_cols=target_cols
        )
        
        results[model_name] = res
        fitted_models[model_name] = fitted_model
        scalers[model_name] = scaler
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\n  Train - RÂ²: {res['train']['R2_mean']:.4f}, RMSE: {res['train']['RMSE_mean']:.2f}")
        print(f"  Valid - RÂ²: {res['valid']['R2_mean']:.4f}, RMSE: {res['valid']['RMSE_mean']:.2f}")
        print(f"  Test  - RÂ²: {res['test']['R2_mean']:.4f}, RMSE: {res['test']['RMSE_mean']:.2f}")
        
        # íƒ€ê²Ÿë³„ ì„±ëŠ¥ ì¶œë ¥
        if len(target_cols) > 1:
            print(f"\n  Per-target Test RÂ²:")
            for i, target_name in enumerate(target_cols):
                print(f"    {target_name}: {res['test']['R2_by_target'][i]:.4f}")
        
        # Overfitting ì²´í¬
        train_r2 = res['train']['R2_mean']
        valid_r2 = res['valid']['R2_mean']
        if train_r2 - valid_r2 > 0.1:
            print(f"  âš ï¸  ê³¼ì í•© ê°€ëŠ¥ì„±: Train RÂ² ({train_r2:.4f}) >> Valid RÂ² ({valid_r2:.4f})")

    
    metric_table = plot_metric_table(results, split="test")
    
    # RÂ² ë¹„êµ ì‹œê°í™”
    plot_r2_comparison(results, mode)
    
    print(f"\n{'='*60}")
    print("ìµœì¢… ê²°ê³¼ (Test Set)")
    print(f"{'='*60}")
    print(metric_table.to_string(index=False))
    
    return {
        "mode": mode,
        "target_cols": target_cols,
        "df_hourly": df_hourly,
        "df_features": df_feat,
        "X": X, "y": y,
        "splits": splits_selected,
        "top_features": top_features,
        "results": results,
        "metric_table": metric_table,
        "fitted_models": fitted_models,
        "scalers": scalers
    }

# =========================
# 9) Main Execution
# =========================
if __name__ == "__main__":
    print("="*80)
    print("IMPROVED ML BASELINE V2 - WWTP PREDICTION")
    print("ì£¼ìš” ê°œì„ ì‚¬í•­:")
    print("  1. ì „ì²˜ë¦¬ëœ ë°ì´í„° ì‚¬ìš© (1ë¶„ ê°„ê²©, ì„ í˜• ë³´ê°„ ì™„ë£Œ)")
    print("  2. ë„ë©”ì¸ í”¼ì²˜ ì¶”ê°€ (ìƒí˜¸ì‘ìš©, ë¹„ìœ¨, ì°¨ë¶„)")
    print("  3. ì •ê·œí™” ê°•í™” (alpha ì¦ê°€, max_depth ì œí•œ)")
    print("="*80)
    
    print("\në°ì´í„° ë¡œë”© ì¤‘...")
    
    # ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ (1ë¶„ ê°„ê²©, ì„ í˜• ë³´ê°„ ì™„ë£Œ)
    df_flow = pd.read_csv("../../../../data/processed/flow_proc.csv")
    df_tms = pd.read_csv("../../../../data/processed/tms_proc.csv")
    df_all = pd.read_csv("../../../../data/processed/all_proc.csv")
    
    print(f"FLOW processed shape: {df_flow.shape}")
    print(f"TMS processed shape: {df_tms.shape}")
    print(f"ALL processed shape: {df_all.shape}")
    
    # Q_in ì»¬ëŸ¼ ìƒì„±: Q_in = flow_TankA + flow_TankB
    if 'Q_in' not in df_flow.columns:
        if 'flow_TankA' in df_flow.columns and 'flow_TankB' in df_flow.columns:
            df_flow['Q_in'] = df_flow['flow_TankA'] + df_flow['flow_TankB']
            print("âœ“ Q_in ì»¬ëŸ¼ ìƒì„± (flow): flow_TankA + flow_TankB")
    
    if 'Q_in' not in df_all.columns:
        if 'flow_TankA' in df_all.columns and 'flow_TankB' in df_all.columns:
            df_all['Q_in'] = df_all['flow_TankA'] + df_all['flow_TankB']
            print("âœ“ Q_in ì»¬ëŸ¼ ìƒì„± (all): flow_TankA + flow_TankB")
    
    # ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€
    for c in ["flow_TankA", "flow_TankB"]:
        if c in df_flow.columns:
            df_flow.drop(columns=[c], inplace=True)
            print(f"âœ“ Dropped {c} from flow to prevent data leakage")
        if c in df_all.columns:
            df_all.drop(columns=[c], inplace=True)
            print(f"âœ“ Dropped {c} from all to prevent data leakage")
    
    dfs = {
        "flow": df_flow,
        "tms": df_tms,
        "all": df_all
    }
    
    time_col_map = {
        "flow": "SYS_TIME",
        "tms": "SYS_TIME",
        "all": "SYS_TIME"
    }
    
    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    print("\n" + "="*80)
    print("íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œì‘")
    print("="*80)
    
    # Flow ì˜ˆì¸¡ (Q_inë§Œ ì˜ˆì¸¡)
    print("\n\n" + "ğŸ”µ"*40)
    print("FLOW ì˜ˆì¸¡ ì‹œì‘")
    print("ğŸ”µ"*40)
    out_flow = run_improved_pipeline_v2(
        {"flow": df_flow},  # flow ë°ì´í„°ë§Œ ì „ë‹¬
        mode="flow", 
        time_col_map={"flow": "SYS_TIME"},
        n_top_features=25,
        cv_splits=3
    )
    
    # TMS ì˜ˆì¸¡ (6ê°œ ìˆ˜ì§ˆ ë³€ìˆ˜ ì˜ˆì¸¡)
    print("\n\n" + "ğŸŸ¢"*40)
    print("TMS ì˜ˆì¸¡ ì‹œì‘")
    print("ğŸŸ¢"*40)
    out_tms = run_improved_pipeline_v2(
        {"tms": df_tms},  # tms ë°ì´í„°ë§Œ ì „ë‹¬
        mode="tms", 
        time_col_map={"tms": "SYS_TIME"},
        n_top_features=30,
        cv_splits=3
    )
    
    # All ì˜ˆì¸¡ (Q_in + 6ê°œ ìˆ˜ì§ˆ ë³€ìˆ˜ = 7ê°œ ì˜ˆì¸¡)
    print("\n\n" + "ğŸŸ¡"*40)
    print("ALL ì˜ˆì¸¡ ì‹œì‘")
    print("ğŸŸ¡"*40)
    out_all = run_improved_pipeline_v2(
        {"all": df_all},  # all ë°ì´í„°ë§Œ ì „ë‹¬
        mode="all", 
        time_col_map={"all": "SYS_TIME"},
        n_top_features=35,
        cv_splits=3
    )
    
    print("\n" + "="*80)
    print("ëª¨ë“  íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
    print("="*80)
    
    # ìµœê³  ëª¨ë¸ ì €ì¥
    best_model_name = out_all["metric_table"].iloc[0]["model"]
    print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model_name}")
    print(f"   Test RÂ²: {out_all['results'][best_model_name]['test']['R2_mean']:.4f}")
    print(f"   Test RMSE: {out_all['results'][best_model_name]['test']['RMSE_mean']:.2f}")
