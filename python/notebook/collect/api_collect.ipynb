{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e973ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_URL = \"https://apihub.kma.go.kr/api/typ01/cgi-bin/url/nph-aws2_min\"\n",
    "\n",
    "AUTH_KEY = \"\"\n",
    "STN = \"368\"\n",
    "\n",
    "OUT_CSV = Path(\"./data/actual/AWS_368.csv\")\n",
    "N_CALLS = 50 # 총 1000번\n",
    "\n",
    "WINDOW_HOURS = 20 # 12시간\n",
    "\n",
    "STEP_MINUTES = 1 # 마지막 관측시각 + 1분\n",
    "\n",
    "TIMEOUT_SEC = 60 # 60초 동안 기다림\n",
    "SLEEP_SEC = 1 # 너무 빠르면 막힐 수 있어 약간 쉬기(필요 시 조절)\n",
    "\n",
    "COLS = [\n",
    "    \"YYMMDDHHMI\", \"STN\",\n",
    "    \"WD1\", \"WS1\", \"WDS\", \"WSS\",\n",
    "    \"WD10\", \"WS10\",\n",
    "    \"TA\", \"RE\",\n",
    "    \"RN_15m\", \"RN_60m\", \"RN_12H\", \"RN_DAY\",\n",
    "    \"HM\", \"PA\", \"PS\", \"TD\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "953ee409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_text(tm1: str, tm2: str) -> str:\n",
    "    params = {\n",
    "        \"tm1\": tm1,\n",
    "        \"tm2\": tm2,\n",
    "        \"stn\": STN,\n",
    "        \"disp\": \"1\",\n",
    "        \"help\": \"0\",\n",
    "        \"authKey\": AUTH_KEY\n",
    "    }\n",
    "    r = requests.get(BASE_URL, params=params, timeout=TIMEOUT_SEC)\n",
    "    r.raise_for_status()\n",
    "    return r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "299ba5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_kma_text_to_df(text: str) -> pd.DataFrame:\n",
    "    # 1) 주석/빈줄 제거\n",
    "    lines = []\n",
    "    for ln in text.splitlines():\n",
    "        ln = ln.strip()\n",
    "        if not ln or ln.startswith(\"#\"):\n",
    "            continue\n",
    "        lines.append(ln)\n",
    "\n",
    "    if not lines:\n",
    "        return pd.DataFrame(columns=COLS)\n",
    "\n",
    "    # 2) 끝 토큰 '=' 제거\n",
    "    cleaned = []\n",
    "    for ln in lines:\n",
    "        if ln.endswith(\",=\"):\n",
    "            ln = ln[:-2]\n",
    "        elif ln.endswith(\"=\"):\n",
    "            ln = ln[:-1]\n",
    "            if ln.endswith(\",\"):\n",
    "                ln = ln[:-1]\n",
    "        cleaned.append(ln)\n",
    "\n",
    "    df = pd.read_csv(StringIO(\"\\n\".join(cleaned)), header=None, dtype=str)\n",
    "\n",
    "    # 열수 체크\n",
    "    if df.shape[1] != len(COLS):\n",
    "        # 포맷이 바뀌었거나 에러 메시지가 섞인 경우가 흔함\n",
    "        raise ValueError(f\"컬럼 수 불일치: expected={len(COLS)}, got={df.shape[1]}\")\n",
    "\n",
    "    df.columns = COLS\n",
    "\n",
    "    # datetime 파생\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"YYMMDDHHMI\"], format=\"%Y%m%d%H%M\", errors=\"coerce\")\n",
    "\n",
    "    # 숫자 변환\n",
    "    for c in df.columns:\n",
    "        if c in (\"YYMMDDHHMI\", \"datetime\"):\n",
    "            continue\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    # 결측 센티넬(-99.x) 처리\n",
    "    num_cols = [c for c in df.columns if c not in (\"YYMMDDHHMI\", \"datetime\")]\n",
    "    for c in num_cols:\n",
    "        df.loc[df[c] <= -99, c] = pd.NA\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1c519d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt_to_tm(dt: pd.Timestamp) -> str:\n",
    "    # KST 타임존을 별도로 붙이지 않아도, 문자열 기준으로 굴리면 충분함(네 데이터가 KST임)\n",
    "    return dt.strftime(\"%Y%m%d%H%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32ba230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_df_to_csv(df: pd.DataFrame, path: Path):\n",
    "    if df.empty:\n",
    "        return\n",
    "    write_header = not path.exists()\n",
    "    df.to_csv(path, mode=\"a\", index=False, encoding=\"utf-8-sig\", header=write_header)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b0b0b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_next_tm1_from_existing_csv(path: Path, fallback_tm1: str) -> str:\n",
    "    if not path.exists():\n",
    "        return fallback_tm1\n",
    "\n",
    "    # 큰 파일이면 tail 방식이 좋지만, 여기선 간단하게 마지막 행만 읽음\n",
    "    last = pd.read_csv(path, usecols=[\"YYMMDDHHMI\"]).tail(1)\n",
    "    if last.empty:\n",
    "        return fallback_tm1\n",
    "\n",
    "    last_dt = pd.to_datetime(last[\"YYMMDDHHMI\"].iloc[0], format=\"%Y%m%d%H%M\", errors=\"coerce\")\n",
    "    if pd.isna(last_dt):\n",
    "        return fallback_tm1\n",
    "\n",
    "    next_dt = last_dt + pd.Timedelta(minutes=STEP_MINUTES)\n",
    "    return dt_to_tm(next_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbea690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/50] tm1=202601130120 tm2=202601132120\n",
      "[2/50] tm1=202601131109 tm2=202601140709\n",
      "[3/50] tm1=202601131844 tm2=202601141444\n",
      "[4/50] tm1=202601132224 tm2=202601141824\n",
      "[5/50] tm1=202601141825 tm2=202601151425\n",
      "[6/50] tm1=202601150325 tm2=202601152325\n",
      "[7/50] tm1=202601152326 tm2=202601161926\n",
      "[8/50] tm1=202601160826 tm2=202601170426\n",
      "[9/50] tm1=202601161554 tm2=202601171154\n",
      "[10/50] tm1=202601162344 tm2=202601171944\n",
      "[11/50] tm1=202601170734 tm2=202601180334\n",
      "[12/50] tm1=202601171809 tm2=202601181409\n",
      "[13/50] tm1=202601180504 tm2=202601190104\n",
      "[14/50] tm1=202601181621 tm2=202601191221\n",
      "[15/50] tm1=202601190106 tm2=202601192106\n",
      "[16/50] tm1=202601191053 tm2=202601200653\n",
      "[17/50] tm1=202601192150 tm2=202601201750\n",
      "[18/50] tm1=202601200731 tm2=202601210331\n",
      "[19/50] tm1=202601200802 tm2=202601210402\n",
      "[20/50] tm1=202601202051 tm2=202601211651\n",
      "  [error] HTTPError('504 Server Error: Gateway Timeout for url: https://apihub.kma.go.kr/api/typ01/cgi-bin/url/nph-aws2_min?tm1=202601202051&tm2=202601211651&stn=368&disp=1&help=0&authKey=bWb9TUUATEGm_U1FAExBlg')\n",
      "[21/50] tm1=202601211652 tm2=202601221252\n",
      "[22/50] tm1=202601220112 tm2=202601222112\n",
      "  [error] HTTPError('504 Server Error: Gateway Timeout for url: https://apihub.kma.go.kr/api/typ01/cgi-bin/url/nph-aws2_min?tm1=202601220112&tm2=202601222112&stn=368&disp=1&help=0&authKey=bWb9TUUATEGm_U1FAExBlg')\n",
      "[23/50] tm1=202601222113 tm2=202601231713\n",
      "[24/50] tm1=202601231714 tm2=202601241314\n",
      "[25/50] tm1=202601240536 tm2=202601250136\n",
      "[26/50] tm1=202601250137 tm2=202601252137\n",
      "[27/50] tm1=202601252138 tm2=202601261738\n",
      "[28/50] tm1=202601261739 tm2=202601271339\n",
      "[29/50] tm1=202601271340 tm2=202601280940\n",
      "[30/50] tm1=202601280941 tm2=202601290541\n",
      "[31/50] tm1=202601290542 tm2=202601300142\n",
      "[32/50] tm1=202601292216 tm2=202601301816\n",
      "[33/50] tm1=202601301817 tm2=202601311417\n",
      "[34/50] tm1=202601311418 tm2=202602011018\n",
      "[35/50] tm1=202602011019 tm2=202602020619\n",
      "[36/50] tm1=202602020620 tm2=202602030220\n",
      "[37/50] tm1=202602030221 tm2=202602032221\n",
      "[38/50] tm1=202602032222 tm2=202602041822\n",
      "[39/50] tm1=202602041823 tm2=202602051423\n",
      "[40/50] tm1=202602051424 tm2=202602061024\n",
      "[41/50] tm1=202602061025 tm2=202602070625\n",
      "[42/50] tm1=202602070626 tm2=202602080226\n",
      "[43/50] tm1=202602080203 tm2=202602082203\n",
      "[44/50] tm1=202602081428 tm2=202602091028\n",
      "[45/50] tm1=202602091029 tm2=202602100629\n",
      "[46/50] tm1=202602100630 tm2=202602110230\n",
      "[47/50] tm1=202602110231 tm2=202602112231\n",
      "[48/50] tm1=202602112232 tm2=202602121832\n",
      "[49/50] tm1=202602121013 tm2=202602130613\n",
      "[50/50] tm1=202602130536 tm2=202602140136\n",
      "DONE: C:\\project_WWTP\\python\\AWS_368.csv\n"
     ]
    }
   ],
   "source": [
    "INITIAL_TM1 = \"202601130120\"  # 첫 실행용 기본값\n",
    "tm1 = infer_next_tm1_from_existing_csv(OUT_CSV, INITIAL_TM1)\n",
    "\n",
    "for i in range(N_CALLS):\n",
    "    start_dt = pd.to_datetime(tm1, format=\"%Y%m%d%H%M\")\n",
    "    end_dt = start_dt + pd.Timedelta(hours=WINDOW_HOURS)\n",
    "    tm2 = dt_to_tm(end_dt)\n",
    "\n",
    "    print(f\"[{i+1}/{N_CALLS}] tm1={tm1} tm2={tm2}\")\n",
    "\n",
    "    try:\n",
    "        text = fetch_text(tm1, tm2)\n",
    "        df = parse_kma_text_to_df(text)\n",
    "\n",
    "        # 혹시 중복이 생기면(이어받기/겹침) 제거\n",
    "        if not df.empty:\n",
    "            df = df.drop_duplicates(subset=[\"YYMMDDHHMI\", \"STN\"], keep=\"last\")\n",
    "\n",
    "        append_df_to_csv(df, OUT_CSV)\n",
    "\n",
    "        # 다음 tm1 = 이번 응답의 마지막 datetime + 1분\n",
    "        if df.empty or df[\"datetime\"].isna().all():\n",
    "            # 데이터가 비었으면 그냥 윈도우를 앞으로 한 칸 이동(12시간)\n",
    "            tm1 = dt_to_tm(end_dt + pd.Timedelta(minutes=STEP_MINUTES))\n",
    "        else:\n",
    "            last_dt = df[\"datetime\"].max()\n",
    "            tm1 = dt_to_tm(last_dt + pd.Timedelta(minutes=STEP_MINUTES))\n",
    "\n",
    "    except Exception as e:\n",
    "        # 에러 나면 너무 멀리 점프하지 말고, 일단 12시간 뒤로만 이동해서 계속\n",
    "        print(\"  [error]\", repr(e))\n",
    "        tm1 = dt_to_tm(end_dt + pd.Timedelta(minutes=STEP_MINUTES))\n",
    "\n",
    "    time.sleep(SLEEP_SEC)\n",
    "\n",
    "print(\"DONE:\", OUT_CSV.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7693ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- 설정 ---\n",
    "FREQ_MIN = 1                 # AWS 1분 자료 가정\n",
    "MAX_FETCH_HOURS = 20         # 한 번 호출할 최대 윈도우(너 코드와 맞춤)\n",
    "SLEEP_SEC = 1                # 너무 빠른 호출 방지\n",
    "RETRY = 3                    # 각 구간 재시도 횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680fbd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_existing_csv(path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, dtype=str)\n",
    "    if \"datetime\" not in df.columns:\n",
    "        df[\"datetime\"] = pd.to_datetime(df[\"YYMMDDHHMI\"], format=\"%Y%m%d%H%M\", errors=\"coerce\")\n",
    "    else:\n",
    "        df[\"datetime\"] = pd.to_datetime(df[\"datetime\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"datetime\"]).sort_values(\"datetime\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c7a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_missing_intervals(df: pd.DataFrame, freq_min: int = 1):\n",
    "    \"\"\"\n",
    "    df(datetime 정렬됨)에서 누락 구간을 [(start_dt, end_dt), ...]로 반환\n",
    "    start_dt/end_dt는 '누락된' 구간의 양끝(둘 다 포함)\n",
    "    \"\"\"\n",
    "    dts = df[\"datetime\"].drop_duplicates().sort_values().to_numpy()\n",
    "    if len(dts) < 2:\n",
    "        return []\n",
    "\n",
    "    missing = []\n",
    "    step = pd.Timedelta(minutes=freq_min)\n",
    "\n",
    "    for prev, nxt in zip(dts[:-1], dts[1:]):\n",
    "        prev = pd.Timestamp(prev)\n",
    "        nxt = pd.Timestamp(nxt)\n",
    "        if (nxt - prev) > step:\n",
    "            start = prev + step\n",
    "            end = nxt - step\n",
    "            missing.append((start, end))\n",
    "\n",
    "    # 인접/겹침 병합(안전)\n",
    "    merged = []\n",
    "    for s, e in missing:\n",
    "        if not merged:\n",
    "            merged.append([s, e])\n",
    "        else:\n",
    "            ps, pe = merged[-1]\n",
    "            if s <= pe + step:\n",
    "                merged[-1][1] = max(pe, e)\n",
    "            else:\n",
    "                merged.append([s, e])\n",
    "    return [(a, b) for a, b in merged]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932b13e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_interval(start_dt: pd.Timestamp, end_dt: pd.Timestamp, max_hours: int, freq_min: int = 1):\n",
    "    \"\"\"\n",
    "    inclusive API 기준으로 누락 구간(start_dt~end_dt)을 호출 가능한 크기로 쪼갬.\n",
    "    각 chunk는 [tm1, tm2] inclusive.\n",
    "    다음 chunk 시작은 tm2 + freq_min.\n",
    "    반환: [(tm1, tm2), ...] (문자열 YYYYmmddHHMM)\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    cur = start_dt\n",
    "    max_span = pd.Timedelta(hours=max_hours)\n",
    "\n",
    "    while cur <= end_dt:\n",
    "        tm1 = dt_to_tm(cur)\n",
    "        tm2_dt = min(cur + max_span, end_dt)\n",
    "        # tm2는 inclusive로 받고 싶으면 +1분을 주는 방식도 있음.\n",
    "        # 여기선 end_dt까지 덮게 하려면 tm2_dt를 그대로 쓰고,\n",
    "        # API가 tm2를 포함해 주는지 애매하면 +1분 해도 됨.\n",
    "        tm2 = dt_to_tm(tm2_dt)\n",
    "        chunks.append((tm1, tm2))\n",
    "        cur = tm2_dt + pd.Timedelta(minutes=freq_min)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9703e15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refetch_missing_and_merge(csv_path: Path):\n",
    "    if not csv_path.exists():\n",
    "        raise FileNotFoundError(csv_path)\n",
    "\n",
    "    base = load_existing_csv(csv_path)\n",
    "    gaps = find_missing_intervals(base, freq_min=FREQ_MIN)\n",
    "\n",
    "    print(f\"Found gaps: {len(gaps)}\")\n",
    "    if not gaps:\n",
    "        print(\"No missing intervals. Done.\")\n",
    "        return\n",
    "\n",
    "    new_rows = []\n",
    "\n",
    "    for gi, (gs, ge) in enumerate(gaps, start=1):\n",
    "        print(f\"\\n[GAP {gi}/{len(gaps)}] missing {gs} ~ {ge} (KST)\")\n",
    "        chunks = chunk_interval(gs, ge, MAX_FETCH_HOURS, freq_min=FREQ_MIN)\n",
    "\n",
    "        for ci, (tm1, tm2) in enumerate(chunks, start=1):\n",
    "            print(f\"  - chunk {ci}/{len(chunks)} tm1={tm1} tm2={tm2}\")\n",
    "            ok = False\n",
    "            last_err = None\n",
    "\n",
    "            for r in range(RETRY):\n",
    "                try:\n",
    "                    text = fetch_text(tm1, tm2)\n",
    "                    df_new = parse_kma_text_to_df(text)\n",
    "                    if not df_new.empty:\n",
    "                        new_rows.append(df_new)\n",
    "                    ok = True\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    last_err = e\n",
    "                    time.sleep(1.0)  # 재시도 간격\n",
    "\n",
    "            if not ok:\n",
    "                print(\"    [failed]\", repr(last_err))\n",
    "\n",
    "            time.sleep(SLEEP_SEC)\n",
    "\n",
    "    if not new_rows:\n",
    "        print(\"\\nNo data fetched for gaps (all failed or empty).\")\n",
    "        return\n",
    "\n",
    "    add = pd.concat(new_rows, ignore_index=True)\n",
    "\n",
    "    # 기존 + 추가 병합\n",
    "    merged = pd.concat([base, add], ignore_index=True)\n",
    "\n",
    "    # 타입/정렬/중복 제거\n",
    "    merged[\"datetime\"] = pd.to_datetime(merged[\"YYMMDDHHMI\"], format=\"%Y%m%d%H%M\", errors=\"coerce\")\n",
    "    merged = merged.dropna(subset=[\"datetime\"]).sort_values(\"datetime\")\n",
    "\n",
    "    # 동일 시각·동일 STN 중복 제거(최신값 유지)\n",
    "    if \"STN\" not in merged.columns:\n",
    "        merged[\"STN\"] = str(STN)\n",
    "    merged = merged.drop_duplicates(subset=[\"YYMMDDHHMI\", \"STN\"], keep=\"last\")\n",
    "\n",
    "    # 최종 저장(덮어쓰기)\n",
    "    merged.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(\"\\nDONE. Filled gaps and rewrote:\", csv_path.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6b90f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found gaps: 2\n",
      "\n",
      "[GAP 1/2] missing 2026-01-13 21:21:00 ~ 2026-01-14 09:09:00 (KST)\n",
      "  - chunk 1/1 tm1=202601132121 tm2=202601140909\n",
      "\n",
      "[GAP 2/2] missing 2026-01-23 18:58:00 ~ 2026-01-24 08:04:00 (KST)\n",
      "  - chunk 1/1 tm1=202601231858 tm2=202601240804\n",
      "\n",
      "DONE. Filled gaps and rewrote: C:\\project_WWTP\\python\\data\\actual\\AWS_368.csv\n"
     ]
    }
   ],
   "source": [
    "# 실행\n",
    "refetch_missing_and_merge(OUT_CSV)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
