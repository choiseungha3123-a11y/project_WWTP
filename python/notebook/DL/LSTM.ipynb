{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "83a03c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:/project_WWTP/python')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from scipy.stats import zscore\n",
    "import scipy.stats as stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "# PyTorch 라이브러리\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "\n",
    "import notebook.feature.WF_feature_selection as wf_fs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "172e6ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path.cwd().resolve().parent.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "62aba9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "MODEL_DIR = BASE_DIR / \"model\"\n",
    "RESULTS_DIR = BASE_DIR / \"results\" / \"DL\"\n",
    "NOTEBOOK_DIR = BASE_DIR / \"notebook\" / \"DL\"\n",
    "\n",
    "MODEL_SAVE_DIR = MODEL_DIR\n",
    "SCALER_SAVE_DIR = MODEL_DIR\n",
    "\n",
    "RESULTS_SAVE_DIR = RESULTS_DIR\n",
    "PLOTS_SAVE_DIR = RESULTS_DIR / \"plots\"\n",
    "METRICS_SAVE_DIR = RESULTS_DIR / \"metrics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "29037366",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE_CONFIGS = {\n",
    "    \"flow\": {\n",
    "        \"hidden_size\": 64, \n",
    "        \"num_layers\": 3, \n",
    "        \"dropout\": 0.2,\n",
    "        \"learning_rate\": 1e-4, \n",
    "        \"batch_size\": 16, \n",
    "        \"window_size\": 48,  # 30분 리샘플링: 24시간 = 48 steps\n",
    "        \"output_size\": 1, \n",
    "    },\n",
    "    \"toc\": {  # TOC_VU 단일 예측\n",
    "        \"hidden_size\": 128,\n",
    "        \"num_layers\": 4,\n",
    "        \"dropout\": 0.5,\n",
    "        \"learning_rate\": 5e-4,\n",
    "        \"batch_size\": 32,\n",
    "        \"window_size\": 96,  # 30분 리샘플링: 48시간 = 96 steps\n",
    "        \"output_size\": 1, \n",
    "    },\n",
    "    \"ss\": {  # SS_VU 단일 예측\n",
    "        \"hidden_size\": 128,\n",
    "        \"num_layers\": 3,\n",
    "        \"dropout\": 0.4,\n",
    "        \"learning_rate\": 5e-5,\n",
    "        \"batch_size\": 32,\n",
    "        \"window_size\": 96,  # 30분 리샘플링: 48시간 = 96 steps\n",
    "        \"output_size\": 1, \n",
    "    },\n",
    "    \"tn\": {  # TN_VU 단일 예측\n",
    "        \"hidden_size\": 128,\n",
    "        \"num_layers\": 3,\n",
    "        \"dropout\": 0.4,\n",
    "        \"learning_rate\": 5e-5,\n",
    "        \"batch_size\": 32,\n",
    "        \"window_size\": 96,  # 30분 리샘플링: 48시간 = 96 steps\n",
    "        \"output_size\": 1, \n",
    "    },\n",
    "    \"tp\": {  # TP_VU 단일 예측\n",
    "        \"hidden_size\": 128,\n",
    "        \"num_layers\": 3,\n",
    "        \"dropout\": 0.4,\n",
    "        \"learning_rate\": 5e-5,\n",
    "        \"batch_size\": 32,\n",
    "        \"window_size\": 96,  # 30분 리샘플링: 48시간 = 96 steps\n",
    "        \"output_size\": 1, \n",
    "    },\n",
    "    \"flux\": {  # FLUX_VU 단일 예측\n",
    "        \"hidden_size\": 128,\n",
    "        \"num_layers\": 3,\n",
    "        \"dropout\": 0.2,\n",
    "        \"learning_rate\": 5e-4,\n",
    "        \"batch_size\": 32,\n",
    "        \"window_size\": 96,  # 30분 리샘플링: 48시간 = 96 steps\n",
    "        \"output_size\": 1, \n",
    "    },\n",
    "    \"ph\": {  # PH_VU 단일 예측\n",
    "        \"hidden_size\": 128,\n",
    "        \"num_layers\": 3,\n",
    "        \"dropout\": 0.4,\n",
    "        \"learning_rate\": 5e-5,\n",
    "        \"batch_size\": 32,\n",
    "        \"window_size\": 96,  # 30분 리샘플링: 48시간 = 96 steps\n",
    "        \"output_size\": 1, \n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6cccc6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = \"flow\"  # flow, toc, ss, tn, tp, flux, ph\n",
    "\n",
    "HORIZON = 1\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "if MODE not in MODE_CONFIGS:\n",
    "    raise ValueError(f\"Unknown MODE: {MODE}. Available modes: {list(MODE_CONFIGS.keys())}\")\n",
    "\n",
    "CONFIG = MODE_CONFIGS[MODE]\n",
    "WINDOW_SIZE = CONFIG[\"window_size\"]                # 슬라이딩 윈도우\n",
    "LSTM_CONFIG = {\n",
    "    \"hidden_size\": CONFIG[\"hidden_size\"],          # LSTM 은닉층 유닛 수\n",
    "    \"num_layers\": CONFIG[\"num_layers\"],            # 쌓인 LSTM 레이어 수\n",
    "    \"dropout\": CONFIG[\"dropout\"],             # 정규화를 위한 드롭아웃 비율\n",
    "    \"output_size\": CONFIG[\"output_size\"],           # 출력 차원 \n",
    "    \"bidirectional\": False,     # 양방향 LSTM 사용 여부\n",
    "}\n",
    "\n",
    "TRAINING_CONFIG = {\n",
    "    \"batch_size\": CONFIG[\"batch_size\"],           # 학습 배치 크기\n",
    "    \"learning_rate\": CONFIG[\"learning_rate\"],     # 옵티마이저 학습률\n",
    "    \"num_epochs\": 100,          # 최대 학습 에포크 수\n",
    "    \"patience\": 20,             # 조기 종료 patience\n",
    "    \"optimizer\": \"adam\",        # 옵티마이저 타입: 'adam', 'rmsprop', 'sgd'\n",
    "    \"loss_function\": \"mse\",     # 손실 함수: 'mse' 또는 'mae'\n",
    "}\n",
    "\n",
    "SPLIT_RATIOS = {\n",
    "    \"train\": 0.7,               # 학습 세트 비율\n",
    "    \"val\": 0.15,                # 검증 세트 비율\n",
    "    \"test\": 0.15,               # 테스트 세트 비율\n",
    "}\n",
    "\n",
    "FLOW_TARGET = \"Q_in\"\n",
    "TOC_TARGET = \"TOC_VU\"\n",
    "SS_TARGET = \"SS_VU\"\n",
    "TN_TARGET = \"TN_VU\"\n",
    "TP_TARGET = \"TP_VU\"\n",
    "FLUX_TARGET = \"FLUX_VU\"\n",
    "PH_TARGET = \"PH_VU\"\n",
    "\n",
    "VISUALIZATION_CONFIG = {\n",
    "    \"dpi\": 300,                 # 플롯 해상도\n",
    "    \"figsize\": (10, 6),         # 그림 크기 (너비, 높이)\n",
    "    \"font_family\": \"Malgun Gothic\",  # 한글 폰트 지원\n",
    "    \"grid\": True,               # 플롯에 그리드 표시\n",
    "}\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "TIME_COL = \"SYS_TIME\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6b362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(DATA_DIR):\n",
    "    dfs = {}\n",
    "\n",
    "    dfs['flow'] = pd.read_csv(DATA_DIR / \"actual/FLOW_Actual.csv\")\n",
    "    dfs['flow']['Q_in'] = dfs['flow'][\"flow_TankA\"] + dfs['flow']['flow_TankB']\n",
    "    dfs['flow']['level_sum'] = dfs['flow']['level_TankA'] + dfs['flow']['level_TankB']\n",
    "    dfs['flow'] = dfs['flow'].drop(columns=[\"data_save_dt\"])\n",
    "    dfs['tms'] = pd.read_csv(DATA_DIR / \"actual/TMS_Actual.csv\")\n",
    "    for station_id in [\"368\", \"541\", \"569\"]:\n",
    "        aws_path = DATA_DIR / f\"actual/AWS_{station_id}.csv\"\n",
    "        df = pd.read_csv(aws_path)\n",
    "        if \"datetime\" in df.columns:\n",
    "            time_col = df[\"datetime\"]\n",
    "            df = df.drop(columns=[\"datetime\",\"YYMMDDHHMI\",\"STN\"], errors=\"ignore\")\n",
    "            df = df.add_suffix(f\"_{station_id}\")\n",
    "            df[\"SYS_TIME\"] = time_col\n",
    "        else:\n",
    "            df = df.drop(columns=[\"YYMMDDHHMI\", \"STN\"], errors=\"ignore\")\n",
    "            df = df.add_suffix(f\"_{station_id}\")\n",
    "        dfs[f\"aws{station_id}\"] = df\n",
    "\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175ff383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_datetime_index(df, time_col):\n",
    "    out = df.copy()\n",
    "    \n",
    "    # 시간 컬럼이 존재하는지 확인\n",
    "    if time_col not in out.columns:\n",
    "        raise ValueError(f\"시간 컬럼 '{time_col}'이 데이터프레임에 없습니다. 사용 가능한 컬럼: {out.columns.tolist()}\")\n",
    "    \n",
    "    out[time_col] = pd.to_datetime(out[time_col], errors=\"coerce\")\n",
    "    out = out.dropna(subset=[time_col])\n",
    "    out = out.set_index(time_col).sort_index()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f7334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_data(dfs):\n",
    "    aligned_dfs = {}\n",
    "    for name, df in dfs.items():\n",
    "        time_col = TIME_COL\n",
    "        df_aligned = set_datetime_index(df, time_col)\n",
    "\n",
    "        df_aligned = df_aligned.resample(\"1min\").ffill()\n",
    "\n",
    "        aligned_dfs[name] = df_aligned\n",
    "            \n",
    "    return aligned_dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5b8636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(dfs):\n",
    "\n",
    "    valid = {}\n",
    "    merged_dfs = {}\n",
    "\n",
    "    for name, df in dfs.items():\n",
    "        df2 = df.sort_index()\n",
    "        if df2.index.has_duplicates:\n",
    "            df2 = df2[~df2.index.duplicated(keep=\"last\")]\n",
    "        valid[name] = df2\n",
    "\n",
    "    for name, df in valid.items():\n",
    "        if name == \"flow\":\n",
    "            merged_dfs[name] = pd.concat([\n",
    "                df,\n",
    "                valid[\"aws368\"],\n",
    "                valid[\"aws541\"],\n",
    "                valid[\"aws569\"],\n",
    "            ], axis = 1, join = \"inner\")\n",
    "\n",
    "        if name == \"tms\":\n",
    "            merged_dfs[name] = pd.concat([\n",
    "                df,\n",
    "                valid[\"flow\"],\n",
    "                valid[\"aws368\"],\n",
    "                valid[\"aws541\"],\n",
    "                valid[\"aws569\"]\n",
    "            ], axis = 1, join = \"inner\")\n",
    "\n",
    "    return merged_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dfcc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ImputationConfig:\n",
    "    short_term_hours: int = 3\n",
    "    medium_term_hours: int = 12\n",
    "    long_term_hours: int = 48\n",
    "    ewma_span: int = 6\n",
    "\n",
    "@dataclass\n",
    "class OutlierConfig:\n",
    "    method: str = \"iqr\"\n",
    "    iqr_threshold: float = 1.5\n",
    "    zscore_threshold: float = 3.0\n",
    "    require_both: bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09861189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing(df, freq = \"1h\", config = ImputationConfig()):\n",
    "    df_out = df.copy()\n",
    "\n",
    "    freq_td = pd.Timedelta(freq)\n",
    "    freq_hours = freq_td.total_seconds() / 3600\n",
    "\n",
    "    mask_dict = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        if not pd.api.types.is_numeric_dtype(df[col]):\n",
    "            continue\n",
    "\n",
    "        series = df[col].copy()\n",
    "        original_missing = series.isna()\n",
    "\n",
    "        mask_dict[f\"{col}_is_missing\"] = original_missing.astype(int)\n",
    "\n",
    "        limit_short = max(1, int(config.short_term_hours / freq_hours))\n",
    "        series_ffill = series.ffill(limit = limit_short)\n",
    "        ffill_mask = original_missing & ~series_ffill.isna()\n",
    "        mask_dict[f\"{col}_imputed_ffill\"] = ffill_mask.astype(int)\n",
    "\n",
    "        still_missing = series_ffill.isna()\n",
    "        if still_missing.sum() > 0:\n",
    "            ewma_span = max(1, int(config.ewma_span / freq_hours))\n",
    "            series_ewma = series_ffill.ewm(span=ewma_span, adjust=False).mean()\n",
    "            \n",
    "            limit_medium = max(1, int(config.medium_term_hours / freq_hours))\n",
    "            missing_groups = (still_missing != still_missing.shift()).cumsum()\n",
    "            missing_lengths = still_missing.groupby(missing_groups).transform(\"sum\")\n",
    "            \n",
    "            medium_mask = still_missing & (missing_lengths > limit_short) & (missing_lengths <= limit_medium)\n",
    "            series_ffill[medium_mask] = series_ewma[medium_mask]\n",
    "            mask_dict[f\"{col}_imputed_ewma\"] = medium_mask.astype(int)\n",
    "        else:\n",
    "            mask_dict[f\"{col}_imputed_ewma\"] = pd.Series(0, index=df.index, dtype=int)\n",
    "\n",
    "        still_missing_long = series_ffill.isna()\n",
    "        if still_missing_long.sum() > 0:\n",
    "            # 장기 결측용 더 긴 span (기본 span의 4배)\n",
    "            long_ewma_span = max(1, int(config.ewma_span * 4 / freq_hours))\n",
    "            series_long_ewma = series_ffill.ewm(span=long_ewma_span, adjust=False).mean()\n",
    "            \n",
    "            long_mask = still_missing_long\n",
    "            series_ffill[long_mask] = series_long_ewma[long_mask]\n",
    "            mask_dict[f\"{col}_imputed_long_ewma\"] = long_mask.astype(int)\n",
    "        else:\n",
    "            mask_dict[f\"{col}_imputed_long_ewma\"] = pd.Series(0, index=df.index, dtype=int)\n",
    "\n",
    "        df_out[col] = series_ffill\n",
    "\n",
    "    df_mask = pd.DataFrame(mask_dict, index=df.index)\n",
    "    \n",
    "    return df_out, df_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853ef2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputate_data(dfs):\n",
    "    config_impute = ImputationConfig()\n",
    "    imputed_dfs = {}\n",
    "    mask_imputed_dfs = {}\n",
    "\n",
    "    for name, df in dfs.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"{name} 결측치 처리\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"결측치 처리 전:\")\n",
    "        print(f\"  총 결측치: {df.isna().sum().sum()}\")\n",
    "        print(f\"  결측치 있는 컬럼: {(df.isna().sum() > 0).sum()}개\")\n",
    "\n",
    "        df_imputed, mask_imputed = impute_missing(df, freq=\"1min\", config = config_impute)\n",
    "\n",
    "        imputed_dfs[name] = df_imputed\n",
    "        mask_imputed_dfs[name] = mask_imputed\n",
    "\n",
    "        print(f\"\\n결측치 처리 후:\")\n",
    "        print(f\"  총 결측치: {df_imputed.isna().sum().sum()}\")\n",
    "        print(f\"  데이터 shape: {df_imputed.shape}\")\n",
    "        print(f\"  마스크 shape: {mask_imputed.shape}\")\n",
    "\n",
    "    return imputed_dfs, mask_imputed_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d83c8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_domain(series, col_name):\n",
    "    outliers = pd.Series([False] * len(series), index = series.index)\n",
    "\n",
    "    if not pd.api.types.is_numeric_dtype(series):\n",
    "        return outliers\n",
    "    \n",
    "    domain_rules = {\n",
    "        \"TOC_VU\": (0, 250),\n",
    "        \"PH_VU\": (0, 14),\n",
    "        \"SS_VU\": (0, 100),\n",
    "        \"TN_VU\": (0, 100),\n",
    "        \"TP_VU\": (0, 20),\n",
    "        \"level_TankA\": (0, 10),\n",
    "        \"level_TankB\": (0, 10),\n",
    "        \"TA\": (-30, 45),\n",
    "        \"HM\": (0, 100),\n",
    "        \"TD\": (-40, 35),\n",
    "    }\n",
    "\n",
    "    if col_name in domain_rules:\n",
    "        lower, upper = domain_rules[col_name]\n",
    "        outliers = (series < lower) | (series > upper)\n",
    "    elif \"RN_\" in col_name:\n",
    "        outliers = (series < 0) | (series > 300)\n",
    "    elif \"flow\" in col_name.lower() or \"flux\" in col_name.lower():\n",
    "        valid_values = series.dropna()\n",
    "        if len(valid_values) > 0:\n",
    "            outliers = (series < 0) | (series > valid_values.quantile(0.99) * 3)\n",
    "    else:\n",
    "        valid_values = series.dropna()\n",
    "        if len(valid_values) > 0:\n",
    "            outliers = (series < 0) | (series > valid_values.quantile(0.999) * 2)\n",
    "    \n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bc61d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_statistical(series, \n",
    "                        method = 'iqr', \n",
    "                        iqr_threshold = 1.5, \n",
    "                        zscore_threshold = 3.0):\n",
    "    outliers = pd.Series([False] * len(series), index=series.index)\n",
    "\n",
    "    if not pd.api.types.is_numeric_dtype(series):\n",
    "        return outliers\n",
    "    \n",
    "    if method == 'iqr':\n",
    "        Q1 = series.quantile(0.25)\n",
    "        Q3 = series.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - iqr_threshold * IQR\n",
    "        upper = Q3 + iqr_threshold * IQR\n",
    "        outliers = (series < lower) | (series > upper)\n",
    "    \n",
    "    elif method == 'zscore':\n",
    "        # NaN 제거 후 Z-score 계산\n",
    "        valid_mask = ~series.isna()\n",
    "        if valid_mask.sum() > 0:\n",
    "            z_scores = np.abs(zscore(series[valid_mask]))\n",
    "            outliers[valid_mask] = z_scores > zscore_threshold\n",
    "    \n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60e9492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_outliers(df, config = OutlierConfig(), ewma_span = 12):\n",
    "    df_out = df.copy()\n",
    "    mask_dict = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        if not pd.api.types.is_numeric_dtype(df[col]):\n",
    "            continue\n",
    "\n",
    "        series = df[col].copy()\n",
    "\n",
    "        domain_outliers = outliers_domain(series, col)\n",
    "\n",
    "        stats_outliers = outliers_statistical(series, method = config.method, iqr_threshold=config.iqr_threshold, zscore_threshold=config.zscore_threshold)\n",
    "\n",
    "        if config.require_both:\n",
    "            final_outliers = domain_outliers & stats_outliers\n",
    "        else:\n",
    "            final_outliers = domain_outliers | stats_outliers\n",
    "\n",
    "        mask_dict[f\"{col}_outlier_domain\"] = domain_outliers.astype(int)\n",
    "        mask_dict[f\"{col}_outlier_stats\"] = stats_outliers.astype(int)\n",
    "        mask_dict[f\"{col}_outlier_final\"] = final_outliers.astype(int)\n",
    "\n",
    "        # EWMA로 이상치 대체\n",
    "        if final_outliers.sum() > 0:\n",
    "            series_ewma = series.ewm(span=ewma_span, adjust=False).mean()\n",
    "            series[final_outliers] = series_ewma[final_outliers]\n",
    "            mask_dict[f\"{col}_outlier_replaced_ewma\"] = final_outliers.astype(int)\n",
    "        else:\n",
    "            mask_dict[f\"{col}_outlier_replaced_ewma\"] = pd.Series(0, index=df.index, dtype=int)\n",
    "\n",
    "        df_out[col] = series\n",
    "\n",
    "    df_mask = pd.DataFrame(mask_dict, index=df.index)\n",
    "\n",
    "    return df_out, df_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7726b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers(dfs):\n",
    "    config_outlier = OutlierConfig()\n",
    "    processed_dfs = {}\n",
    "    mask_processed_dfs = {}\n",
    "\n",
    "    for name, df in dfs.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"{name} 이상치 처리\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        df_outlier, mask_outlier = process_outliers(df, config = config_outlier, ewma_span = 12)\n",
    "\n",
    "        processed_dfs[name] = df_outlier\n",
    "        mask_processed_dfs[name] = mask_outlier\n",
    "\n",
    "    return processed_dfs, mask_processed_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7e5fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_data(df, freq = \"30min\", rain_cols=None, other_cols=None):\n",
    "    if not isinstance(df.index, pd.DatetimeIndex) :\n",
    "        raise ValueError(\"리샘플링을 위해서는 DatetimeIndex가 필요합니다\")\n",
    "    \n",
    "    numeric_cols = df.select_dtypes(include = [np.number]).columns\n",
    "    df_numeric = df[numeric_cols]\n",
    "\n",
    "    agg_dict = {}\n",
    "    for col in numeric_cols:\n",
    "        if col.startswith(\"RN_\") or col.startswith(\"AR_\"):\n",
    "            agg_dict[col] = \"sum\"  # ← 강수량은 누적\n",
    "        else:\n",
    "            agg_dict[col] = \"mean\"\n",
    "    \n",
    "    return df_numeric.resample(freq).agg(agg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45fb8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rain_features(df):\n",
    "    \"\"\"\n",
    "    강수 + 기상-강수 상호작용 통합 (PerformanceWarning 최소화 버전)\n",
    "    - 새 컬럼은 new_cols dict에 누적 후 마지막에 한 번에 concat\n",
    "    \"\"\"\n",
    "    df_out = df.copy()\n",
    "    new_cols = {}\n",
    "\n",
    "    station_ids = [\"368\", \"541\", \"569\"]\n",
    "    rain_cols = [c for c in df_out.columns if c.startswith(\"RN_\")]\n",
    "    antecedent_hours = (3, 6, 12, 24)\n",
    "    wet_thr_mm = 0.1\n",
    "    ari_taus = (6, 12, 24)\n",
    "    eps = 1e-9\n",
    "\n",
    "    # ====== 1. 지점별 기본 강수 특성 ======\n",
    "    for sid in station_ids:\n",
    "        for rc in rain_cols[:3]:\n",
    "            col = f\"{rc}_{sid}\"\n",
    "            if col in df_out.columns:\n",
    "                new_cols[f\"d_{col}\"] = df_out[col].diff()\n",
    "\n",
    "    # ====== 2. 지점별 기상-강수 상호작용 ======\n",
    "    for sid in station_ids:\n",
    "        ta = f\"TA_{sid}\"\n",
    "        td = f\"TD_{sid}\"\n",
    "        hm = f\"HM_{sid}\"\n",
    "        rn15 = f\"RN_15m_{sid}\"\n",
    "        rn60 = f\"RN_60m_{sid}\"\n",
    "\n",
    "        if ta in df_out.columns and td in df_out.columns:\n",
    "            tadtd = df_out[ta] - df_out[td]\n",
    "            new_cols[f\"TA_minus_TD_{sid}\"] = tadtd\n",
    "\n",
    "            if hm in df_out.columns:\n",
    "                new_cols[f\"TAxHM_{sid}\"] = df_out[ta] * df_out[hm]\n",
    "                new_cols[f\"TA_minus_TD_x_HM_{sid}\"] = tadtd * df_out[hm]\n",
    "\n",
    "        if rn15 in df_out.columns and rn60 in df_out.columns:\n",
    "            new_cols[f\"RN15_div_RN60_{sid}\"] = df_out[rn15] / (df_out[rn60] + eps)\n",
    "\n",
    "    # ====== 3. 공간 통합 강수/기상 특성 ======\n",
    "    def _spatial_stats(base_name):\n",
    "        cols = [f\"{base_name}_{sid}\" for sid in station_ids if f\"{base_name}_{sid}\" in df_out.columns]\n",
    "        if not cols:\n",
    "            return {}\n",
    "\n",
    "        arr = df_out[cols]\n",
    "        mean_ = arr.mean(axis=1)\n",
    "        max_ = arr.max(axis=1)\n",
    "        min_ = arr.min(axis=1)\n",
    "        std_ = arr.std(axis=1, ddof=0)\n",
    "\n",
    "        out = {\n",
    "            f\"{base_name}_mean\": mean_,\n",
    "            f\"{base_name}_max\": max_,\n",
    "            f\"{base_name}_min\": min_,\n",
    "            f\"{base_name}_std\": std_,\n",
    "            f\"{base_name}_spread\": max_ - min_,\n",
    "        }\n",
    "        return out\n",
    "\n",
    "    for rc in rain_cols:\n",
    "        new_cols.update(_spatial_stats(rc))\n",
    "\n",
    "    for mc in [\"TA\", \"TD\", \"HM\"]:\n",
    "        new_cols.update(_spatial_stats(mc))\n",
    "\n",
    "    # 이슬점 감차 공간 통계 (TA_minus_TD는 위에서 new_cols로 만들었을 수 있음)\n",
    "    if any(f\"TA_minus_TD_{sid}\" in new_cols or f\"TA_minus_TD_{sid}\" in df_out.columns for sid in station_ids):\n",
    "        df_out_tmp = df_out\n",
    "        if new_cols:\n",
    "            df_out_tmp = pd.concat([df_out, pd.DataFrame(new_cols, index=df_out.index)], axis=1)\n",
    "        # tmp에서 계산해 다시 new_cols에 추가(중복키는 덮어씀)\n",
    "        cols_tadtd = [f\"TA_minus_TD_{sid}\" for sid in station_ids if f\"TA_minus_TD_{sid}\" in df_out_tmp.columns]\n",
    "        if cols_tadtd:\n",
    "            arr = df_out_tmp[cols_tadtd]\n",
    "            mean_ = arr.mean(axis=1)\n",
    "            max_ = arr.max(axis=1)\n",
    "            min_ = arr.min(axis=1)\n",
    "            std_ = arr.std(axis=1, ddof=0)\n",
    "            new_cols.update({\n",
    "                \"TA_minus_TD_mean\": mean_,\n",
    "                \"TA_minus_TD_max\": max_,\n",
    "                \"TA_minus_TD_min\": min_,\n",
    "                \"TA_minus_TD_std\": std_,\n",
    "                \"TA_minus_TD_spread\": max_ - min_,\n",
    "            })\n",
    "\n",
    "    # ====== 4. 강수 비율 ======\n",
    "    for sid in station_ids:\n",
    "        rn15 = f\"RN_15m_{sid}\"\n",
    "        rn60 = f\"RN_60m_{sid}\"\n",
    "        if rn15 in df_out.columns and rn60 in df_out.columns:\n",
    "            new_cols[f\"rain_ratio_15m_60m_{sid}\"] = df_out[rn15] / (df_out[rn60] + eps)\n",
    "\n",
    "    # ====== 5. 누적강수 (선행강우) ======\n",
    "    steps_per_hour = 2  # 30분 리샘플링: 1시간 = 2 steps\n",
    "    for sid in station_ids:\n",
    "        rn_col = f\"RN_60m_{sid}\"\n",
    "        if rn_col in df_out.columns:\n",
    "            s = df_out[rn_col]\n",
    "            for h in antecedent_hours:\n",
    "                win = h * steps_per_hour\n",
    "                ar = s.rolling(win, min_periods=1).sum()\n",
    "                new_cols[f\"AR_{h}h_{sid}\"] = ar\n",
    "                new_cols[f\"log1p_AR_{h}h_{sid}\"] = np.log1p(ar)\n",
    "\n",
    "    # ====== 6. Wet/Dry 상태 ======\n",
    "    for sid in station_ids:\n",
    "        col = f\"RN_15m_{sid}\"\n",
    "        if col not in df_out.columns:\n",
    "            continue\n",
    "\n",
    "        wet = (df_out[col].fillna(0.0) >= wet_thr_mm)\n",
    "\n",
    "        # last_wet_ts (datetimeindex) -> wet인 시점 index를 ffill\n",
    "        idx = df_out.index\n",
    "        last_wet_ts = pd.Series(idx.where(wet), index=idx).ffill()\n",
    "\n",
    "        dry_td = idx - last_wet_ts\n",
    "        dry_min = (dry_td / pd.Timedelta(\"1min\")).astype(\"float64\")\n",
    "        dry_hr = (dry_td / pd.Timedelta(\"1h\")).astype(\"float64\")\n",
    "\n",
    "        new_cols[f\"dry_minutes_{sid}\"] = pd.Series(dry_min, index=idx).fillna(0.0)\n",
    "        new_cols[f\"dry_hours_{sid}\"] = pd.Series(dry_hr, index=idx).fillna(0.0)\n",
    "        new_cols[f\"is_wet_{sid}\"] = wet.astype(np.int8)\n",
    "\n",
    "        rain_start = wet & (~wet.shift(1, fill_value=False))\n",
    "        rain_end = (~wet) & (wet.shift(1, fill_value=False))\n",
    "        new_cols[f\"rain_start_{sid}\"] = rain_start.astype(np.int8)\n",
    "        new_cols[f\"rain_end_{sid}\"] = rain_end.astype(np.int8)\n",
    "\n",
    "        post_win = 6 * steps_per_hour\n",
    "        new_cols[f\"post_rain_6H_{sid}\"] = (\n",
    "            pd.Series(rain_end.to_numpy(), index=idx)\n",
    "            .rolling(post_win, min_periods=1).max()\n",
    "            .fillna(0).astype(np.int8)\n",
    "        )\n",
    "\n",
    "    # ====== 7. ARI (선행강우지수) ======\n",
    "    # RN_60m_mean이 df_out에 있거나 new_cols에서 만들어졌을 수 있음\n",
    "    rn60_mean = None\n",
    "    if \"RN_60m_mean\" in new_cols:\n",
    "        rn60_mean = new_cols[\"RN_60m_mean\"]\n",
    "    elif \"RN_60m_mean\" in df_out.columns:\n",
    "        rn60_mean = df_out[\"RN_60m_mean\"]\n",
    "\n",
    "    if rn60_mean is not None:\n",
    "        rain_for_ari = rn60_mean.shift(1)  # 현재 강우 제외\n",
    "\n",
    "        for tau in ari_taus:\n",
    "            klen = int(6 * tau)  # (원 코드 유지)\n",
    "            w = np.exp(-np.arange(klen) / float(tau))\n",
    "            w = w / (w.sum() + eps)\n",
    "\n",
    "            def _ari(x):\n",
    "                x = np.asarray(x, dtype=float)\n",
    "                if np.any(~np.isfinite(x)):\n",
    "                    return np.nan\n",
    "                ww = w[-len(x):]\n",
    "                return float((x * ww).sum())\n",
    "\n",
    "            new_cols[f\"ARI_tau{tau}\"] = rain_for_ari.rolling(klen, min_periods=klen).apply(_ari, raw=True)\n",
    "\n",
    "    # ====== 8. 면적강수 통합 ======\n",
    "    ar12_cols = [f\"AR_12h_{sid}\" for sid in station_ids]\n",
    "    # ar12가 new_cols에 있을 수도 있으니 tmp에서 계산\n",
    "    df_tmp = df_out\n",
    "    if new_cols:\n",
    "        df_tmp = pd.concat([df_out, pd.DataFrame(new_cols, index=df_out.index)], axis=1)\n",
    "\n",
    "    ar12_exist = [c for c in ar12_cols if c in df_tmp.columns]\n",
    "    if ar12_exist:\n",
    "        new_cols[\"AR_12h_sum_all\"] = df_tmp[ar12_exist].sum(axis=1)\n",
    "        new_cols[\"AR_12h_mean_all\"] = df_tmp[ar12_exist].mean(axis=1)\n",
    "\n",
    "    rn15_mean = df_tmp[\"RN_15m_mean\"] if \"RN_15m_mean\" in df_tmp.columns else None\n",
    "    rn60_mean2 = df_tmp[\"RN_60m_mean\"] if \"RN_60m_mean\" in df_tmp.columns else None\n",
    "    if rn15_mean is not None and rn60_mean2 is not None:\n",
    "        new_cols[\"RN_15m_div_RN_60m_mean\"] = rn15_mean / (rn60_mean2 + eps)\n",
    "\n",
    "    # ====== 마지막: 한 번에 합치기 ======\n",
    "    if new_cols:\n",
    "        df_out = pd.concat([df_out, pd.DataFrame(new_cols, index=df_out.index)], axis=1)\n",
    "\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ad8399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_process_features(df):\n",
    "    ph_low, ph_high = (5.8, 8.5)\n",
    "    eps = 1e-6\n",
    "\n",
    "    df_out = df.copy()\n",
    "    new_cols = {}\n",
    "\n",
    "    cols = df_out.columns\n",
    "\n",
    "    # 자주 쓰는 컬럼은 미리 뽑아두기(있을 때만)\n",
    "    FLUX = df_out[\"FLUX_VU\"] if \"FLUX_VU\" in cols else None\n",
    "    PH   = df_out[\"PH_VU\"]   if \"PH_VU\"   in cols else None\n",
    "    SS   = df_out[\"SS_VU\"]   if \"SS_VU\"   in cols else None\n",
    "    TOC  = df_out[\"TOC_VU\"]  if \"TOC_VU\"  in cols else None\n",
    "    TN   = df_out[\"TN_VU\"]   if \"TN_VU\"   in cols else None\n",
    "    TP   = df_out[\"TP_VU\"]   if \"TP_VU\"   in cols else None\n",
    "\n",
    "    # Loads\n",
    "    if FLUX is not None and SS is not None:\n",
    "        new_cols[\"SS_load\"] = FLUX * SS\n",
    "        new_cols[\"SS_x_FLUX\"] = SS * FLUX\n",
    "\n",
    "    if FLUX is not None and TOC is not None:\n",
    "        new_cols[\"TOC_load\"] = FLUX * TOC\n",
    "\n",
    "    if FLUX is not None and TN is not None and TP is not None:\n",
    "        new_cols[\"load_proxy_NP\"] = FLUX * (TN + TP)\n",
    "\n",
    "    # Interactions\n",
    "    if PH is not None and FLUX is not None:\n",
    "        new_cols[\"PH_x_FLUX\"] = PH * FLUX\n",
    "\n",
    "    if PH is not None and TOC is not None:\n",
    "        new_cols[\"PH_x_TOC\"] = PH * TOC\n",
    "\n",
    "    if TOC is not None and SS is not None:\n",
    "        new_cols[\"TOC_x_SS\"] = TOC * SS\n",
    "        new_cols[\"TOC_div_SS\"] = TOC / (SS + eps)\n",
    "\n",
    "    if TN is not None and TP is not None:\n",
    "        new_cols[\"TN_x_TP\"] = TN * TP\n",
    "        new_cols[\"TN_div_TP\"] = TN / (TP + eps)\n",
    "        new_cols[\"log1p_TN_TP\"] = np.log1p(TN + TP)\n",
    "\n",
    "    if TOC is not None and TN is not None:\n",
    "        new_cols[\"TOC_div_TN\"] = TOC / (TN + eps)\n",
    "\n",
    "    # pH zone flags\n",
    "    if PH is not None:\n",
    "        phv = PH.astype(\"float64\")\n",
    "        new_cols[\"pH_acid\"] = (phv < ph_low).astype(np.int8)\n",
    "        new_cols[\"pH_neutral\"] = ((phv >= ph_low) & (phv <= ph_high)).astype(np.int8)\n",
    "        new_cols[\"pH_basic\"] = (phv > ph_high).astype(np.int8)\n",
    "\n",
    "    if new_cols:\n",
    "        df_out = pd.concat([df_out, pd.DataFrame(new_cols, index=df_out.index)], axis=1)\n",
    "\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a2d3470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScaler:\n",
    "    def __init__(self):\n",
    "        self.mean_ = None\n",
    "        self.std_ = None\n",
    "\n",
    "    def fit(self, x):\n",
    "        self.mean_ = x.mean(axis = 0, keepdims = True)\n",
    "        self.std_ = x.std(axis = 0, keepdims = True) + 1e-8\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x):\n",
    "        return (x - self.mean_) / self.std_\n",
    "    \n",
    "    def inverse_transform(self, x):\n",
    "        return x * self.std_ + self.mean_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549b30e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_temporal_features(df):\n",
    "    \"\"\"\n",
    "    시간 특성 생성 (성능 개선 버전)\n",
    "    - Lag\n",
    "    - Rolling 통계 (mean, std, max, min, IQR=Q90-Q10)\n",
    "    - Rolling slope (closed-form)\n",
    "    - Difference\n",
    "    \n",
    "    주기: 30분 리샘플링 기준 (1시간 = 2 steps)\n",
    "    \"\"\"\n",
    "    station_ids = [\"368\", \"541\", \"569\"]\n",
    "    weather_cols = [\"TA\", \"TD\", \"HM\"]\n",
    "    process_cols = [\"PH_VU\", \"FLUX_VU\", \"TN_VU\", \"TP_VU\", \"SS_VU\", \"TOC_VU\"]\n",
    "\n",
    "    # 30분 리샘플링: 1시간 = 2 steps\n",
    "    roll_windows = [6, 12, 24, 72]      # 3h, 6h, 12h, 36h\n",
    "    lags = [2, 4, 6, 12, 24, 48, 72]    # 1h, 2h, 3h, 6h, 12h, 24h, 36h\n",
    "    slope_windows = [12, 24, 48]        # 6h, 12h, 24h\n",
    "\n",
    "    df_out = df.copy()\n",
    "    new_cols = {}\n",
    "\n",
    "    # ====== 1) 대상 컬럼(존재하는 것만) ======\n",
    "    roll_targets = (\n",
    "        list(process_cols)\n",
    "        + [f\"{wc}_{sid}\" for sid in station_ids for wc in weather_cols]\n",
    "        + [f\"RN_15m_{sid}\" for sid in station_ids]\n",
    "        + [f\"RN_60m_{sid}\" for sid in station_ids]\n",
    "    )\n",
    "    roll_targets = [c for c in roll_targets if c in df_out.columns]\n",
    "\n",
    "    lag_targets = (\n",
    "        list(process_cols)\n",
    "        + [f\"{col}_{sid}\" for sid in station_ids for col in ([\"RN_15m\", \"RN_60m\", \"RN_12H\"] + weather_cols)]\n",
    "    )\n",
    "    lag_targets = [c for c in lag_targets if c in df_out.columns]\n",
    "\n",
    "    # ====== 2) Rolling 통계 (DataFrame 단위) ======\n",
    "    if roll_targets:\n",
    "        X = df_out[roll_targets].shift(1)  # 미래정보 방지\n",
    "\n",
    "        for w in roll_windows:\n",
    "            win_steps = int(w)                 # 30분 단위 steps\n",
    "            minp = max(1, win_steps // 2)\n",
    "\n",
    "            r = X.rolling(win_steps, min_periods=minp)\n",
    "\n",
    "            mean_df = r.mean()\n",
    "            std_df  = r.std(ddof=0)\n",
    "            max_df  = r.max()\n",
    "            min_df  = r.min()\n",
    "\n",
    "            q90_df = r.quantile(0.90)\n",
    "            q10_df = r.quantile(0.10)\n",
    "            iqr_df = q90_df - q10_df\n",
    "\n",
    "            for c in roll_targets:\n",
    "                new_cols[f\"{c}_roll_mean_{w}\"] = mean_df[c]\n",
    "                new_cols[f\"{c}_roll_std_{w}\"]  = std_df[c]\n",
    "                new_cols[f\"{c}_roll_max_{w}\"]  = max_df[c]\n",
    "                new_cols[f\"{c}_roll_min_{w}\"]  = min_df[c]\n",
    "                new_cols[f\"{c}_roll_IQR_{w}\"]  = iqr_df[c]\n",
    "\n",
    "    # ====== 3) Rolling slope (closed-form; stats.linregress 제거) ======\n",
    "    def _rolling_slope_fast(s: pd.Series, window: int) -> pd.Series:\n",
    "        \"\"\"\n",
    "        slope = Σ((t- t̄)(x- x̄)) / Σ((t- t̄)²)\n",
    "        raw=True rolling.apply에서 x만 들어오므로 t는 고정 벡터로 처리\n",
    "        window: 30분 단위 steps\n",
    "        \"\"\"\n",
    "        t = np.arange(window, dtype=float)\n",
    "        t0 = t - t.mean()\n",
    "        denom = float((t0 * t0).sum())\n",
    "        if denom <= 0:\n",
    "            return s.rolling(window, min_periods=window).mean() * np.nan\n",
    "\n",
    "        def _slope(x):\n",
    "            x = np.asarray(x, dtype=float)\n",
    "            if np.any(~np.isfinite(x)):\n",
    "                return np.nan\n",
    "            x0 = x - x.mean()\n",
    "            return float((t0 * x0).sum() / denom)\n",
    "\n",
    "        return s.rolling(window, min_periods=window).apply(_slope, raw=True)\n",
    "\n",
    "    if roll_targets:\n",
    "        for w in slope_windows:\n",
    "            win_steps = int(w)\n",
    "            for c in roll_targets:\n",
    "                # 이미 shift(1)한 X가 있으면 재사용\n",
    "                s = df_out[c].shift(1)\n",
    "                new_cols[f\"{c}_roll_slope_{w}\"] = _rolling_slope_fast(s, win_steps)\n",
    "\n",
    "    # ====== 4) Lag ======\n",
    "    for lag in lags:\n",
    "        lag_steps = int(lag)\n",
    "        for c in lag_targets:\n",
    "            new_cols[f\"{c}_lag_{lag}steps\"] = df_out[c].shift(lag_steps)\n",
    "\n",
    "    # ====== 5) Difference ======\n",
    "    for c in lag_targets:\n",
    "        new_cols[f\"d_{c}\"] = df_out[c].diff()\n",
    "\n",
    "    if \"FLUX_VU\" in df_out.columns:\n",
    "        new_cols[\"abs_d_FLUX_VU\"] = df_out[\"FLUX_VU\"].diff().abs()\n",
    "\n",
    "    # ====== 6) 한 번에 합치기 ======\n",
    "    if new_cols:\n",
    "        df_out = pd.concat([df_out, pd.DataFrame(new_cols, index=df_out.index)], axis=1)\n",
    "\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28ed329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_interaction_features(df):\n",
    "    \"\"\"\n",
    "    상호작용 특성 (성능 개선: new_cols 누적 후 1회 concat)\n",
    "    \"\"\"\n",
    "    df_out = df.copy()\n",
    "    new_cols = {}\n",
    "\n",
    "    station_ids = [\"368\", \"541\", \"569\"]\n",
    "    eps = 1e-9\n",
    "\n",
    "    # ====== 1) 공정 컬럼 캐시 ======\n",
    "    proc_cols = [\"TOC_VU\", \"SS_VU\", \"TN_VU\", \"TP_VU\", \"FLUX_VU\", \"PH_VU\"]\n",
    "    cols = df_out.columns\n",
    "    has_proc = {c: (c in cols) for c in proc_cols}\n",
    "\n",
    "    TOC  = df_out[\"TOC_VU\"]  if has_proc[\"TOC_VU\"]  else None\n",
    "    SS   = df_out[\"SS_VU\"]   if has_proc[\"SS_VU\"]   else None\n",
    "    TN   = df_out[\"TN_VU\"]   if has_proc[\"TN_VU\"]   else None\n",
    "    TP   = df_out[\"TP_VU\"]   if has_proc[\"TP_VU\"]   else None\n",
    "    FLUX = df_out[\"FLUX_VU\"] if has_proc[\"FLUX_VU\"] else None\n",
    "\n",
    "    # ====== 2) 수위/플래그 존재 ======\n",
    "    level_sum_exists  = \"level_sum\" in cols\n",
    "    level_diff_exists = \"level_diff\" in cols\n",
    "\n",
    "    # ====== 3) 강우×수위 (lag1) ======\n",
    "    # shift(1) 재사용\n",
    "    if level_sum_exists:\n",
    "        level_sum_l1 = df_out[\"level_sum\"].shift(1)\n",
    "    else:\n",
    "        level_sum_l1 = None\n",
    "\n",
    "    if level_diff_exists:\n",
    "        level_diff_l1 = df_out[\"level_diff\"].shift(1)\n",
    "    else:\n",
    "        level_diff_l1 = None\n",
    "\n",
    "    rn60_mean = df_out[\"RN_60m_mean\"] if \"RN_60m_mean\" in cols else None\n",
    "    rn15_mean = df_out[\"RN_15m_mean\"] if \"RN_15m_mean\" in cols else None\n",
    "\n",
    "    if rn60_mean is not None and level_sum_l1 is not None:\n",
    "        new_cols[\"rain_x_levelsum_lag1\"] = rn60_mean.shift(1) * level_sum_l1\n",
    "\n",
    "    if rn15_mean is not None and level_sum_l1 is not None:\n",
    "        new_cols[\"rain15_x_levelsum_lag1\"] = rn15_mean.shift(1) * level_sum_l1\n",
    "\n",
    "    if rn60_mean is not None and level_diff_l1 is not None:\n",
    "        new_cols[\"rain_x_leveldiff_lag1\"] = rn60_mean.shift(1) * level_diff_l1\n",
    "\n",
    "    if \"wet_flag\" in cols and level_sum_l1 is not None:\n",
    "        new_cols[\"wet_x_levelsum\"] = df_out[\"wet_flag\"].shift(1) * level_sum_l1\n",
    "\n",
    "    # ====== 4) 지점별 강우 × 공정 ======\n",
    "    for sid in station_ids:\n",
    "        rn15 = f\"RN_15m_{sid}\"\n",
    "        rn60 = f\"RN_60m_{sid}\"\n",
    "\n",
    "        if rn15 in cols:\n",
    "            s15 = df_out[rn15]\n",
    "            if FLUX is not None:\n",
    "                new_cols[f\"RN15m_x_FLUX_{sid}\"] = s15 * FLUX\n",
    "            if SS is not None:\n",
    "                new_cols[f\"RN15_x_SS_{sid}\"] = s15 * SS\n",
    "            if TOC is not None:\n",
    "                new_cols[f\"RN15_x_TOC_{sid}\"] = s15 * TOC\n",
    "\n",
    "        if rn60 in cols:\n",
    "            s60 = df_out[rn60]\n",
    "            if FLUX is not None:\n",
    "                new_cols[f\"RN60m_x_FLUX_{sid}\"] = s60 * FLUX\n",
    "            if SS is not None:\n",
    "                new_cols[f\"RN60_x_SS_{sid}\"] = s60 * SS\n",
    "            if TOC is not None:\n",
    "                new_cols[f\"RN60_x_TOC_{sid}\"] = s60 * TOC\n",
    "\n",
    "    # ====== 5) 공간 평균 강우 × 공정 ======\n",
    "    if rn15_mean is not None:\n",
    "        if SS is not None:\n",
    "            new_cols[\"RN15_mean_x_SS\"] = rn15_mean * SS\n",
    "        if TOC is not None:\n",
    "            new_cols[\"RN15_mean_x_TOC\"] = rn15_mean * TOC\n",
    "        if TN is not None:\n",
    "            new_cols[\"RN15_mean_x_TN\"] = rn15_mean * TN\n",
    "        if TP is not None:\n",
    "            new_cols[\"RN15_mean_x_TP\"] = rn15_mean * TP\n",
    "\n",
    "    if rn60_mean is not None:\n",
    "        if SS is not None:\n",
    "            new_cols[\"RN60_mean_x_SS\"] = rn60_mean * SS\n",
    "        if TOC is not None:\n",
    "            new_cols[\"RN60_mean_x_TOC\"] = rn60_mean * TOC\n",
    "\n",
    "    # ====== 6) 기상 × 공정 ======\n",
    "    for sid in station_ids:\n",
    "        ta = f\"TA_{sid}\"\n",
    "        hm = f\"HM_{sid}\"\n",
    "        td = f\"TD_{sid}\"\n",
    "\n",
    "        if ta in cols:\n",
    "            sTA = df_out[ta]\n",
    "            if TN is not None:\n",
    "                new_cols[f\"TA_x_TN_{sid}\"] = sTA * TN\n",
    "            if TOC is not None:\n",
    "                new_cols[f\"TA_x_TOC_{sid}\"] = sTA * TOC\n",
    "            if FLUX is not None:\n",
    "                new_cols[f\"TA_x_FLUX_{sid}\"] = sTA * FLUX\n",
    "\n",
    "        if hm in cols and SS is not None:\n",
    "            new_cols[f\"HM_x_SS_{sid}\"] = df_out[hm] * SS\n",
    "\n",
    "        # (TA-TD) x TN : TA_minus_TD_{sid}가 이미 만들어져 있을 때만\n",
    "        if (f\"TA_{sid}\" in cols) and (f\"TD_{sid}\" in cols) and (TN is not None):\n",
    "            tadtd = df_out[f\"TA_{sid}\"] - df_out[f\"TD_{sid}\"]\n",
    "            new_cols[f\"(TA-TD)_x_TN_{sid}\"] = tadtd * TN\n",
    "\n",
    "    # ====== 7) 건조기간 × 강우 ======\n",
    "    for sid in station_ids:\n",
    "        dry_hr = f\"dry_hours_{sid}\"\n",
    "        rn15 = f\"RN_15m_{sid}\"\n",
    "        if dry_hr in cols and rn15 in cols:\n",
    "            new_cols[f\"dry_hours_x_RN15m_{sid}\"] = df_out[dry_hr] * df_out[rn15]\n",
    "\n",
    "    if \"dry_hours_mean\" in cols and rn15_mean is not None:\n",
    "        new_cols[\"dry_hours_mean_x_RN15_mean\"] = df_out[\"dry_hours_mean\"] * rn15_mean\n",
    "\n",
    "    # ====== 8) 누적강수 × 공정 ======\n",
    "    for sid in station_ids:\n",
    "        ar12 = f\"AR_12h_{sid}\"\n",
    "        if ar12 in cols:\n",
    "            sAR = df_out[ar12]\n",
    "            if SS is not None:\n",
    "                new_cols[f\"AR12h_x_SS_{sid}\"] = sAR * SS\n",
    "            if TOC is not None:\n",
    "                new_cols[f\"AR12h_x_TOC_{sid}\"] = sAR * TOC\n",
    "\n",
    "    if \"AR_12h_mean_all\" in cols:\n",
    "        ar_mean = df_out[\"AR_12h_mean_all\"]\n",
    "        if SS is not None:\n",
    "            new_cols[\"AR12h_mean_x_SS\"] = ar_mean * SS\n",
    "        if TOC is not None:\n",
    "            new_cols[\"AR12h_mean_x_TOC\"] = ar_mean * TOC\n",
    "\n",
    "    # ====== 9) 공정 지표 간 상호작용 ======\n",
    "    if SS is not None and FLUX is not None:\n",
    "        new_cols[\"SS_x_FLUX\"] = SS * FLUX\n",
    "    if TOC is not None and FLUX is not None:\n",
    "        new_cols[\"TOC_x_FLUX\"] = TOC * FLUX\n",
    "    if TN is not None and TP is not None:\n",
    "        new_cols[\"TN_x_TP\"] = TN * TP\n",
    "\n",
    "    # ====== 10) ARI × 공정 ======\n",
    "    if \"ARI_tau12\" in cols:\n",
    "        ari12 = df_out[\"ARI_tau12\"]\n",
    "        if SS is not None:\n",
    "            new_cols[\"ARI_tau12_x_SS\"] = ari12 * SS\n",
    "        if TOC is not None:\n",
    "            new_cols[\"ARI_tau12_x_TOC\"] = ari12 * TOC\n",
    "\n",
    "    # ====== 마지막: 한 번에 합치기 ======\n",
    "    if new_cols:\n",
    "        df_out = pd.concat([df_out, pd.DataFrame(new_cols, index=df_out.index)], axis=1)\n",
    "\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083f2bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_station_agg_rain_features(df):\n",
    "    station_ids = [\"368\", \"541\", \"569\"]\n",
    "    rain_cols = [c for c in df.columns if c.startswith(\"RN_\")]\n",
    "    df_out = df.copy()\n",
    "\n",
    "    new_cols = {}\n",
    "    eps = 1e-6\n",
    "\n",
    "    # 1) RN_* 지점 통합\n",
    "    for rc in rain_cols:\n",
    "        cols = [f\"{rc}_{sid}\" for sid in station_ids if f\"{rc}_{sid}\" in df_out.columns]\n",
    "        if not cols:\n",
    "            continue\n",
    "\n",
    "        arr = df_out[cols]  # 한 번만 뽑아 재사용\n",
    "\n",
    "        areal_mean = arr.mean(axis=1)\n",
    "        areal_max  = arr.max(axis=1)\n",
    "        areal_std  = arr.std(axis=1, ddof=0)\n",
    "\n",
    "        new_cols[f\"{rc}_areal_mean\"] = areal_mean\n",
    "        new_cols[f\"{rc}_areal_max\"]  = areal_max\n",
    "        new_cols[f\"{rc}_areal_max_minus_mean\"] = areal_max - areal_mean\n",
    "        new_cols[f\"{rc}_areal_std\"]  = areal_std\n",
    "\n",
    "    # 2) AR_12h 통합 (원본 df_out 기준 + 혹시 new_cols에 있을 수도 있으니 tmp로 안전 처리)\n",
    "    df_tmp = df_out\n",
    "    if new_cols:\n",
    "        df_tmp = pd.concat([df_out, pd.DataFrame(new_cols, index=df_out.index)], axis=1)\n",
    "\n",
    "    ar12_cols = [f\"AR_12h_{sid}\" for sid in station_ids if f\"AR_12h_{sid}\" in df_tmp.columns]\n",
    "    if ar12_cols:\n",
    "        new_cols[\"AR_12h_sum_all\"] = df_tmp[ar12_cols].sum(axis=1)\n",
    "        new_cols[\"AR_12h_mean_all\"] = df_tmp[ar12_cols].mean(axis=1)\n",
    "\n",
    "    # 3) 비율 특성\n",
    "    rn15_mean = f\"RN_15m_areal_mean\"\n",
    "    rn60_mean = f\"RN_60m_areal_mean\"\n",
    "    if rn15_mean in df_tmp.columns and rn60_mean in df_tmp.columns:\n",
    "        new_cols[\"RN_15m_div_RN_60m_areal_mean\"] = df_tmp[rn15_mean] / (df_tmp[rn60_mean] + eps)\n",
    "\n",
    "    # 4) 마지막에 한 번에 합치기\n",
    "    if new_cols:\n",
    "        df_out = pd.concat([df_out, pd.DataFrame(new_cols, index=df_out.index)], axis=1)\n",
    "\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3e26a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weather_features(df):\n",
    "    df_out = df.copy()\n",
    "    station_ids = [\"368\", \"541\", \"569\"]\n",
    "\n",
    "    new_cols = {}\n",
    "\n",
    "    for sid in station_ids:\n",
    "        ta = f\"TA_{sid}\"\n",
    "        td = f\"TD_{sid}\"\n",
    "        hm = f\"HM_{sid}\"\n",
    "\n",
    "        # Dewpoint depression\n",
    "        if ta in df_out.columns and td in df_out.columns:\n",
    "            new_cols[f\"TA_minus_TD_{sid}\"] = df_out[ta] - df_out[td]\n",
    "\n",
    "        # VPD (kPa)\n",
    "        if ta in df_out.columns and hm in df_out.columns:\n",
    "            T = df_out[ta].astype(\"float64\")\n",
    "            RH = df_out[hm].astype(\"float64\").clip(0.0, 100.0)\n",
    "\n",
    "            e_s = 0.6108 * np.exp((17.27 * T) / (T + 237.3))  # saturation vapor pressure\n",
    "            new_cols[f\"VPD_{sid}\"] = e_s * (1.0 - RH / 100.0)\n",
    "\n",
    "    if new_cols:\n",
    "        df_out = pd.concat([df_out, pd.DataFrame(new_cols, index=df_out.index)], axis=1)\n",
    "\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ad840f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features(df):\n",
    "    df_out = df.copy()\n",
    "    idx = df_out.index\n",
    "\n",
    "    # DatetimeIndex 전제(아니면 여기서 에러 나게 두는 게 디버깅에 유리)\n",
    "    hour = idx.hour\n",
    "    dow = idx.dayofweek\n",
    "    month = idx.month\n",
    "    doy = idx.dayofyear\n",
    "\n",
    "    new_cols = {\n",
    "        \"hour\": hour,\n",
    "        \"dayofweek\": dow,\n",
    "        \"month\": month,\n",
    "        \"is_weekend\": np.isin(dow, [5, 6]).astype(np.int8),\n",
    "        \"hour_sin\": np.sin(2.0 * np.pi * hour / 24.0),\n",
    "        \"hour_cos\": np.cos(2.0 * np.pi * hour / 24.0),\n",
    "        \"doy_sin\": np.sin(2.0 * np.pi * doy / 365.25),\n",
    "        \"doy_cos\": np.cos(2.0 * np.pi * doy / 365.25),\n",
    "    }\n",
    "\n",
    "    df_out = pd.concat([df_out, pd.DataFrame(new_cols, index=idx)], axis=1)\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8f552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 데이터 누수(Data Leakage) 방지 검증 ======\n",
    "# MODE별 타겟과 타겟이 아닌 프로세스 변수 명시\n",
    "\n",
    "DATA_LEAKAGE_CONFIG = {\n",
    "    \"flow\": {\n",
    "        \"target\": [\"Q_in\"],\n",
    "        # FLOW는 독립적인 변수이므로 다른 프로세스 변수 포함 가능\n",
    "        \"safe_process_features\": [\"FLUX_VU\", \"TOC_VU\", \"SS_VU\", \"TN_VU\", \"TP_VU\", \"PH_VU\"]\n",
    "    },\n",
    "    \"toc\": {\n",
    "        \"target\": [\"TOC_VU\"],\n",
    "        # TOC 예측 시 동시 측정되는 다른 TMS 지표는 제외\n",
    "        \"safe_process_features\": [\"FLUX_VU\"]  # FLUX만 사용 (다른 TMS 지표 제외)\n",
    "    },\n",
    "    \"ss\": {\n",
    "        \"target\": [\"SS_VU\"],\n",
    "        \"safe_process_features\": [\"FLUX_VU\"]\n",
    "    },\n",
    "    \"tn\": {\n",
    "        \"target\": [\"TN_VU\"],\n",
    "        \"safe_process_features\": [\"FLUX_VU\"]\n",
    "    },\n",
    "    \"tp\": {\n",
    "        \"target\": [\"TP_VU\"],\n",
    "        \"safe_process_features\": [\"FLUX_VU\"]\n",
    "    },\n",
    "    \"flux\": {\n",
    "        \"target\": [\"FLUX_VU\"],\n",
    "        \"safe_process_features\": [\"Q_in\"]  # 유입량만 사용 (TMS 제외)\n",
    "    },\n",
    "    \"ph\": {\n",
    "        \"target\": [\"PH_VU\"],\n",
    "        \"safe_process_features\": [\"FLUX_VU\"]\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"데이터 누수(Data Leakage) 설정\")\n",
    "print(\"=\"*70)\n",
    "for mode, config in DATA_LEAKAGE_CONFIG.items():\n",
    "    print(f\"\\n[{mode.upper()}]\")\n",
    "    print(f\"  타겟: {config['target']}\")\n",
    "    print(f\"  안전한 프로세스 특성: {config['safe_process_features']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aa4192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(dfs):\n",
    "    # 시간 축 정렬\n",
    "    aligned_dfs = align_data(dfs)\n",
    "\n",
    "    # 데이터 병합(flow, tms)\n",
    "    merged_dfs = merge_data(aligned_dfs)\n",
    "\n",
    "    # 결측치 처리\n",
    "    imputed_dfs, mask_imputed_dfs = imputate_data(merged_dfs)\n",
    "\n",
    "    # 이상치 처리\n",
    "    processed_dfs, mask_process_dfs = handle_outliers(imputed_dfs)\n",
    "\n",
    "    # 리샘플링\n",
    "    resample_dfs = {}\n",
    "    for name, df in processed_dfs.items():\n",
    "        resample_dfs[name] = resample_data(df, freq=\"30min\")\n",
    "\n",
    "    mode = MODE\n",
    "\n",
    "    MODE_CFG = {\n",
    "        \"flow\": (\"flow\", [FLOW_TARGET]),\n",
    "        \"toc\":  (\"tms\",  [TOC_TARGET]),\n",
    "        \"ss\":   (\"tms\",  [SS_TARGET]),\n",
    "        \"tn\":   (\"tms\",  [TN_TARGET]),\n",
    "        \"tp\":   (\"tms\",  [TP_TARGET]),\n",
    "        \"flux\": (\"tms\",  [FLUX_TARGET]),\n",
    "        \"ph\":   (\"tms\",  [PH_TARGET]),\n",
    "    }\n",
    "\n",
    "    if mode not in MODE_CFG:\n",
    "        raise ValueError(f\"Unknown MODE: {mode}\")\n",
    "    \n",
    "    source_key, target_col = MODE_CFG[mode]\n",
    "\n",
    "    for name, df0 in resample_dfs.items():\n",
    "        df = df0.loc[:, ~df0.columns.duplicated()].copy()\n",
    "\n",
    "        if name == \"flow\":\n",
    "            df = df.drop(columns=[\"flow_TankA\", \"flow_TankB\"], errors=\"ignore\")\n",
    "\n",
    "        tgt_in_df = [c for c in target_col if c in df.columns]\n",
    "        if tgt_in_df:\n",
    "            y_part = df[tgt_in_df].copy()\n",
    "            base = df.drop(columns=tgt_in_df)\n",
    "        else:\n",
    "            y_part = None\n",
    "            base = df\n",
    "\n",
    "        # ====== 데이터 누수 방지: 타겟이 아닌 프로세스 변수 제외 ======\n",
    "        if mode in DATA_LEAKAGE_CONFIG:\n",
    "            # 모든 프로세스 변수 중 타겟이 아니면서 안전 목록에 없는 변수 제거\n",
    "            all_process_vars = [\"TOC_VU\", \"SS_VU\", \"TN_VU\", \"TP_VU\", \"FLUX_VU\", \"PH_VU\"]\n",
    "            target_vars = set(DATA_LEAKAGE_CONFIG[mode][\"target\"])\n",
    "            safe_vars = set(DATA_LEAKAGE_CONFIG[mode][\"safe_process_features\"])\n",
    "            \n",
    "            # 타겟도 아니고 안전한 목록에도 없는 변수들 제거\n",
    "            unsafe_vars = [v for v in all_process_vars if v not in target_vars and v not in safe_vars and v in base.columns]\n",
    "            if unsafe_vars:\n",
    "                print(f\"  ⚠️ 데이터 누수 방지 ({name}): {unsafe_vars} 제외\")\n",
    "                base = base.drop(columns=unsafe_vars)\n",
    "\n",
    "        base = add_rain_features(base)\n",
    "        base = add_station_agg_rain_features(base)\n",
    "        base = add_weather_features(base)\n",
    "        base = add_process_features(base)\n",
    "        base = add_temporal_features(base)\n",
    "        # base = add_interaction_features(base)\n",
    "        base = add_time_features(base)\n",
    "\n",
    "        if y_part is not None:\n",
    "            df_fe = base.join(y_part, how=\"left\")\n",
    "        else:\n",
    "            df_fe = base\n",
    "\n",
    "        resample_dfs[name] = df_fe.dropna()\n",
    "\n",
    "    source_data = resample_dfs[source_key]\n",
    "\n",
    "    # ====== 1단계: 전체 특성 추출 (Walk-Forward 실행용) ======\n",
    "    X_all = source_data.drop(columns=target_col).values\n",
    "    y = source_data[target_col]\n",
    "    \n",
    "    # 실제 컬럼명 저장 (시각화/분석용)\n",
    "    feature_names_all = source_data.drop(columns=target_col).columns.tolist()\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"전체 특성 정보\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"전체 특성 수: {len(feature_names_all)}\")\n",
    "    print(f\"샘플 수: {len(X_all)}\")\n",
    "    print(f\"타겟 개수: {y.shape[1]}\")\n",
    "\n",
    "    # ====== 2단계: Walk-Forward Validation 실행 ======\n",
    "    wf_selector = wf_fs.WalkForwardFeatureSelector(\n",
    "        X=X_all,\n",
    "        y=y,\n",
    "        feature_names=feature_names_all,  # ← 실제 컬럼명 사용\n",
    "        n_splits=5,\n",
    "        train_size=700,    # 350시간 (30분 단위: 700 steps = 약 14일)\n",
    "        val_size=200,      # 100시간 (30분 단위: 200 steps = 약 4일)\n",
    "        test_size=200,     # 100시간 (30분 단위: 200 steps = 약 4일)\n",
    "        window_step=200,   # 100시간마다 이동 (30분 단위: 200 steps)\n",
    "    )\n",
    "\n",
    "    results = wf_selector.run(model_type=\"rf\", verbose=True)\n",
    "\n",
    "    # ====== 3단계: 결과 분석 ======\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"WALK-FORWARD VALIDATION 결과 요약\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"원본 특성: {results['n_features_original']}\")\n",
    "    print(f\"선택된 특성 (평균): {results['n_selected_mean']:.1f} ± {results['n_selected_std']:.1f}\")\n",
    "    print(f\"특성 감소율: {(1 - results['n_selected_mean']/results['n_features_original'])*100:.1f}%\")\n",
    "    print(f\"\\n안정적 특성 (모든 폴드에서 선택): {len(results['stable_features'])}\")\n",
    "\n",
    "    # ====== 4단계: 추천 특성 선택 ======\n",
    "    recommended_idx = wf_selector.get_recommended_features(stability_ratio=0.6)\n",
    "    recommended_names = [feature_names_all[i] for i in recommended_idx]\n",
    "    \n",
    "    print(f\"\\n추천 특성 (60%+ 안정성): {len(recommended_idx)}\")\n",
    "    print(f\"특성 개수: {len(recommended_idx)}/{len(feature_names_all)}\")\n",
    "    print(f\"\\n추천 특성 목록:\")\n",
    "    for i, (idx, name) in enumerate(zip(recommended_idx, recommended_names), 1):\n",
    "        print(f\"  {i:3d}. [{idx:3d}] {name}\")\n",
    "\n",
    "    # ====== 5단계: 추천 특성으로 X 필터링 ======\n",
    "    X = X_all[:, recommended_idx]  # ← 추천 특성만 선택\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"특성 선택 완료\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"원본 X shape: {X_all.shape}\")\n",
    "    print(f\"필터링된 X shape: {X.shape}\")\n",
    "    print(f\"선택률: {X.shape[1]/X_all.shape[1]*100:.1f}%\")\n",
    "\n",
    "    # ====== 6단계: 결과 저장 (선택사항) ======\n",
    "    # 추천 특성 정보 저장\n",
    "    recommended_df = pd.DataFrame({\n",
    "        \"index\": recommended_idx,\n",
    "        \"feature_name\": recommended_names,\n",
    "    })\n",
    "    RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    recommended_df.to_csv(\n",
    "        RESULTS_DIR / f\"{MODE}_recommended_features.csv\", \n",
    "        index=False\n",
    "    )\n",
    "    print(f\"\\n✓ 추천 특성 저장: {RESULTS_DIR / f'{MODE}_recommended_features.csv'}\")\n",
    "\n",
    "    return X, y, recommended_idx, feature_names_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066bfc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesWindowDataset(Dataset):\n",
    "    def __init__(self, X, y, window_size, horizon):\n",
    "        self.X = np.asarray(X, dtype=np.float32)\n",
    "        self.y = np.asarray(y, dtype=np.float32)\n",
    "        self.window_size = window_size\n",
    "        self.horizon = horizon\n",
    "\n",
    "        if self.y.ndim == 1:\n",
    "            self.y = self.y[:, None]\n",
    "\n",
    "        self.max_start = len(self.X) - self.window_size - self.horizon + 1\n",
    "        if self.max_start <= 0:\n",
    "            raise ValueError(\"데이터 길이가 window_size + horizon 보다 짧습니다.\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.max_start\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # ====== 미래 정보 누수(Future Leakage) 방지 검증 ======\n",
    "        # x_seq: 과거 window_size개 시점 (idx ~ idx+window_size-1)\n",
    "        # y_t: 미래 horizon 시점 (idx+window_size+horizon-1)\n",
    "        # horizon=1이므로 y_t는 x_seq 이후의 값 → 미래 정보 누수 없음 ✓\n",
    "        \n",
    "        x_seq = self.X[idx : idx + self.window_size]  # 과거 데이터 (현재까지)\n",
    "        y_t = self.y[idx + self.window_size + self.horizon - 1]  # 미래 데이터 (예측 대상)\n",
    "        y_t = np.asarray(y_t, dtype=np.float32).reshape(-1)\n",
    "        return torch.from_numpy(x_seq), torch.from_numpy(y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be818ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 데이터 누수(Data Leakage) 최종 검증 ======\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"데이터 누수 점검 보고서\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n✓ 1) 타겟 컬럼 분리\")\n",
    "print(f\"   - MODE: {MODE}\")\n",
    "print(f\"   - 타겟: {DATA_LEAKAGE_CONFIG[MODE]['target']}\")\n",
    "print(f\"   - 안전한 프로세스 특성: {DATA_LEAKAGE_CONFIG[MODE]['safe_process_features']}\")\n",
    "print(f\"   - 제외된 특성: {[v for v in ['TOC_VU', 'SS_VU', 'TN_VU', 'TP_VU', 'FLUX_VU', 'PH_VU'] if v not in DATA_LEAKAGE_CONFIG[MODE]['target'] and v not in DATA_LEAKAGE_CONFIG[MODE]['safe_process_features']]}\")\n",
    "\n",
    "print(\"\\n✓ 2) 시계열 윈도우 구성 (미래 정보 누수 확인)\")\n",
    "print(f\"   - 슬라이딩 윈도우 크기 (WINDOW_SIZE): {WINDOW_SIZE} 스텝 (30분 단위)\")\n",
    "print(f\"   - 예측 지평 (HORIZON): {HORIZON} 스텝\")\n",
    "print(f\"   - X 범위: [t, t+{WINDOW_SIZE}-1]\")\n",
    "print(f\"   - y 범위: [t+{WINDOW_SIZE}+{HORIZON}-1]\")\n",
    "print(f\"   - 결론: X와 y 사이의 시간 간격 ✓ 미래 정보 누수 없음\")\n",
    "\n",
    "print(\"\\n✓ 3) 시간 특성 엔지니어링\")\n",
    "print(f\"   - add_temporal_features() 사용:\")\n",
    "print(f\"     • shift(1) 적용 → 미래 정보 방지 ✓\")\n",
    "print(f\"     • Lag 특성: lag=1~72스텝 (과거만) ✓\")\n",
    "print(f\"     • Rolling 특성: 윈도우 내 과거 데이터만 사용 ✓\")\n",
    "\n",
    "print(\"\\n✓ 4) 강우 누적 특성 (Antecedent Rainfall)\")\n",
    "print(f\"   - steps_per_hour = 2 (30분 리샘플링)\")\n",
    "print(f\"   - 누적강우 산출: 과거 데이터만 사용 ✓\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"결론: 데이터 누수 위험 최소화 ✓\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "78981a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMRegressor(nn.Module):\n",
    "    def __init__(self, n_features, hidden_size = 64, num_layers = 2, dropout = 0.2, out_size = 1):\n",
    "        super(LSTMRegressor, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size = n_features,\n",
    "            hidden_size = hidden_size,\n",
    "            num_layers = num_layers,\n",
    "            batch_first = True,\n",
    "            dropout = dropout if num_layers > 1 else 0.0,\n",
    "        )\n",
    "\n",
    "        lstm_out_size = hidden_size\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=lstm_out_size,\n",
    "            num_heads=4,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(lstm_out_size, lstm_out_size * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(lstm_out_size * 2, lstm_out_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(lstm_out_size, out_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        attn_out, _ = self.attention(lstm_out, lstm_out, lstm_out)\n",
    "        \n",
    "        last = attn_out[:, -1, :]\n",
    "        yhat = self.head(last)\n",
    "        return yhat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1301a020",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberLoss(nn.Module):\n",
    "    \"\"\"이상치에 강건한 손실 함수\"\"\"\n",
    "    def __init__(self, delta=1.0):\n",
    "        super().__init__()\n",
    "        self.delta = delta\n",
    "    \n",
    "    def forward(self, preds, targets):\n",
    "        diff = torch.abs(preds - targets)\n",
    "        huber = torch.where(\n",
    "            diff <= self.delta,\n",
    "            0.5 * diff ** 2,\n",
    "            self.delta * (diff - 0.5 * self.delta)\n",
    "        )\n",
    "        return huber.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9f324a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    criterion, \n",
    "    optimizer, \n",
    "    scheduler = None, \n",
    "    num_epochs = TRAINING_CONFIG[\"num_epochs\"], \n",
    "    patience = TRAINING_CONFIG[\"patience\"],\n",
    "    device = \"cpu\",\n",
    "    save_path = None\n",
    "):\n",
    "    train_loss_history = []\n",
    "    train_mae_history = []\n",
    "    train_rmse_history = []\n",
    "    train_mape_history = []\n",
    "    val_loss_history = []\n",
    "    val_mae_history = []\n",
    "    val_rmse_history = []\n",
    "    val_mape_history = []\n",
    "    \n",
    "    best_val_rmse = float(\"inf\")\n",
    "    best_model_state = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        epoch_mae = 0.0\n",
    "        epoch_mse = 0.0\n",
    "        epoch_mape = 0.0\n",
    "        train_total = 0\n",
    "\n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
    "        for X, y in train_pbar:\n",
    "            X, y = X.to(device).float(), y.to(device).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(X)\n",
    "\n",
    "            # ← 차원 처리 수정: batch_size x output_size 유지\n",
    "            if preds.dim() > 2:\n",
    "                preds = preds.squeeze(1)\n",
    "            if y.dim() > 2:\n",
    "                y = y.squeeze(1)\n",
    "\n",
    "            loss = criterion(preds, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_size = y.size(0)\n",
    "            train_total += batch_size\n",
    "            epoch_loss += loss.item() * batch_size\n",
    "\n",
    "            with torch.no_grad():\n",
    "                err = preds - y\n",
    "                abs_err = err.abs()\n",
    "                epoch_mae += abs_err.sum().item()\n",
    "                epoch_mse += (err ** 2).sum().item()\n",
    "\n",
    "                # MAPE는 1D 데이터만 처리\n",
    "                if y.dim() == 1:\n",
    "                    denom = y.abs().clamp_min(1e-6)\n",
    "                    epoch_mape += (abs_err / denom).sum().item()\n",
    "\n",
    "            train_pbar.set_postfix({\n",
    "                \"loss\": f\"{loss.item():.4f}\",\n",
    "                \"mae\": f\"{abs_err.mean().item():.4f}\",\n",
    "                \"rmse\": f\"{err.pow(2).mean().sqrt().item():.4f}\",\n",
    "            })\n",
    "\n",
    "        avg_loss = epoch_loss / train_total\n",
    "        mae = epoch_mae /train_total\n",
    "        rmse = (epoch_mse / train_total) ** 0.5\n",
    "        mape = 100.0 * (epoch_mape / train_total)\n",
    "\n",
    "        train_loss_history.append(avg_loss)\n",
    "        train_mae_history.append(mae)\n",
    "        train_rmse_history.append(rmse)\n",
    "        train_mape_history.append(mape)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_mae = 0.0\n",
    "        val_mse = 0.0\n",
    "        val_mape = 0.0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\")\n",
    "            for X, y in val_pbar:\n",
    "                X, y = X.to(device).float(), y.to(device).float()\n",
    "                outs = model(X)\n",
    "\n",
    "                # ← 차원 처리 수정: batch_size x output_size 유지\n",
    "                if outs.dim() > 2:\n",
    "                    outs = outs.squeeze(1)\n",
    "                if y.dim() > 2:\n",
    "                    y = y.squeeze(1)\n",
    "                \n",
    "                loss = criterion(outs, y)\n",
    "\n",
    "                batch_size = y.size(0)\n",
    "                val_total += batch_size\n",
    "                val_loss += loss.item() * batch_size\n",
    "\n",
    "                err = outs - y\n",
    "                abs_err = err.abs()\n",
    "                val_mae += abs_err.sum().item()\n",
    "                val_mse += (err ** 2).sum().item()\n",
    "\n",
    "                # MAPE는 1D 데이터만 처리\n",
    "                if y.dim() == 1:\n",
    "                    denom = y.abs().clamp_min(1e-6)\n",
    "                    val_mape += (abs_err / denom).sum().item()\n",
    "\n",
    "                val_pbar.set_postfix({\n",
    "                    \"loss\": f\"{loss.item():.4f}\",\n",
    "                    \"mae\": f\"{abs_err.mean().item():.4f}\",\n",
    "                    \"rmse\": f\"{err.pow(2).mean().sqrt().item():.4f}\",\n",
    "                })\n",
    "\n",
    "        v_loss = val_loss / val_total\n",
    "        v_mae = val_mae / val_total\n",
    "        v_rmse = (val_mse / val_total) ** 0.5\n",
    "        v_mape = 100.0 * (val_mape / val_total)\n",
    "\n",
    "        val_loss_history.append(v_loss)\n",
    "        val_mae_history.append(v_mae)\n",
    "        val_rmse_history.append(v_rmse)\n",
    "        val_mape_history.append(v_mape)\n",
    "\n",
    "        # 에포크 종료 후 메트릭 출력\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs} Summary:\")\n",
    "        print(f\"  Train - Loss: {avg_loss:.4f}, MAE: {mae:.4f}, RMSE: {rmse:.4f}, MAPE: {mape:.2f}%\")\n",
    "        print(f\"  Val   - Loss: {v_loss:.4f}, MAE: {v_mae:.4f}, RMSE: {v_rmse:.4f}, MAPE: {v_mape:.2f}%\")\n",
    "\n",
    "        if scheduler is not None:\n",
    "            if hasattr(scheduler, \"step\") and scheduler.__class__.__name__ == \"ReduceLROnPlateau\":\n",
    "                scheduler.step(v_rmse)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "\n",
    "        # Early Stopping 및 Best Model 저장\n",
    "        if v_rmse < best_val_rmse:\n",
    "            best_val_rmse = v_rmse\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            patience_counter = 0\n",
    "            print(f\"  ✓ New best model! Val RMSE: {best_val_rmse:.4f}\")\n",
    "            \n",
    "            # 최적 모델 저장\n",
    "            if save_path is not None:\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': best_model_state,\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'val_rmse': best_val_rmse,\n",
    "                    'train_history': {\n",
    "                        'train_loss': train_loss_history,\n",
    "                        'train_mae': train_mae_history,\n",
    "                        'train_rmse': train_rmse_history,\n",
    "                        'train_mape': train_mape_history,\n",
    "                        'val_loss': val_loss_history,\n",
    "                        'val_mae': val_mae_history,\n",
    "                        'val_rmse': val_rmse_history,\n",
    "                        'val_mape': val_mape_history,\n",
    "                    }\n",
    "                }, save_path)\n",
    "                print(f\"  ✓ Model saved to {save_path}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"  No improvement. Patience: {patience_counter}/{patience}\")\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                print(f\"\\n⚠ Early stopping triggered after {epoch+1} epochs\")\n",
    "                break\n",
    "\n",
    "    # 최적 모델 로드\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(f\"\\n✓ Loaded best model with Val RMSE: {best_val_rmse:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"train_loss\": train_loss_history,\n",
    "        \"train_mae\": train_mae_history,\n",
    "        \"train_rmse\": train_rmse_history,\n",
    "        \"train_mape\": train_mape_history,\n",
    "        \"val_loss\": val_loss_history,\n",
    "        \"val_mae\": val_mae_history,\n",
    "        \"val_rmse\": val_rmse_history,\n",
    "        \"val_mape\": val_mape_history,\n",
    "        \"best_val_rmse\": best_val_rmse,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6b96a2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion = None, device = \"cpu\", return_arrays = True):\n",
    "    model.eval()\n",
    "\n",
    "    if criterion is None:\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "    preds_all = []\n",
    "    y_all = []\n",
    "\n",
    "    total_loss_sum = 0.0\n",
    "    mae_sum = 0.0\n",
    "    mse_sum = 0.0\n",
    "    mape_sum = 0.0\n",
    "    n_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(test_loader, desc = \"[Test]\")\n",
    "        for X, y in pbar:\n",
    "            X = X.to(device).float()\n",
    "            y = y.to(device).float()\n",
    "\n",
    "            preds = model(X)\n",
    "\n",
    "            if preds.dim() > 2:\n",
    "                preds = preds.squeeze(1)\n",
    "            if y.dim() > 2:\n",
    "                y = y.squeeze(1)\n",
    "\n",
    "            loss = criterion(preds, y)\n",
    "\n",
    "            batch_size = y.size(0)\n",
    "            n_samples += batch_size\n",
    "            total_loss_sum += loss.item() * batch_size\n",
    "\n",
    "            err = preds - y\n",
    "            abs_err = err.abs()\n",
    "            \n",
    "            mae_sum += abs_err.sum().item()\n",
    "            mse_sum += (err ** 2).sum().item()\n",
    "\n",
    "            denom = y.abs().clamp_min(1e-6)\n",
    "            mape_sum += (abs_err / denom).sum().item()\n",
    "\n",
    "            pbar.set_postfix({\n",
    "                \"loss\": f\"{loss.item():.4f}\",\n",
    "                \"mae\": f\"{abs_err.mean().item():.4f}\",\n",
    "                \"rmse\": f\"{err.pow(2).mean().sqrt().item():.4f}\",\n",
    "            })\n",
    "\n",
    "            if return_arrays:\n",
    "                preds_all.append(preds.detach().cpu())\n",
    "                y_all.append(y.detach().cpu())\n",
    "\n",
    "    avg_loss = total_loss_sum / n_samples\n",
    "    mae = mae_sum / n_samples\n",
    "    rmse = (mse_sum / n_samples) ** 0.5\n",
    "    mape = 100.0 * (mape_sum / n_samples)\n",
    "\n",
    "    r2 = None\n",
    "    if return_arrays and len(y_all) > 0:\n",
    "        y_cat = torch.cat(y_all).numpy()\n",
    "        p_cat = torch.cat(preds_all).numpy()\n",
    "        # 다중 출력일 경우 각 출력별 R² 계산\n",
    "        if y_cat.ndim > 1:\n",
    "            r2_list = []\n",
    "            for i in range(y_cat.shape[1]):\n",
    "                ss_res = np.sum((y_cat[:, i] - p_cat[:, i]) ** 2)\n",
    "                ss_tot = np.sum((y_cat[:, i] - np.mean(y_cat[:, i])) ** 2)\n",
    "                r2_i = 1.0 - (ss_res / ss_tot) if ss_tot > 0 else None\n",
    "                r2_list.append(r2_i)\n",
    "            r2 = r2_list\n",
    "        else:\n",
    "            ss_res = np.sum((y_cat - p_cat) ** 2)\n",
    "            ss_tot = np.sum((y_cat - np.mean(y_cat)) ** 2)\n",
    "            r2 = 1.0 - (ss_res / ss_tot) if ss_tot > 0 else None\n",
    "\n",
    "    print(\"\\n=== 테스트 세트 평가(회귀) ===\")\n",
    "    print(f\"Loss: {avg_loss:.4f}\")\n",
    "    print(f\"MAE : {mae:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAPE: {mape:.2f}%\")\n",
    "    if r2 is not None:\n",
    "        if isinstance(r2, list):\n",
    "            for i, r2_val in enumerate(r2):\n",
    "                print(f\"R² (Output {i+1}): {r2_val:.4f}\")\n",
    "        else:\n",
    "            print(f\"R²  : {r2:.4f}\")\n",
    "\n",
    "    if return_arrays:\n",
    "        predictions = torch.cat(preds_all).numpy()\n",
    "        actuals = torch.cat(y_all).numpy()\n",
    "        return predictions, actuals, {\"loss\": avg_loss, \"mae\": mae, \"rmse\": rmse, \"mape\": mape, \"r2\": r2}\n",
    "    else:\n",
    "        return {\"loss\": avg_loss, \"mae\": mae, \"rmse\": rmse, \"mape\": mape, \"r2\": r2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2f2561bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(\n",
    "    train_loss, \n",
    "    train_mae, \n",
    "    train_rmse, \n",
    "    train_mape,\n",
    "    val_loss=None, \n",
    "    val_mae=None, \n",
    "    val_rmse=None, \n",
    "    val_mape=None,\n",
    "    title=\"Training Progress (Regression)\"\n",
    "):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 8))\n",
    "    ax_loss, ax_mae, ax_rmse, ax_mape = axes[0,0], axes[0,1], axes[1,0], axes[1,1]\n",
    "\n",
    "    # Loss\n",
    "    ax_loss.plot(train_loss, linewidth=2, label=\"Train Loss\")\n",
    "    if val_loss is not None and len(val_loss) > 0:\n",
    "        ax_loss.plot(val_loss, linewidth=2, label=\"Val Loss\")\n",
    "    ax_loss.set_title(\"Loss\")\n",
    "    ax_loss.set_xlabel(\"Epoch\"); ax_loss.set_ylabel(\"Loss\")\n",
    "    ax_loss.legend()\n",
    "    ax_loss.grid(True, alpha=0.3)\n",
    "\n",
    "    # MAE\n",
    "    ax_mae.plot(train_mae, linewidth=2, label=\"Train MAE\")\n",
    "    if val_mae is not None and len(val_mae) > 0:\n",
    "        ax_mae.plot(val_mae, linewidth=2, label=\"Val MAE\")\n",
    "    ax_mae.set_title(\"MAE\")\n",
    "    ax_mae.set_xlabel(\"Epoch\"); ax_mae.set_ylabel(\"MAE\")\n",
    "    ax_mae.legend()\n",
    "    ax_mae.grid(True, alpha=0.3)\n",
    "\n",
    "    # RMSE\n",
    "    ax_rmse.plot(train_rmse, linewidth=2, label=\"Train RMSE\")\n",
    "    if val_rmse is not None and len(val_rmse) > 0:\n",
    "        ax_rmse.plot(val_rmse, linewidth=2, label=\"Val RMSE\")\n",
    "    ax_rmse.set_title(\"RMSE\")\n",
    "    ax_rmse.set_xlabel(\"Epoch\"); ax_rmse.set_ylabel(\"RMSE\")\n",
    "    ax_rmse.legend()\n",
    "    ax_rmse.grid(True, alpha=0.3)\n",
    "\n",
    "    # MAPE (1D 데이터만 표시)\n",
    "    # ← 다중 출력일 경우 MAPE는 NaN이 될 수 있으므로 필터링\n",
    "    train_mape_valid = [x for x in train_mape if not np.isnan(x) and not np.isinf(x)]\n",
    "    val_mape_valid = [x for x in val_mape if not np.isnan(x) and not np.isinf(x)] if val_mape is not None else []\n",
    "    \n",
    "    if len(train_mape_valid) > 0:\n",
    "        ax_mape.plot(train_mape_valid, linewidth=2, label=\"Train MAPE\")\n",
    "    if val_mape_valid is not None and len(val_mape_valid) > 0:\n",
    "        ax_mape.plot(val_mape_valid, linewidth=2, label=\"Val MAPE\")\n",
    "    \n",
    "    ax_mape.set_title(\"MAPE (%) - 1D 데이터만\")\n",
    "    ax_mape.set_xlabel(\"Epoch\")\n",
    "    ax_mape.set_ylabel(\"MAPE (%)\")\n",
    "    ax_mape.legend()\n",
    "    ax_mape.grid(True, alpha=0.3)\n",
    "\n",
    "    fig.suptitle(title, fontsize=14, fontweight=\"bold\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "eb3806eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_timewise(X, y, ratio = SPLIT_RATIOS):\n",
    "    T = len(X)\n",
    "    n_train = int(T * ratio[\"train\"])\n",
    "    n_val = int(T * ratio[\"val\"])\n",
    "\n",
    "    X_train, y_train = X[:n_train], y[:n_train]\n",
    "    X_val, y_val = X[n_train : n_train + n_val], y[n_train : n_train + n_val]\n",
    "    X_test, y_test = X[n_train + n_val : ], y[n_train + n_val : ]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3740eab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_and_fix(name, arr):\n",
    "        arr = np.asarray(arr, dtype=np.float32)\n",
    "        n_nan = np.isnan(arr).sum()\n",
    "        n_inf = np.isinf(arr).sum()\n",
    "        print(f\"{name}: shape={arr.shape}, n_nan={n_nan}, n_inf={n_inf}\")\n",
    "        if n_nan > 0 or n_inf > 0:\n",
    "            # 컬럼별 평균으로 NaN 대체 (모두 NaN이면 0으로 대체)\n",
    "            if arr.ndim == 1:\n",
    "                col_mean = np.nanmean(arr)\n",
    "                if np.isnan(col_mean):\n",
    "                    col_mean = 0.0\n",
    "                arr = np.where(np.isfinite(arr), arr, col_mean).astype(np.float32)\n",
    "            else:\n",
    "                col_mean = np.nanmean(arr, axis=0)\n",
    "                col_mean = np.where(np.isnan(col_mean), 0.0, col_mean)\n",
    "                inds = np.where(~np.isfinite(arr))\n",
    "                if inds[0].size > 0:\n",
    "                    arr[inds] = col_mean[inds[1]]\n",
    "            print(f\"  -> fixed {name}: n_nan now {np.isnan(arr).sum()}, n_inf now {np.isinf(arr).sum()}\")\n",
    "        return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "03464119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "\n",
    "    x_scaler = StandardScaler().fit(X_train)\n",
    "    y_scaler = StandardScaler().fit(y_train)\n",
    "\n",
    "    X_train_scaled = x_scaler.transform(X_train)\n",
    "    X_val_scaled = x_scaler.transform(X_val)\n",
    "    X_test_scaled = x_scaler.transform(X_test)\n",
    "\n",
    "    y_train_scaled = y_scaler.transform(y_train)\n",
    "    y_val_scaled = y_scaler.transform(y_val)\n",
    "    y_test_scaled = y_scaler.transform(y_test)\n",
    "\n",
    "    return X_train_scaled, X_val_scaled, X_test_scaled, y_train_scaled, y_val_scaled, y_test_scaled, x_scaler, y_scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "008c2df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_2d_y(y):\n",
    "    y = np.asarray(y, dtype = np.float32)\n",
    "    if y.ndim == 1:\n",
    "        y = y[:, None]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ad915eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    dfs = load_data(DATA_DIR)\n",
    "    \n",
    "    X, y, *_ = preprocess_data(dfs)\n",
    "\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = split_timewise(X, y)\n",
    "\n",
    "    X_train = report_and_fix(\"X_train\", X_train)\n",
    "    X_val   = report_and_fix(\"X_val\", X_val)\n",
    "    X_test  = report_and_fix(\"X_test\", X_test)\n",
    "    y_train = report_and_fix(\"y_train\", y_train)\n",
    "    y_val   = report_and_fix(\"y_val\", y_val)\n",
    "    y_test  = report_and_fix(\"y_test\", y_test)\n",
    "\n",
    "    X_tr_s, X_va_s, X_te_s, y_tr_s, y_va_s, y_te_s, x_scaler, y_scaler = scale_data(\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test\n",
    "    )\n",
    "\n",
    "    # 스케일러 저장\n",
    "    SCALER_SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    with open(SCALER_SAVE_DIR / \"X_scaler.pkl\", \"wb\") as f:\n",
    "        pickle.dump(x_scaler, f)\n",
    "    with open(SCALER_SAVE_DIR / \"y_scaler.pkl\", \"wb\") as f:\n",
    "        pickle.dump(y_scaler, f)\n",
    "    print(f\"\\n✓ Scalers saved to {SCALER_SAVE_DIR}\")\n",
    "\n",
    "    y_tr_s = ensure_2d_y(y_tr_s)\n",
    "    y_va_s = ensure_2d_y(y_va_s)\n",
    "    y_te_s = ensure_2d_y(y_te_s)\n",
    "\n",
    "    train_ds = TimeSeriesWindowDataset(X_tr_s, y_tr_s, WINDOW_SIZE, HORIZON)\n",
    "    val_ds = TimeSeriesWindowDataset(X_va_s, y_va_s, WINDOW_SIZE, HORIZON)\n",
    "    test_ds = TimeSeriesWindowDataset(X_te_s, y_te_s, WINDOW_SIZE, HORIZON)\n",
    "\n",
    "    train_dl = DataLoader(train_ds,\n",
    "                          batch_size=TRAINING_CONFIG[\"batch_size\"],\n",
    "                          shuffle=False,\n",
    "                          drop_last=False)\n",
    "    val_dl = DataLoader(val_ds,\n",
    "                        batch_size=TRAINING_CONFIG[\"batch_size\"],\n",
    "                        shuffle=False,\n",
    "                        drop_last=False)\n",
    "    test_dl = DataLoader(test_ds,\n",
    "                         batch_size=TRAINING_CONFIG[\"batch_size\"],\n",
    "                         shuffle=False,\n",
    "                         drop_last=False)\n",
    "    \n",
    "    n_features = X_tr_s.shape[1]\n",
    "    out_size = y_tr_s.shape[1]\n",
    "    model = LSTMRegressor(n_features=n_features,\n",
    "                          hidden_size=LSTM_CONFIG[\"hidden_size\"],\n",
    "                          num_layers=LSTM_CONFIG[\"num_layers\"],\n",
    "                          dropout=LSTM_CONFIG[\"dropout\"],\n",
    "                          out_size=out_size).to(DEVICE)\n",
    "    \n",
    "    # 모드별 손실 함수 설정 (TMS 지표는 Huber Loss 사용)\n",
    "    if MODE in [\"toc\", \"ss\", \"tn\", \"tp\", \"flux\", \"ph\"]:\n",
    "        criterion = HuberLoss(delta=1.0)  # ← TMS용\n",
    "    else:\n",
    "        criterion = nn.MSELoss()  # ← FLOW용 (flow는 MSELoss)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = TRAINING_CONFIG[\"learning_rate\"])\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "    # 모델 저장 경로 설정\n",
    "    MODEL_SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    model_save_path = MODEL_SAVE_DIR / f\"{MODE}_lstm_model.pth\"\n",
    "\n",
    "    hist = train_model(\n",
    "        model, \n",
    "        train_dl, \n",
    "        val_dl, \n",
    "        criterion, \n",
    "        optimizer, \n",
    "        scheduler, \n",
    "        num_epochs=TRAINING_CONFIG[\"num_epochs\"],\n",
    "        patience=TRAINING_CONFIG[\"patience\"],\n",
    "        device=DEVICE,\n",
    "        save_path=model_save_path\n",
    "    )\n",
    "    \n",
    "    plot_learning_curve(\n",
    "        train_loss=hist[\"train_loss\"],\n",
    "        train_mae=hist[\"train_mae\"],\n",
    "        train_rmse=hist[\"train_rmse\"],\n",
    "        train_mape=hist[\"train_mape\"],\n",
    "        val_loss=hist[\"val_loss\"],\n",
    "        val_mae=hist[\"val_mae\"],\n",
    "        val_rmse=hist[\"val_rmse\"],\n",
    "        val_mape=hist[\"val_mape\"],\n",
    "    )\n",
    "    \n",
    "    # 테스트 평가\n",
    "    predictions, actuals, test_metrics = evaluate_model(model, test_dl, criterion, device=DEVICE)\n",
    "\n",
    "    # ← 역변환: 스케일된 값을 원래 값으로 복원\n",
    "    predictions_denorm = y_scaler.inverse_transform(predictions)\n",
    "    actuals_denorm = y_scaler.inverse_transform(actuals)\n",
    "    \n",
    "    print(f\"\\n✓ Predictions denormalized\")\n",
    "    print(f\"  Original shape: {predictions.shape}\")\n",
    "    print(f\"  Denormalized shape: {predictions_denorm.shape}\")\n",
    "    \n",
    "    # 예측 결과 저장\n",
    "    RESULTS_SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # 단일 출력 처리 (모든 모드가 output_size=1)\n",
    "    results_df = pd.DataFrame({\n",
    "        'actual': actuals_denorm.flatten(),\n",
    "        'predicted': predictions_denorm.flatten()\n",
    "    })\n",
    "    \n",
    "    results_df.to_csv(RESULTS_SAVE_DIR / f\"{MODE}_predictions.csv\", index=False)\n",
    "    print(f\"\\n✓ Predictions saved to {RESULTS_SAVE_DIR / f'{MODE}_predictions.csv'}\")\n",
    "    \n",
    "    return model, hist, test_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "03aeaae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "flow 결측치 처리\n",
      "============================================================\n",
      "결측치 처리 전:\n",
      "  총 결측치: 108578\n",
      "  결측치 있는 컬럼: 21개\n",
      "\n",
      "결측치 처리 후:\n",
      "  총 결측치: 818\n",
      "  데이터 shape: (131687, 30)\n",
      "  마스크 shape: (131687, 120)\n",
      "\n",
      "============================================================\n",
      "tms 결측치 처리\n",
      "============================================================\n",
      "결측치 처리 전:\n",
      "  총 결측치: 19590\n",
      "  결측치 있는 컬럼: 24개\n",
      "\n",
      "결측치 처리 후:\n",
      "  총 결측치: 818\n",
      "  데이터 shape: (37771, 36)\n",
      "  마스크 shape: (37771, 144)\n",
      "\n",
      "============================================================\n",
      "flow 이상치 처리\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "tms 이상치 처리\n",
      "============================================================\n",
      "\n",
      "======================================================================\n",
      "전체 특성 정보\n",
      "======================================================================\n",
      "전체 특성 수: 611\n",
      "샘플 수: 4355\n",
      "타겟 개수: 1\n",
      "✓ 5개 폴드 생성\n",
      "  총 윈도우 크기: 1100\n",
      "  Train: 700, Val: 200, Test: 200\n",
      "\n",
      "======================================================================\n",
      "Walk-Forward Validation 시작 (Model: RF)\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold Progress:  20%|██        | 1/5 [00:01<00:06,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Fold 1/5]\n",
      "  선택된 특성: 55/611 (91.0% 감소)\n",
      "  Val RMSE (All): 71.0857\n",
      "  Val RMSE (Selected): 69.6651\n",
      "  성능 변화: -2.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold Progress:  40%|████      | 2/5 [00:03<00:04,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Fold 2/5]\n",
      "  선택된 특성: 79/611 (87.1% 감소)\n",
      "  Val RMSE (All): 56.5748\n",
      "  Val RMSE (Selected): 55.8288\n",
      "  성능 변화: -1.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold Progress:  60%|██████    | 3/5 [00:04<00:03,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Fold 3/5]\n",
      "  선택된 특성: 83/611 (86.4% 감소)\n",
      "  Val RMSE (All): 53.7806\n",
      "  Val RMSE (Selected): 55.1710\n",
      "  성능 변화: +2.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold Progress:  80%|████████  | 4/5 [00:06<00:01,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Fold 4/5]\n",
      "  선택된 특성: 68/611 (88.9% 감소)\n",
      "  Val RMSE (All): 50.4892\n",
      "  Val RMSE (Selected): 49.8762\n",
      "  성능 변화: -1.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold Progress: 100%|██████████| 5/5 [00:08<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Fold 5/5]\n",
      "  선택된 특성: 44/611 (92.8% 감소)\n",
      "  Val RMSE (All): 62.2291\n",
      "  Val RMSE (Selected): 64.8962\n",
      "  성능 변화: +4.29%\n",
      "\n",
      "======================================================================\n",
      "WALK-FORWARD VALIDATION 결과 요약\n",
      "======================================================================\n",
      "원본 특성: 611\n",
      "선택된 특성 (평균): 65.8 ± 14.6\n",
      "특성 감소율: 89.2%\n",
      "\n",
      "안정적 특성 (모든 폴드에서 선택): 11\n",
      "\n",
      "추천 특성 (60%+ 안정성): 44\n",
      "특성 개수: 44/611\n",
      "\n",
      "추천 특성 목록:\n",
      "    1. [  0] level_TankA\n",
      "    2. [  1] level_TankB\n",
      "    3. [  2] level_sum\n",
      "    4. [138] TD_541_roll_IQR_3\n",
      "    5. [145] TA_569_roll_std_3\n",
      "    6. [236] RN_15m_368_roll_max_6\n",
      "    7. [246] RN_15m_569_roll_max_6\n",
      "    8. [249] RN_60m_368_roll_mean_6\n",
      "    9. [251] RN_60m_368_roll_max_6\n",
      "   10. [259] RN_60m_569_roll_mean_6\n",
      "   11. [261] RN_60m_569_roll_max_6\n",
      "   12. [281] TA_541_roll_max_12\n",
      "   13. [296] TA_569_roll_max_12\n",
      "   14. [340] TA_368_roll_std_36\n",
      "   15. [345] TD_368_roll_std_36\n",
      "   16. [348] TD_368_roll_IQR_36\n",
      "   17. [383] HM_569_roll_IQR_36\n",
      "   18. [384] RN_15m_368_roll_mean_36\n",
      "   19. [385] RN_15m_368_roll_std_36\n",
      "   20. [390] RN_15m_541_roll_std_36\n",
      "   21. [433] TD_541_roll_slope_12\n",
      "   22. [436] TD_569_roll_slope_12\n",
      "   23. [444] TA_368_roll_slope_24\n",
      "   24. [445] TD_368_roll_slope_24\n",
      "   25. [446] HM_368_roll_slope_24\n",
      "   26. [450] TA_569_roll_slope_24\n",
      "   27. [451] TD_569_roll_slope_24\n",
      "   28. [453] RN_15m_368_roll_slope_24\n",
      "   29. [456] RN_60m_368_roll_slope_24\n",
      "   30. [457] RN_60m_541_roll_slope_24\n",
      "   31. [458] RN_60m_569_roll_slope_24\n",
      "   32. [497] RN_12H_368_lag_3h\n",
      "   33. [527] RN_12H_569_lag_6h\n",
      "   34. [554] HM_368_lag_24h\n",
      "   35. [560] HM_541_lag_24h\n",
      "   36. [565] TD_569_lag_24h\n",
      "   37. [571] TD_368_lag_36h\n",
      "   38. [582] TA_569_lag_36h\n",
      "   39. [584] HM_569_lag_36h\n",
      "   40. [594] d_TA_541\n",
      "   41. [600] d_TA_569\n",
      "   42. [603] hour\n",
      "   43. [607] hour_sin\n",
      "   44. [608] hour_cos\n",
      "\n",
      "======================================================================\n",
      "특성 선택 완료\n",
      "======================================================================\n",
      "원본 X shape: (4355, 611)\n",
      "필터링된 X shape: (4355, 44)\n",
      "선택률: 7.2%\n",
      "\n",
      "✓ 추천 특성 저장: C:\\project_WWTP\\python\\results\\DL\\flow_recommended_features.csv\n",
      "X_train: shape=(3048, 44), n_nan=0, n_inf=0\n",
      "X_val: shape=(653, 44), n_nan=0, n_inf=0\n",
      "X_test: shape=(654, 44), n_nan=0, n_inf=0\n",
      "y_train: shape=(3048, 1), n_nan=0, n_inf=0\n",
      "y_val: shape=(653, 1), n_nan=0, n_inf=0\n",
      "y_test: shape=(654, 1), n_nan=0, n_inf=0\n",
      "\n",
      "✓ Scalers saved to C:\\project_WWTP\\python\\model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 123.05it/s, loss=0.0277, mae=0.1161, rmse=0.1663] \n",
      "Epoch 1/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 326.04it/s, loss=0.0052, mae=0.0724, rmse=0.0724]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100 Summary:\n",
      "  Train - Loss: 1.0156, MAE: 0.7003, RMSE: 1.0078, MAPE: 0.00%\n",
      "  Val   - Loss: 0.9501, MAE: 0.6027, RMSE: 0.9747, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.9747\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 144.76it/s, loss=0.0764, mae=0.2505, rmse=0.2765]\n",
      "Epoch 2/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 283.69it/s, loss=0.1121, mae=0.3348, rmse=0.3349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/100 Summary:\n",
      "  Train - Loss: 0.9959, MAE: 0.7124, RMSE: 0.9980, MAPE: 0.00%\n",
      "  Val   - Loss: 0.8257, MAE: 0.6667, RMSE: 0.9087, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.9087\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 140.75it/s, loss=0.2497, mae=0.4594, rmse=0.4997]\n",
      "Epoch 3/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 236.87it/s, loss=0.1898, mae=0.4305, rmse=0.4356]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/100 Summary:\n",
      "  Train - Loss: 0.9472, MAE: 0.7327, RMSE: 0.9732, MAPE: 0.00%\n",
      "  Val   - Loss: 0.6537, MAE: 0.5975, RMSE: 0.8085, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.8085\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 139.60it/s, loss=0.4512, mae=0.4630, rmse=0.6717]\n",
      "Epoch 4/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 281.42it/s, loss=0.0889, mae=0.2769, rmse=0.2981]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/100 Summary:\n",
      "  Train - Loss: 0.7901, MAE: 0.6458, RMSE: 0.8889, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4843, MAE: 0.4558, RMSE: 0.6959, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6959\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 135.30it/s, loss=0.4031, mae=0.4465, rmse=0.6349]\n",
      "Epoch 5/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 275.22it/s, loss=0.0495, mae=0.1885, rmse=0.2225]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/100 Summary:\n",
      "  Train - Loss: 0.7284, MAE: 0.5984, RMSE: 0.8534, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4916, MAE: 0.4517, RMSE: 0.7012, MAPE: 0.00%\n",
      "  No improvement. Patience: 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 138.54it/s, loss=0.2042, mae=0.3498, rmse=0.4518]\n",
      "Epoch 6/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 282.23it/s, loss=0.0451, mae=0.1827, rmse=0.2123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/100 Summary:\n",
      "  Train - Loss: 0.6989, MAE: 0.5794, RMSE: 0.8360, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4995, MAE: 0.4517, RMSE: 0.7067, MAPE: 0.00%\n",
      "  No improvement. Patience: 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 141.10it/s, loss=0.1353, mae=0.2808, rmse=0.3679]\n",
      "Epoch 7/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 272.19it/s, loss=0.0379, mae=0.1648, rmse=0.1946]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/100 Summary:\n",
      "  Train - Loss: 0.6732, MAE: 0.5653, RMSE: 0.8205, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4982, MAE: 0.4500, RMSE: 0.7058, MAPE: 0.00%\n",
      "  No improvement. Patience: 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 133.87it/s, loss=0.1503, mae=0.3035, rmse=0.3877]\n",
      "Epoch 8/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 277.48it/s, loss=0.0378, mae=0.1640, rmse=0.1945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/100 Summary:\n",
      "  Train - Loss: 0.6692, MAE: 0.5600, RMSE: 0.8180, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4962, MAE: 0.4474, RMSE: 0.7044, MAPE: 0.00%\n",
      "  No improvement. Patience: 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 139.89it/s, loss=0.1352, mae=0.2803, rmse=0.3677]\n",
      "Epoch 9/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 272.22it/s, loss=0.0353, mae=0.1557, rmse=0.1879]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/100 Summary:\n",
      "  Train - Loss: 0.6541, MAE: 0.5513, RMSE: 0.8088, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4909, MAE: 0.4434, RMSE: 0.7006, MAPE: 0.00%\n",
      "  No improvement. Patience: 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 137.96it/s, loss=0.1448, mae=0.2903, rmse=0.3805]\n",
      "Epoch 10/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 281.37it/s, loss=0.0339, mae=0.1504, rmse=0.1841]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/100 Summary:\n",
      "  Train - Loss: 0.6413, MAE: 0.5433, RMSE: 0.8008, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4831, MAE: 0.4381, RMSE: 0.6950, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6950\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 140.05it/s, loss=0.1224, mae=0.2656, rmse=0.3498]\n",
      "Epoch 11/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 245.13it/s, loss=0.0411, mae=0.1704, rmse=0.2027]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/100 Summary:\n",
      "  Train - Loss: 0.6290, MAE: 0.5361, RMSE: 0.7931, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4848, MAE: 0.4368, RMSE: 0.6963, MAPE: 0.00%\n",
      "  No improvement. Patience: 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 136.52it/s, loss=0.1130, mae=0.2596, rmse=0.3362]\n",
      "Epoch 12/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 285.15it/s, loss=0.0433, mae=0.1744, rmse=0.2082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12/100 Summary:\n",
      "  Train - Loss: 0.6182, MAE: 0.5323, RMSE: 0.7863, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4775, MAE: 0.4331, RMSE: 0.6910, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6910\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 139.40it/s, loss=0.1534, mae=0.3107, rmse=0.3917]\n",
      "Epoch 13/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 281.48it/s, loss=0.0556, mae=0.2065, rmse=0.2359]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13/100 Summary:\n",
      "  Train - Loss: 0.6109, MAE: 0.5261, RMSE: 0.7816, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4723, MAE: 0.4310, RMSE: 0.6872, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6872\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 136.13it/s, loss=0.1549, mae=0.3252, rmse=0.3936]\n",
      "Epoch 14/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 274.86it/s, loss=0.0627, mae=0.2228, rmse=0.2505]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14/100 Summary:\n",
      "  Train - Loss: 0.5982, MAE: 0.5202, RMSE: 0.7734, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4624, MAE: 0.4285, RMSE: 0.6800, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6800\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 134.85it/s, loss=0.1488, mae=0.3316, rmse=0.3857]\n",
      "Epoch 15/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 285.25it/s, loss=0.0675, mae=0.2330, rmse=0.2597]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/100 Summary:\n",
      "  Train - Loss: 0.5951, MAE: 0.5164, RMSE: 0.7715, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4498, MAE: 0.4261, RMSE: 0.6706, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6706\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 139.53it/s, loss=0.1560, mae=0.3231, rmse=0.3949]\n",
      "Epoch 16/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 284.34it/s, loss=0.0767, mae=0.2534, rmse=0.2770]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16/100 Summary:\n",
      "  Train - Loss: 0.5816, MAE: 0.5116, RMSE: 0.7626, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4442, MAE: 0.4253, RMSE: 0.6665, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6665\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 139.06it/s, loss=0.2331, mae=0.4239, rmse=0.4828]\n",
      "Epoch 17/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 270.50it/s, loss=0.0793, mae=0.2584, rmse=0.2815]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17/100 Summary:\n",
      "  Train - Loss: 0.5749, MAE: 0.5049, RMSE: 0.7582, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4367, MAE: 0.4240, RMSE: 0.6608, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6608\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 137.84it/s, loss=0.2231, mae=0.4222, rmse=0.4723]\n",
      "Epoch 18/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 275.85it/s, loss=0.0803, mae=0.2609, rmse=0.2834]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18/100 Summary:\n",
      "  Train - Loss: 0.5645, MAE: 0.5027, RMSE: 0.7514, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4310, MAE: 0.4227, RMSE: 0.6565, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6565\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 142.02it/s, loss=0.2237, mae=0.4407, rmse=0.4729]\n",
      "Epoch 19/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 286.32it/s, loss=0.0812, mae=0.2623, rmse=0.2850]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19/100 Summary:\n",
      "  Train - Loss: 0.5623, MAE: 0.4998, RMSE: 0.7498, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4243, MAE: 0.4215, RMSE: 0.6514, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6514\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 137.24it/s, loss=0.3015, mae=0.4976, rmse=0.5491]\n",
      "Epoch 20/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 272.15it/s, loss=0.0822, mae=0.2641, rmse=0.2868]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/100 Summary:\n",
      "  Train - Loss: 0.5537, MAE: 0.4986, RMSE: 0.7441, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4187, MAE: 0.4204, RMSE: 0.6470, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6470\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 140.82it/s, loss=0.2041, mae=0.4058, rmse=0.4517]\n",
      "Epoch 21/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 281.43it/s, loss=0.0810, mae=0.2619, rmse=0.2846]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21/100 Summary:\n",
      "  Train - Loss: 0.5456, MAE: 0.4923, RMSE: 0.7387, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4159, MAE: 0.4198, RMSE: 0.6449, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6449\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 132.95it/s, loss=0.2094, mae=0.4276, rmse=0.4576]\n",
      "Epoch 22/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 280.92it/s, loss=0.0799, mae=0.2599, rmse=0.2826]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22/100 Summary:\n",
      "  Train - Loss: 0.5435, MAE: 0.4893, RMSE: 0.7372, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4126, MAE: 0.4191, RMSE: 0.6423, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6423\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 140.08it/s, loss=0.2441, mae=0.4677, rmse=0.4941]\n",
      "Epoch 23/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 275.49it/s, loss=0.0802, mae=0.2604, rmse=0.2832]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23/100 Summary:\n",
      "  Train - Loss: 0.5370, MAE: 0.4877, RMSE: 0.7328, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4106, MAE: 0.4189, RMSE: 0.6408, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6408\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 136.32it/s, loss=0.3544, mae=0.5470, rmse=0.5953]\n",
      "Epoch 24/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 279.26it/s, loss=0.0799, mae=0.2601, rmse=0.2827]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24/100 Summary:\n",
      "  Train - Loss: 0.5396, MAE: 0.4891, RMSE: 0.7346, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4093, MAE: 0.4188, RMSE: 0.6397, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6397\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 137.52it/s, loss=0.2764, mae=0.4921, rmse=0.5257]\n",
      "Epoch 25/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 273.78it/s, loss=0.0813, mae=0.2627, rmse=0.2852]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25/100 Summary:\n",
      "  Train - Loss: 0.5352, MAE: 0.4882, RMSE: 0.7316, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4075, MAE: 0.4191, RMSE: 0.6383, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6383\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 135.67it/s, loss=0.2726, mae=0.4872, rmse=0.5221]\n",
      "Epoch 26/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 283.58it/s, loss=0.0804, mae=0.2611, rmse=0.2835]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26/100 Summary:\n",
      "  Train - Loss: 0.5293, MAE: 0.4838, RMSE: 0.7275, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4063, MAE: 0.4188, RMSE: 0.6374, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6374\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 138.53it/s, loss=0.3537, mae=0.5506, rmse=0.5948]\n",
      "Epoch 27/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 275.73it/s, loss=0.0798, mae=0.2599, rmse=0.2825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27/100 Summary:\n",
      "  Train - Loss: 0.5316, MAE: 0.4855, RMSE: 0.7291, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4055, MAE: 0.4188, RMSE: 0.6368, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6368\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 134.67it/s, loss=0.3097, mae=0.5234, rmse=0.5565]\n",
      "Epoch 28/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 273.61it/s, loss=0.0783, mae=0.2572, rmse=0.2799]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28/100 Summary:\n",
      "  Train - Loss: 0.5288, MAE: 0.4861, RMSE: 0.7272, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4042, MAE: 0.4186, RMSE: 0.6358, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6358\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 138.49it/s, loss=0.2559, mae=0.4936, rmse=0.5059]\n",
      "Epoch 29/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 273.66it/s, loss=0.0775, mae=0.2556, rmse=0.2783]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29/100 Summary:\n",
      "  Train - Loss: 0.5372, MAE: 0.4881, RMSE: 0.7329, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4035, MAE: 0.4187, RMSE: 0.6352, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6352\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 135.20it/s, loss=0.2152, mae=0.4299, rmse=0.4639]\n",
      "Epoch 30/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 283.41it/s, loss=0.0784, mae=0.2576, rmse=0.2800]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30/100 Summary:\n",
      "  Train - Loss: 0.5280, MAE: 0.4854, RMSE: 0.7267, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4035, MAE: 0.4189, RMSE: 0.6352, MAPE: 0.00%\n",
      "  No improvement. Patience: 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 138.44it/s, loss=0.2943, mae=0.5156, rmse=0.5425]\n",
      "Epoch 31/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 280.65it/s, loss=0.0781, mae=0.2570, rmse=0.2795]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 31/100 Summary:\n",
      "  Train - Loss: 0.5266, MAE: 0.4847, RMSE: 0.7256, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4029, MAE: 0.4188, RMSE: 0.6348, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6348\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 134.27it/s, loss=0.2170, mae=0.4396, rmse=0.4659]\n",
      "Epoch 32/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 284.78it/s, loss=0.0779, mae=0.2565, rmse=0.2791]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32/100 Summary:\n",
      "  Train - Loss: 0.5259, MAE: 0.4831, RMSE: 0.7252, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4026, MAE: 0.4189, RMSE: 0.6345, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6345\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 139.64it/s, loss=0.1993, mae=0.4340, rmse=0.4464]\n",
      "Epoch 33/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 273.38it/s, loss=0.0777, mae=0.2561, rmse=0.2787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 33/100 Summary:\n",
      "  Train - Loss: 0.5237, MAE: 0.4823, RMSE: 0.7237, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4023, MAE: 0.4190, RMSE: 0.6342, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6342\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 132.96it/s, loss=0.2255, mae=0.4509, rmse=0.4749]\n",
      "Epoch 34/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 267.88it/s, loss=0.0769, mae=0.2548, rmse=0.2774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34/100 Summary:\n",
      "  Train - Loss: 0.5254, MAE: 0.4837, RMSE: 0.7248, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4021, MAE: 0.4188, RMSE: 0.6341, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6341\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 138.10it/s, loss=0.2862, mae=0.5181, rmse=0.5349]\n",
      "Epoch 35/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 275.95it/s, loss=0.0761, mae=0.2532, rmse=0.2759]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 35/100 Summary:\n",
      "  Train - Loss: 0.5227, MAE: 0.4844, RMSE: 0.7230, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4016, MAE: 0.4188, RMSE: 0.6337, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6337\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 136.13it/s, loss=0.3045, mae=0.5282, rmse=0.5518]\n",
      "Epoch 36/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 271.80it/s, loss=0.0758, mae=0.2525, rmse=0.2754]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36/100 Summary:\n",
      "  Train - Loss: 0.5209, MAE: 0.4820, RMSE: 0.7217, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4013, MAE: 0.4189, RMSE: 0.6335, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6335\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 138.93it/s, loss=0.2833, mae=0.5097, rmse=0.5323]\n",
      "Epoch 37/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 282.19it/s, loss=0.0755, mae=0.2519, rmse=0.2748]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 37/100 Summary:\n",
      "  Train - Loss: 0.5224, MAE: 0.4812, RMSE: 0.7228, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4011, MAE: 0.4189, RMSE: 0.6333, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6333\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 136.11it/s, loss=0.2714, mae=0.4933, rmse=0.5209]\n",
      "Epoch 38/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 275.32it/s, loss=0.0752, mae=0.2513, rmse=0.2742]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38/100 Summary:\n",
      "  Train - Loss: 0.5209, MAE: 0.4809, RMSE: 0.7217, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4008, MAE: 0.4189, RMSE: 0.6331, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6331\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 137.22it/s, loss=0.2318, mae=0.4603, rmse=0.4815]\n",
      "Epoch 39/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 276.17it/s, loss=0.0749, mae=0.2508, rmse=0.2737]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 39/100 Summary:\n",
      "  Train - Loss: 0.5258, MAE: 0.4848, RMSE: 0.7251, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4007, MAE: 0.4189, RMSE: 0.6330, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6330\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 136.45it/s, loss=0.2717, mae=0.5097, rmse=0.5213]\n",
      "Epoch 40/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 267.45it/s, loss=0.0748, mae=0.2505, rmse=0.2734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40/100 Summary:\n",
      "  Train - Loss: 0.5212, MAE: 0.4806, RMSE: 0.7220, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4005, MAE: 0.4189, RMSE: 0.6329, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6329\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 137.72it/s, loss=0.3654, mae=0.5662, rmse=0.6045]\n",
      "Epoch 41/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 281.83it/s, loss=0.0746, mae=0.2503, rmse=0.2732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 41/100 Summary:\n",
      "  Train - Loss: 0.5222, MAE: 0.4814, RMSE: 0.7227, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4005, MAE: 0.4189, RMSE: 0.6328, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6328\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 134.49it/s, loss=0.2719, mae=0.4800, rmse=0.5215]\n",
      "Epoch 42/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 283.33it/s, loss=0.0746, mae=0.2501, rmse=0.2731]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 42/100 Summary:\n",
      "  Train - Loss: 0.5214, MAE: 0.4827, RMSE: 0.7221, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4005, MAE: 0.4189, RMSE: 0.6328, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6328\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 138.33it/s, loss=0.2315, mae=0.4726, rmse=0.4811]\n",
      "Epoch 43/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 274.90it/s, loss=0.0744, mae=0.2499, rmse=0.2729]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 43/100 Summary:\n",
      "  Train - Loss: 0.5239, MAE: 0.4823, RMSE: 0.7238, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4004, MAE: 0.4189, RMSE: 0.6328, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6328\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 134.41it/s, loss=0.2525, mae=0.4786, rmse=0.5025]\n",
      "Epoch 44/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 278.01it/s, loss=0.0745, mae=0.2501, rmse=0.2730]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 44/100 Summary:\n",
      "  Train - Loss: 0.5259, MAE: 0.4833, RMSE: 0.7252, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4004, MAE: 0.4189, RMSE: 0.6327, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6327\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 135.85it/s, loss=0.1798, mae=0.4043, rmse=0.4241]\n",
      "Epoch 45/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 262.97it/s, loss=0.0743, mae=0.2496, rmse=0.2726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 45/100 Summary:\n",
      "  Train - Loss: 0.5303, MAE: 0.4875, RMSE: 0.7282, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4003, MAE: 0.4189, RMSE: 0.6327, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6327\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 134.76it/s, loss=0.2665, mae=0.4863, rmse=0.5162]\n",
      "Epoch 46/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 266.77it/s, loss=0.0742, mae=0.2494, rmse=0.2724]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 46/100 Summary:\n",
      "  Train - Loss: 0.5210, MAE: 0.4820, RMSE: 0.7218, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4002, MAE: 0.4189, RMSE: 0.6326, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6326\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 138.59it/s, loss=0.2015, mae=0.4378, rmse=0.4489]\n",
      "Epoch 47/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 268.55it/s, loss=0.0742, mae=0.2494, rmse=0.2723]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 47/100 Summary:\n",
      "  Train - Loss: 0.5187, MAE: 0.4803, RMSE: 0.7202, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4002, MAE: 0.4189, RMSE: 0.6326, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6326\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 135.86it/s, loss=0.2997, mae=0.5304, rmse=0.5474]\n",
      "Epoch 48/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 275.54it/s, loss=0.0741, mae=0.2493, rmse=0.2723]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 48/100 Summary:\n",
      "  Train - Loss: 0.5223, MAE: 0.4832, RMSE: 0.7227, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4001, MAE: 0.4189, RMSE: 0.6326, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6326\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 136.72it/s, loss=0.3546, mae=0.5575, rmse=0.5955]\n",
      "Epoch 49/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 277.91it/s, loss=0.0741, mae=0.2492, rmse=0.2721]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 49/100 Summary:\n",
      "  Train - Loss: 0.5342, MAE: 0.4885, RMSE: 0.7309, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4001, MAE: 0.4189, RMSE: 0.6325, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6325\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 133.19it/s, loss=0.1719, mae=0.4063, rmse=0.4146]\n",
      "Epoch 50/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 272.39it/s, loss=0.0740, mae=0.2491, rmse=0.2721]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 50/100 Summary:\n",
      "  Train - Loss: 0.5176, MAE: 0.4812, RMSE: 0.7194, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4001, MAE: 0.4189, RMSE: 0.6325, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6325\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 139.04it/s, loss=0.2887, mae=0.4951, rmse=0.5373]\n",
      "Epoch 51/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 284.55it/s, loss=0.0740, mae=0.2491, rmse=0.2720]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 51/100 Summary:\n",
      "  Train - Loss: 0.5230, MAE: 0.4836, RMSE: 0.7232, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4000, MAE: 0.4189, RMSE: 0.6325, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6325\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 133.68it/s, loss=0.3277, mae=0.5502, rmse=0.5725]\n",
      "Epoch 52/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 277.71it/s, loss=0.0740, mae=0.2491, rmse=0.2720]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 52/100 Summary:\n",
      "  Train - Loss: 0.5138, MAE: 0.4798, RMSE: 0.7168, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4000, MAE: 0.4189, RMSE: 0.6325, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6325\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 139.29it/s, loss=0.2702, mae=0.4935, rmse=0.5198]\n",
      "Epoch 53/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 289.49it/s, loss=0.0740, mae=0.2490, rmse=0.2720]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 53/100 Summary:\n",
      "  Train - Loss: 0.5243, MAE: 0.4833, RMSE: 0.7241, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4000, MAE: 0.4189, RMSE: 0.6325, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6325\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 130.61it/s, loss=0.3317, mae=0.5435, rmse=0.5759]\n",
      "Epoch 54/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 264.56it/s, loss=0.0739, mae=0.2489, rmse=0.2719]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 54/100 Summary:\n",
      "  Train - Loss: 0.5200, MAE: 0.4808, RMSE: 0.7211, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4000, MAE: 0.4189, RMSE: 0.6325, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6325\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 137.00it/s, loss=0.2682, mae=0.4951, rmse=0.5179]\n",
      "Epoch 55/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 263.00it/s, loss=0.0738, mae=0.2488, rmse=0.2718]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 55/100 Summary:\n",
      "  Train - Loss: 0.5179, MAE: 0.4812, RMSE: 0.7197, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4000, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 137.76it/s, loss=0.2383, mae=0.4737, rmse=0.4882]\n",
      "Epoch 56/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 269.28it/s, loss=0.0738, mae=0.2487, rmse=0.2717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 56/100 Summary:\n",
      "  Train - Loss: 0.5220, MAE: 0.4842, RMSE: 0.7225, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4000, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 138.93it/s, loss=0.2508, mae=0.4634, rmse=0.5008]\n",
      "Epoch 57/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 270.15it/s, loss=0.0738, mae=0.2487, rmse=0.2717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 57/100 Summary:\n",
      "  Train - Loss: 0.5187, MAE: 0.4830, RMSE: 0.7202, MAPE: 0.00%\n",
      "  Val   - Loss: 0.4000, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 137.49it/s, loss=0.4018, mae=0.5825, rmse=0.6339]\n",
      "Epoch 58/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 276.24it/s, loss=0.0738, mae=0.2486, rmse=0.2716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 58/100 Summary:\n",
      "  Train - Loss: 0.5199, MAE: 0.4816, RMSE: 0.7210, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 137.51it/s, loss=0.3542, mae=0.5686, rmse=0.5951]\n",
      "Epoch 59/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 281.71it/s, loss=0.0738, mae=0.2486, rmse=0.2716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 59/100 Summary:\n",
      "  Train - Loss: 0.5233, MAE: 0.4820, RMSE: 0.7234, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 134.52it/s, loss=0.1783, mae=0.4130, rmse=0.4223]\n",
      "Epoch 60/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 278.32it/s, loss=0.0738, mae=0.2486, rmse=0.2716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 60/100 Summary:\n",
      "  Train - Loss: 0.5208, MAE: 0.4825, RMSE: 0.7217, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 135.39it/s, loss=0.2483, mae=0.4779, rmse=0.4983]\n",
      "Epoch 61/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 278.16it/s, loss=0.0738, mae=0.2486, rmse=0.2716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 61/100 Summary:\n",
      "  Train - Loss: 0.5168, MAE: 0.4825, RMSE: 0.7189, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 133.68it/s, loss=0.3364, mae=0.5540, rmse=0.5800]\n",
      "Epoch 62/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 284.27it/s, loss=0.0737, mae=0.2486, rmse=0.2715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 62/100 Summary:\n",
      "  Train - Loss: 0.5311, MAE: 0.4871, RMSE: 0.7288, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 133.50it/s, loss=0.2854, mae=0.4964, rmse=0.5342]\n",
      "Epoch 63/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 260.14it/s, loss=0.0737, mae=0.2485, rmse=0.2715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 63/100 Summary:\n",
      "  Train - Loss: 0.5252, MAE: 0.4835, RMSE: 0.7247, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 130.84it/s, loss=0.3128, mae=0.5087, rmse=0.5593]\n",
      "Epoch 64/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 264.78it/s, loss=0.0737, mae=0.2485, rmse=0.2715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 64/100 Summary:\n",
      "  Train - Loss: 0.5215, MAE: 0.4818, RMSE: 0.7222, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 135.19it/s, loss=0.2073, mae=0.4467, rmse=0.4554]\n",
      "Epoch 65/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 265.51it/s, loss=0.0737, mae=0.2485, rmse=0.2715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 65/100 Summary:\n",
      "  Train - Loss: 0.5276, MAE: 0.4840, RMSE: 0.7263, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 134.28it/s, loss=0.2822, mae=0.4995, rmse=0.5312]\n",
      "Epoch 66/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 253.86it/s, loss=0.0737, mae=0.2485, rmse=0.2715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 66/100 Summary:\n",
      "  Train - Loss: 0.5249, MAE: 0.4861, RMSE: 0.7245, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 138.89it/s, loss=0.1897, mae=0.4259, rmse=0.4356]\n",
      "Epoch 67/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 255.79it/s, loss=0.0737, mae=0.2485, rmse=0.2715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 67/100 Summary:\n",
      "  Train - Loss: 0.5258, MAE: 0.4829, RMSE: 0.7251, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 138.10it/s, loss=0.2757, mae=0.4845, rmse=0.5251]\n",
      "Epoch 68/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 267.67it/s, loss=0.0737, mae=0.2485, rmse=0.2715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 68/100 Summary:\n",
      "  Train - Loss: 0.5265, MAE: 0.4841, RMSE: 0.7256, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 132.68it/s, loss=0.2940, mae=0.5175, rmse=0.5422]\n",
      "Epoch 69/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 267.45it/s, loss=0.0737, mae=0.2485, rmse=0.2715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 69/100 Summary:\n",
      "  Train - Loss: 0.5193, MAE: 0.4823, RMSE: 0.7206, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 135.62it/s, loss=0.3243, mae=0.5371, rmse=0.5694]\n",
      "Epoch 70/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 265.86it/s, loss=0.0737, mae=0.2485, rmse=0.2715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 70/100 Summary:\n",
      "  Train - Loss: 0.5188, MAE: 0.4817, RMSE: 0.7203, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 134.04it/s, loss=0.3422, mae=0.5532, rmse=0.5850]\n",
      "Epoch 71/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 270.50it/s, loss=0.0737, mae=0.2485, rmse=0.2714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 71/100 Summary:\n",
      "  Train - Loss: 0.5149, MAE: 0.4802, RMSE: 0.7175, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 133.31it/s, loss=0.2544, mae=0.4755, rmse=0.5044]\n",
      "Epoch 72/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 263.24it/s, loss=0.0737, mae=0.2484, rmse=0.2714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 72/100 Summary:\n",
      "  Train - Loss: 0.5215, MAE: 0.4844, RMSE: 0.7222, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 134.06it/s, loss=0.3158, mae=0.5377, rmse=0.5619]\n",
      "Epoch 73/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 273.07it/s, loss=0.0737, mae=0.2484, rmse=0.2714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 73/100 Summary:\n",
      "  Train - Loss: 0.5196, MAE: 0.4809, RMSE: 0.7208, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 134.94it/s, loss=0.2863, mae=0.5052, rmse=0.5351]\n",
      "Epoch 74/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 268.80it/s, loss=0.0737, mae=0.2484, rmse=0.2714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 74/100 Summary:\n",
      "  Train - Loss: 0.5241, MAE: 0.4833, RMSE: 0.7239, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 140.30it/s, loss=0.3060, mae=0.5093, rmse=0.5532]\n",
      "Epoch 75/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 300.20it/s, loss=0.0737, mae=0.2484, rmse=0.2714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 75/100 Summary:\n",
      "  Train - Loss: 0.5224, MAE: 0.4833, RMSE: 0.7228, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 141.19it/s, loss=0.2214, mae=0.4507, rmse=0.4706]\n",
      "Epoch 76/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 324.69it/s, loss=0.0737, mae=0.2484, rmse=0.2714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 76/100 Summary:\n",
      "  Train - Loss: 0.5196, MAE: 0.4820, RMSE: 0.7208, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 139.62it/s, loss=0.1875, mae=0.4164, rmse=0.4331]\n",
      "Epoch 77/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 277.99it/s, loss=0.0737, mae=0.2484, rmse=0.2714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 77/100 Summary:\n",
      "  Train - Loss: 0.5139, MAE: 0.4791, RMSE: 0.7169, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 137.42it/s, loss=0.2853, mae=0.5118, rmse=0.5341]\n",
      "Epoch 78/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 278.06it/s, loss=0.0737, mae=0.2484, rmse=0.2714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 78/100 Summary:\n",
      "  Train - Loss: 0.5153, MAE: 0.4784, RMSE: 0.7178, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 134.77it/s, loss=0.2712, mae=0.4912, rmse=0.5208]\n",
      "Epoch 79/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 273.33it/s, loss=0.0737, mae=0.2484, rmse=0.2714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 79/100 Summary:\n",
      "  Train - Loss: 0.5300, MAE: 0.4864, RMSE: 0.7280, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 135.27it/s, loss=0.1784, mae=0.4113, rmse=0.4224]\n",
      "Epoch 80/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 273.09it/s, loss=0.0737, mae=0.2484, rmse=0.2714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 80/100 Summary:\n",
      "  Train - Loss: 0.5158, MAE: 0.4777, RMSE: 0.7182, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 137.75it/s, loss=0.1786, mae=0.3965, rmse=0.4226]\n",
      "Epoch 81/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 255.44it/s, loss=0.0737, mae=0.2484, rmse=0.2714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 81/100 Summary:\n",
      "  Train - Loss: 0.5196, MAE: 0.4835, RMSE: 0.7208, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 135.95it/s, loss=0.3486, mae=0.5541, rmse=0.5905]\n",
      "Epoch 82/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 272.36it/s, loss=0.0737, mae=0.2484, rmse=0.2714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 82/100 Summary:\n",
      "  Train - Loss: 0.5233, MAE: 0.4839, RMSE: 0.7234, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 135.83it/s, loss=0.2685, mae=0.5008, rmse=0.5181]\n",
      "Epoch 83/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 272.02it/s, loss=0.0737, mae=0.2484, rmse=0.2714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 83/100 Summary:\n",
      "  Train - Loss: 0.5236, MAE: 0.4825, RMSE: 0.7236, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 137.12it/s, loss=0.3252, mae=0.5324, rmse=0.5703]\n",
      "Epoch 84/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 276.40it/s, loss=0.0737, mae=0.2484, rmse=0.2714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 84/100 Summary:\n",
      "  Train - Loss: 0.5293, MAE: 0.4844, RMSE: 0.7275, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 131.23it/s, loss=0.2972, mae=0.5205, rmse=0.5452]\n",
      "Epoch 85/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 267.26it/s, loss=0.0737, mae=0.2484, rmse=0.2714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 85/100 Summary:\n",
      "  Train - Loss: 0.5219, MAE: 0.4842, RMSE: 0.7224, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 133.50it/s, loss=0.2275, mae=0.4529, rmse=0.4770]\n",
      "Epoch 86/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 280.07it/s, loss=0.0737, mae=0.2484, rmse=0.2714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 86/100 Summary:\n",
      "  Train - Loss: 0.5232, MAE: 0.4833, RMSE: 0.7233, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 136.83it/s, loss=0.3276, mae=0.5451, rmse=0.5724]\n",
      "Epoch 87/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 270.45it/s, loss=0.0737, mae=0.2484, rmse=0.2714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 87/100 Summary:\n",
      "  Train - Loss: 0.5202, MAE: 0.4839, RMSE: 0.7212, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 136.23it/s, loss=0.3135, mae=0.5428, rmse=0.5599]\n",
      "Epoch 88/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 275.02it/s, loss=0.0737, mae=0.2484, rmse=0.2714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 88/100 Summary:\n",
      "  Train - Loss: 0.5236, MAE: 0.4842, RMSE: 0.7236, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 134.69it/s, loss=0.3331, mae=0.5484, rmse=0.5772]\n",
      "Epoch 89/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 266.91it/s, loss=0.0737, mae=0.2484, rmse=0.2714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 89/100 Summary:\n",
      "  Train - Loss: 0.5232, MAE: 0.4843, RMSE: 0.7233, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 134.15it/s, loss=0.2484, mae=0.4877, rmse=0.4984]\n",
      "Epoch 90/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 270.28it/s, loss=0.0737, mae=0.2484, rmse=0.2714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 90/100 Summary:\n",
      "  Train - Loss: 0.5214, MAE: 0.4818, RMSE: 0.7221, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 135.98it/s, loss=0.2877, mae=0.5118, rmse=0.5364]\n",
      "Epoch 91/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 271.32it/s, loss=0.0737, mae=0.2484, rmse=0.2714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 91/100 Summary:\n",
      "  Train - Loss: 0.5218, MAE: 0.4817, RMSE: 0.7223, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  No improvement. Patience: 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 132.96it/s, loss=0.2335, mae=0.4597, rmse=0.4832]\n",
      "Epoch 92/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 265.68it/s, loss=0.0737, mae=0.2484, rmse=0.2714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 92/100 Summary:\n",
      "  Train - Loss: 0.5226, MAE: 0.4822, RMSE: 0.7229, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 135.73it/s, loss=0.2228, mae=0.4571, rmse=0.4720]\n",
      "Epoch 93/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 319.44it/s, loss=0.0737, mae=0.2484, rmse=0.2714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 93/100 Summary:\n",
      "  Train - Loss: 0.5214, MAE: 0.4841, RMSE: 0.7221, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  No improvement. Patience: 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 142.02it/s, loss=0.2983, mae=0.5328, rmse=0.5461]\n",
      "Epoch 94/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 322.10it/s, loss=0.0737, mae=0.2484, rmse=0.2714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 94/100 Summary:\n",
      "  Train - Loss: 0.5205, MAE: 0.4826, RMSE: 0.7215, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 139.46it/s, loss=0.2224, mae=0.4525, rmse=0.4716]\n",
      "Epoch 95/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 259.48it/s, loss=0.0737, mae=0.2484, rmse=0.2714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 95/100 Summary:\n",
      "  Train - Loss: 0.5235, MAE: 0.4825, RMSE: 0.7236, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  ✓ New best model! Val RMSE: 0.6324\n",
      "  ✓ Model saved to C:\\project_WWTP\\python\\model\\flow_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 134.34it/s, loss=0.2522, mae=0.4766, rmse=0.5022]\n",
      "Epoch 96/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 277.22it/s, loss=0.0737, mae=0.2484, rmse=0.2714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 96/100 Summary:\n",
      "  Train - Loss: 0.5256, MAE: 0.4845, RMSE: 0.7250, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  No improvement. Patience: 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 134.95it/s, loss=0.2211, mae=0.4522, rmse=0.4702]\n",
      "Epoch 97/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 265.27it/s, loss=0.0737, mae=0.2484, rmse=0.2714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 97/100 Summary:\n",
      "  Train - Loss: 0.5247, MAE: 0.4864, RMSE: 0.7244, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  No improvement. Patience: 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 134.88it/s, loss=0.2595, mae=0.4941, rmse=0.5094]\n",
      "Epoch 98/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 273.52it/s, loss=0.0737, mae=0.2484, rmse=0.2714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 98/100 Summary:\n",
      "  Train - Loss: 0.5189, MAE: 0.4814, RMSE: 0.7203, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  No improvement. Patience: 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 132.10it/s, loss=0.2712, mae=0.4961, rmse=0.5208]\n",
      "Epoch 99/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 261.53it/s, loss=0.0737, mae=0.2484, rmse=0.2714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 99/100 Summary:\n",
      "  Train - Loss: 0.5193, MAE: 0.4814, RMSE: 0.7206, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  No improvement. Patience: 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/100 [Train]: 100%|██████████| 188/188 [00:01<00:00, 135.74it/s, loss=0.2900, mae=0.4995, rmse=0.5385]\n",
      "Epoch 100/100 [Val]: 100%|██████████| 38/38 [00:00<00:00, 268.78it/s, loss=0.0737, mae=0.2484, rmse=0.2714]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7476\\2033297674.py:59: UserWarning: Glyph 45936 (\\N{HANGUL SYLLABLE DE}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7476\\2033297674.py:59: UserWarning: Glyph 51060 (\\N{HANGUL SYLLABLE I}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7476\\2033297674.py:59: UserWarning: Glyph 53552 (\\N{HANGUL SYLLABLE TEO}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7476\\2033297674.py:59: UserWarning: Glyph 47564 (\\N{HANGUL SYLLABLE MAN}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/100 Summary:\n",
      "  Train - Loss: 0.5247, MAE: 0.4848, RMSE: 0.7244, MAPE: 0.00%\n",
      "  Val   - Loss: 0.3999, MAE: 0.4189, RMSE: 0.6324, MAPE: 0.00%\n",
      "  No improvement. Patience: 5/20\n",
      "\n",
      "✓ Loaded best model with Val RMSE: 0.6324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\envs\\AIproject\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 45936 (\\N{HANGUL SYLLABLE DE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\user\\miniconda3\\envs\\AIproject\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 51060 (\\N{HANGUL SYLLABLE I}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\user\\miniconda3\\envs\\AIproject\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 53552 (\\N{HANGUL SYLLABLE TEO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\user\\miniconda3\\envs\\AIproject\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 47564 (\\N{HANGUL SYLLABLE MAN}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Test]: 100%|██████████| 38/38 [00:00<00:00, 222.37it/s, loss=1.4412, mae=0.9142, rmse=1.2005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 테스트 세트 평가(회귀) ===\n",
      "Loss: 0.4690\n",
      "MAE : 0.4540\n",
      "RMSE: 0.6848\n",
      "MAPE: 135.95%\n",
      "R² (Output 1): 0.4034\n",
      "\n",
      "✓ Predictions denormalized\n",
      "  Original shape: (606, 1)\n",
      "  Denormalized shape: (606, 1)\n",
      "\n",
      "✓ Predictions saved to C:\\project_WWTP\\python\\results\\DL\\flow_predictions.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LSTMRegressor(\n",
       "   (lstm): LSTM(44, 64, num_layers=3, batch_first=True, dropout=0.2)\n",
       "   (attention): MultiheadAttention(\n",
       "     (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "   )\n",
       "   (head): Sequential(\n",
       "     (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Dropout(p=0.2, inplace=False)\n",
       "     (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "     (4): ReLU()\n",
       "     (5): Dropout(p=0.2, inplace=False)\n",
       "     (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "   )\n",
       " ),\n",
       " {'train_loss': [1.0156170279942454,\n",
       "   0.9959411473212143,\n",
       "   0.9471877228803932,\n",
       "   0.7901334399580956,\n",
       "   0.7283676823526621,\n",
       "   0.6988789698121448,\n",
       "   0.6731849570026001,\n",
       "   0.6691872466057539,\n",
       "   0.6540850236465534,\n",
       "   0.6413406006619334,\n",
       "   0.6289977492491404,\n",
       "   0.6182072410484155,\n",
       "   0.6108590578933557,\n",
       "   0.5981855906198422,\n",
       "   0.5951368898749352,\n",
       "   0.5816167276700338,\n",
       "   0.5749262943814198,\n",
       "   0.5645277821868658,\n",
       "   0.5622660551865896,\n",
       "   0.553703931748867,\n",
       "   0.5456115708549817,\n",
       "   0.543480455165108,\n",
       "   0.5369873698850472,\n",
       "   0.5395936877628168,\n",
       "   0.5351780703266462,\n",
       "   0.5293077647189299,\n",
       "   0.5315532610913117,\n",
       "   0.5287753719935815,\n",
       "   0.5371526059210301,\n",
       "   0.5280374051233133,\n",
       "   0.5265667503674825,\n",
       "   0.5258834212919077,\n",
       "   0.5237410558362802,\n",
       "   0.5253548344473044,\n",
       "   0.5227225743681192,\n",
       "   0.520879472369949,\n",
       "   0.5223779961665471,\n",
       "   0.5208701595614353,\n",
       "   0.5258278629084429,\n",
       "   0.5212301189402739,\n",
       "   0.5222400234043598,\n",
       "   0.5214415254890918,\n",
       "   0.5239304471313954,\n",
       "   0.5259451110213995,\n",
       "   0.5302896857758364,\n",
       "   0.5210355716745059,\n",
       "   0.5186819733480612,\n",
       "   0.5223047887682915,\n",
       "   0.5342140907843907,\n",
       "   0.5175805858771007,\n",
       "   0.5229573492805163,\n",
       "   0.5137957373758157,\n",
       "   0.5243147364705801,\n",
       "   0.5200406941274802,\n",
       "   0.5179011173496644,\n",
       "   0.5219677963455518,\n",
       "   0.5187175774176915,\n",
       "   0.519866760969162,\n",
       "   0.5232950713634491,\n",
       "   0.5208166382958491,\n",
       "   0.5168107086072365,\n",
       "   0.5310948551694552,\n",
       "   0.525203995709618,\n",
       "   0.5215316927880049,\n",
       "   0.5275805177390576,\n",
       "   0.5249384813904763,\n",
       "   0.5257761157204708,\n",
       "   0.5265304542034864,\n",
       "   0.5192818061461051,\n",
       "   0.5188424016038576,\n",
       "   0.5148587818990151,\n",
       "   0.5215105623801549,\n",
       "   0.5195766921242078,\n",
       "   0.5240534336417914,\n",
       "   0.522404182155927,\n",
       "   0.5196027206331492,\n",
       "   0.5139012651989857,\n",
       "   0.5153029668082794,\n",
       "   0.5299974100788435,\n",
       "   0.5157507094790538,\n",
       "   0.5196024976273378,\n",
       "   0.5233104806443055,\n",
       "   0.5236032849450906,\n",
       "   0.5293192704617977,\n",
       "   0.5219058455452323,\n",
       "   0.5232141424616178,\n",
       "   0.5201908058077097,\n",
       "   0.523607282012701,\n",
       "   0.5232039435158173,\n",
       "   0.5214396524926027,\n",
       "   0.5217793856859207,\n",
       "   0.5226231394708156,\n",
       "   0.5214289137820403,\n",
       "   0.5205088659524918,\n",
       "   0.5235347313384215,\n",
       "   0.5256256241897742,\n",
       "   0.5247282512187957,\n",
       "   0.5188694887707631,\n",
       "   0.5193102765331665,\n",
       "   0.5246964963028828],\n",
       "  'train_mae': [0.7002514251867931,\n",
       "   0.7123508498271306,\n",
       "   0.7327145599325497,\n",
       "   0.6457937449614207,\n",
       "   0.5983608091274897,\n",
       "   0.5794477058251699,\n",
       "   0.56528559923172,\n",
       "   0.559950773994128,\n",
       "   0.551277969400088,\n",
       "   0.5433003265857697,\n",
       "   0.5361425552765529,\n",
       "   0.5322564041217168,\n",
       "   0.5260643312136333,\n",
       "   0.5201845514376958,\n",
       "   0.5164181406100591,\n",
       "   0.5115799587567648,\n",
       "   0.5048802314201991,\n",
       "   0.5027303684949875,\n",
       "   0.4998228654464086,\n",
       "   0.4986367533604304,\n",
       "   0.49232570513089496,\n",
       "   0.4892876617511113,\n",
       "   0.487690394560496,\n",
       "   0.48913479220867156,\n",
       "   0.4881728655894597,\n",
       "   0.48382686007022857,\n",
       "   0.48547541348139445,\n",
       "   0.48614154573281604,\n",
       "   0.48806779670715333,\n",
       "   0.48538078427314757,\n",
       "   0.48472185349464414,\n",
       "   0.48307967297236126,\n",
       "   0.48229797979195915,\n",
       "   0.48371323823928836,\n",
       "   0.48441860075791676,\n",
       "   0.4820436656077703,\n",
       "   0.4812477364142736,\n",
       "   0.4808590706586838,\n",
       "   0.4848324670394262,\n",
       "   0.48064171270529427,\n",
       "   0.48144790224234263,\n",
       "   0.48271697481473286,\n",
       "   0.4823413817485174,\n",
       "   0.48333767406145733,\n",
       "   0.4875441575447718,\n",
       "   0.48198013389110567,\n",
       "   0.4802811580896378,\n",
       "   0.4831567231019338,\n",
       "   0.48849704213937123,\n",
       "   0.481215150197347,\n",
       "   0.4836352573633194,\n",
       "   0.4797767539024353,\n",
       "   0.48328385257720946,\n",
       "   0.480808843811353,\n",
       "   0.48116764549414315,\n",
       "   0.4841657291253408,\n",
       "   0.48298026172320047,\n",
       "   0.481615947842598,\n",
       "   0.4819949245452881,\n",
       "   0.48252072914441424,\n",
       "   0.4824836135307948,\n",
       "   0.48712090706825256,\n",
       "   0.48347125391165413,\n",
       "   0.48182980295022326,\n",
       "   0.48403448597590126,\n",
       "   0.48610579419136046,\n",
       "   0.4829007657766342,\n",
       "   0.48411468195915225,\n",
       "   0.48232273733615877,\n",
       "   0.4816779539585114,\n",
       "   0.48023073252042137,\n",
       "   0.4844460627237956,\n",
       "   0.4808805377483368,\n",
       "   0.48334960985183717,\n",
       "   0.48325372020403545,\n",
       "   0.48203761998812356,\n",
       "   0.479121129155159,\n",
       "   0.47841791713237763,\n",
       "   0.48637704412142435,\n",
       "   0.4776849897702535,\n",
       "   0.4835030540625254,\n",
       "   0.4838580162127813,\n",
       "   0.4825218452612559,\n",
       "   0.4843642429113388,\n",
       "   0.4842262164751689,\n",
       "   0.48325819869836173,\n",
       "   0.4839370818932851,\n",
       "   0.48420971747239433,\n",
       "   0.48429865296681723,\n",
       "   0.4818052275180817,\n",
       "   0.48168974403540293,\n",
       "   0.4822072747548421,\n",
       "   0.48410157350699107,\n",
       "   0.4825714936256409,\n",
       "   0.4825176362991333,\n",
       "   0.48451660271485647,\n",
       "   0.48636937018235527,\n",
       "   0.4813948920170466,\n",
       "   0.48138116478919984,\n",
       "   0.4848452482620875],\n",
       "  'train_rmse': [1.0077782633070855,\n",
       "   0.9979685101851733,\n",
       "   0.973235697495932,\n",
       "   0.8888945044031353,\n",
       "   0.8534445982913373,\n",
       "   0.8359898144188987,\n",
       "   0.8204784927117834,\n",
       "   0.8180386583809801,\n",
       "   0.808755230985589,\n",
       "   0.8008374371006475,\n",
       "   0.7930937833882827,\n",
       "   0.7862615602001763,\n",
       "   0.7815747295642022,\n",
       "   0.7734245862524944,\n",
       "   0.7714511584507053,\n",
       "   0.7626380056553921,\n",
       "   0.7582389428019507,\n",
       "   0.7513506386414174,\n",
       "   0.7498440205713383,\n",
       "   0.7441128487997415,\n",
       "   0.7386552449248442,\n",
       "   0.7372112690166287,\n",
       "   0.7327942206957198,\n",
       "   0.7345704103507144,\n",
       "   0.7315586581584871,\n",
       "   0.7275354044436119,\n",
       "   0.7290769925675283,\n",
       "   0.7271694245453266,\n",
       "   0.7329069558416198,\n",
       "   0.7266618230809386,\n",
       "   0.7256491923563909,\n",
       "   0.725178199680539,\n",
       "   0.7236995618599477,\n",
       "   0.7248136549812678,\n",
       "   0.7229955562575189,\n",
       "   0.7217198018413719,\n",
       "   0.7227572179968507,\n",
       "   0.7217133499952979,\n",
       "   0.7251398919577124,\n",
       "   0.7219626852824694,\n",
       "   0.7226617627938812,\n",
       "   0.7221090814337484,\n",
       "   0.7238303994247516,\n",
       "   0.7252207326196621,\n",
       "   0.728209918756835,\n",
       "   0.7218279377209681,\n",
       "   0.7201957882048889,\n",
       "   0.7227065716930291,\n",
       "   0.7308995079929872,\n",
       "   0.7194307373730293,\n",
       "   0.723157900655532,\n",
       "   0.7167954641149843,\n",
       "   0.7240958061407207,\n",
       "   0.7211384708414053,\n",
       "   0.7196534703242001,\n",
       "   0.7224733879843269,\n",
       "   0.7202205061074639,\n",
       "   0.721017864528447,\n",
       "   0.7233913680459901,\n",
       "   0.7216762697330772,\n",
       "   0.7188954782214425,\n",
       "   0.7287625506085335,\n",
       "   0.7247095940510364,\n",
       "   0.7221715120302136,\n",
       "   0.7263473808991519,\n",
       "   0.7245263841920985,\n",
       "   0.725104210248755,\n",
       "   0.725624182482562,\n",
       "   0.7206121051898207,\n",
       "   0.7203071578180087,\n",
       "   0.7175366066613014,\n",
       "   0.7221568821109129,\n",
       "   0.7208166841328021,\n",
       "   0.7239153497763335,\n",
       "   0.7227753331125288,\n",
       "   0.7208347387807758,\n",
       "   0.716869071169196,\n",
       "   0.7178460606622281,\n",
       "   0.7280092101607256,\n",
       "   0.7181578583285528,\n",
       "   0.7208345840949488,\n",
       "   0.723402018689681,\n",
       "   0.7236043704574279,\n",
       "   0.7275433117428801,\n",
       "   0.7224305126067367,\n",
       "   0.7233354287338744,\n",
       "   0.7212425429823934,\n",
       "   0.7236071323672127,\n",
       "   0.723328378757406,\n",
       "   0.7221077845395399,\n",
       "   0.7223429834129496,\n",
       "   0.7229267870751613,\n",
       "   0.7221003488311304,\n",
       "   0.7214630038695621,\n",
       "   0.7235569993707625,\n",
       "   0.7250004304755786,\n",
       "   0.7243812885620361,\n",
       "   0.7203259600838797,\n",
       "   0.7206318592271413,\n",
       "   0.7243593695831392],\n",
       "  'train_mape': [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  'val_loss': [0.9501195028789865,\n",
       "   0.8256998527271688,\n",
       "   0.6537335153946207,\n",
       "   0.48432613532405255,\n",
       "   0.49164783623346614,\n",
       "   0.4994713113389232,\n",
       "   0.49817439171154637,\n",
       "   0.4961824655532837,\n",
       "   0.4908812728179388,\n",
       "   0.48305670397956507,\n",
       "   0.4847911577517829,\n",
       "   0.4775190352593079,\n",
       "   0.4722790912347884,\n",
       "   0.462378956045001,\n",
       "   0.4497586719137578,\n",
       "   0.444174618329391,\n",
       "   0.4366669076287057,\n",
       "   0.4310238723666215,\n",
       "   0.4243091518351854,\n",
       "   0.41867163766267873,\n",
       "   0.41588319980901134,\n",
       "   0.4125622925556396,\n",
       "   0.41057193915952334,\n",
       "   0.4092680016086121,\n",
       "   0.4074856589402049,\n",
       "   0.4062982868557134,\n",
       "   0.4054990181129826,\n",
       "   0.40423039850617243,\n",
       "   0.40349702045690916,\n",
       "   0.40350951436629967,\n",
       "   0.40294522735451865,\n",
       "   0.40259048049607554,\n",
       "   0.4022515746249148,\n",
       "   0.4021032656458291,\n",
       "   0.4015762199301365,\n",
       "   0.40131860690052845,\n",
       "   0.40110565414113447,\n",
       "   0.40080919952308836,\n",
       "   0.40073119910541644,\n",
       "   0.4005162905008832,\n",
       "   0.40047008361328734,\n",
       "   0.40046011862183406,\n",
       "   0.40039193865435185,\n",
       "   0.4003540654074062,\n",
       "   0.4002691924941441,\n",
       "   0.4002130944312604,\n",
       "   0.40017070735781646,\n",
       "   0.40013533301097304,\n",
       "   0.40010884470683483,\n",
       "   0.40006253441626377,\n",
       "   0.4000436063948249,\n",
       "   0.40002945641840787,\n",
       "   0.40001560073992437,\n",
       "   0.4000051686216977,\n",
       "   0.39997417120155226,\n",
       "   0.3999672452218769,\n",
       "   0.3999595354411228,\n",
       "   0.3999457398044669,\n",
       "   0.3999405401858909,\n",
       "   0.39993724047768214,\n",
       "   0.39992613607694294,\n",
       "   0.39991821257536075,\n",
       "   0.399912286445129,\n",
       "   0.3999101792546836,\n",
       "   0.3999058778867249,\n",
       "   0.3999027108050082,\n",
       "   0.39990073241724455,\n",
       "   0.39989591203937846,\n",
       "   0.39989345827994266,\n",
       "   0.39989231810096865,\n",
       "   0.3998912368431564,\n",
       "   0.3998901404255678,\n",
       "   0.39988889215160006,\n",
       "   0.39988785402095023,\n",
       "   0.3998864863529678,\n",
       "   0.3998861267300677,\n",
       "   0.3998859333474774,\n",
       "   0.3998856283293283,\n",
       "   0.3998853354291482,\n",
       "   0.3998850413097823,\n",
       "   0.3998849696856885,\n",
       "   0.3998848446021395,\n",
       "   0.399884796690596,\n",
       "   0.3998847729657307,\n",
       "   0.3998846957136777,\n",
       "   0.3998846747165869,\n",
       "   0.39988465782655175,\n",
       "   0.3998846525926728,\n",
       "   0.3998846385104597,\n",
       "   0.39988462022267096,\n",
       "   0.3998846278210317,\n",
       "   0.39988460875739734,\n",
       "   0.3998846095209279,\n",
       "   0.3998846043978841,\n",
       "   0.39988459065433374,\n",
       "   0.39988459979207064,\n",
       "   0.3998846040407488,\n",
       "   0.399884597636944,\n",
       "   0.39988459936720283,\n",
       "   0.39988460234127754],\n",
       "  'val_mae': [0.6026996989388111,\n",
       "   0.6666593591043771,\n",
       "   0.5975437968230445,\n",
       "   0.4558399690084221,\n",
       "   0.4517410191622647,\n",
       "   0.45172529575253323,\n",
       "   0.4500065543434837,\n",
       "   0.4473886726316342,\n",
       "   0.44342009883281613,\n",
       "   0.43814265885628945,\n",
       "   0.43678677889926376,\n",
       "   0.43306950557330426,\n",
       "   0.4309611773687946,\n",
       "   0.4285010266895137,\n",
       "   0.42607310606428417,\n",
       "   0.4252598512271219,\n",
       "   0.42397842505746636,\n",
       "   0.4226696932611387,\n",
       "   0.4215219391278984,\n",
       "   0.42044934792952104,\n",
       "   0.4198070234503628,\n",
       "   0.41908668870768273,\n",
       "   0.41893941390612893,\n",
       "   0.4187628187423895,\n",
       "   0.41911857798079816,\n",
       "   0.41877661224239127,\n",
       "   0.4187657470545493,\n",
       "   0.4186387460093853,\n",
       "   0.4186714964464676,\n",
       "   0.41887680479317657,\n",
       "   0.4188314904851362,\n",
       "   0.4189324489309768,\n",
       "   0.4189726248260372,\n",
       "   0.4188415841622786,\n",
       "   0.41881162095661006,\n",
       "   0.41889348049794345,\n",
       "   0.4188994488440269,\n",
       "   0.4188821558124763,\n",
       "   0.4188591634931643,\n",
       "   0.41888541328020334,\n",
       "   0.4188945437265822,\n",
       "   0.4188898280632397,\n",
       "   0.4188902820437408,\n",
       "   0.41890047709803935,\n",
       "   0.4188848208789983,\n",
       "   0.41889001466025994,\n",
       "   0.4188933788252271,\n",
       "   0.4188886500587148,\n",
       "   0.4188911457692296,\n",
       "   0.4188976197203329,\n",
       "   0.41889771075288124,\n",
       "   0.4189033583176037,\n",
       "   0.4189106052572077,\n",
       "   0.41891611942574997,\n",
       "   0.41890741271420945,\n",
       "   0.4189059150120443,\n",
       "   0.4189056780712664,\n",
       "   0.4189051897072595,\n",
       "   0.418909061447648,\n",
       "   0.41891008113041395,\n",
       "   0.4189091694256491,\n",
       "   0.4189083233352535,\n",
       "   0.4189076046313136,\n",
       "   0.418908872387626,\n",
       "   0.41891080663223895,\n",
       "   0.41890991364628816,\n",
       "   0.41890919720830994,\n",
       "   0.41890799743084867,\n",
       "   0.41890849042529904,\n",
       "   0.4189088033250541,\n",
       "   0.4189088981013653,\n",
       "   0.4189086405698918,\n",
       "   0.4189083580143195,\n",
       "   0.41890812136910177,\n",
       "   0.41890820156444203,\n",
       "   0.41890815604816783,\n",
       "   0.4189081997910807,\n",
       "   0.4189082224506977,\n",
       "   0.41890818067818636,\n",
       "   0.418908148265082,\n",
       "   0.41890812747734635,\n",
       "   0.41890810481772933,\n",
       "   0.41890811092597396,\n",
       "   0.4189080924042,\n",
       "   0.418908068365302,\n",
       "   0.41890805398137115,\n",
       "   0.41890805614881277,\n",
       "   0.41890804531160464,\n",
       "   0.41890803999152065,\n",
       "   0.41890803210991473,\n",
       "   0.4189080328980753,\n",
       "   0.4189080330951155,\n",
       "   0.4189080433412032,\n",
       "   0.41890804077968125,\n",
       "   0.4189080394004002,\n",
       "   0.4189080395974404,\n",
       "   0.4189080396959604,\n",
       "   0.4189080360507177,\n",
       "   0.4189080388092798,\n",
       "   0.4189080420604422],\n",
       "  'val_rmse': [0.9747407362330043,\n",
       "   0.9086802808000478,\n",
       "   0.8085378873901709,\n",
       "   0.6959354389957179,\n",
       "   0.7011760379465085,\n",
       "   0.7067328429527919,\n",
       "   0.7058147006822905,\n",
       "   0.704402204392692,\n",
       "   0.7006291977618144,\n",
       "   0.6950228082397063,\n",
       "   0.6962694576699816,\n",
       "   0.6910275213338724,\n",
       "   0.6872256479616545,\n",
       "   0.6799845263457331,\n",
       "   0.6706404937645898,\n",
       "   0.6664642662543325,\n",
       "   0.660807769006574,\n",
       "   0.656524083558807,\n",
       "   0.6513901686758102,\n",
       "   0.6470484043725814,\n",
       "   0.6448900678980459,\n",
       "   0.6423101217434336,\n",
       "   0.640758877463815,\n",
       "   0.6397405736385274,\n",
       "   0.6383460338371147,\n",
       "   0.6374153173030621,\n",
       "   0.6367880479422863,\n",
       "   0.6357911594286699,\n",
       "   0.6352141532149564,\n",
       "   0.6352239874782591,\n",
       "   0.634779668353137,\n",
       "   0.6345001815680358,\n",
       "   0.6342330601117461,\n",
       "   0.634116129376153,\n",
       "   0.6337004180459537,\n",
       "   0.6334971245703909,\n",
       "   0.6333290251747661,\n",
       "   0.6330949371338933,\n",
       "   0.6330333316907778,\n",
       "   0.6328635638618629,\n",
       "   0.632827056540835,\n",
       "   0.6328191831967754,\n",
       "   0.6327653108518251,\n",
       "   0.6327353833327176,\n",
       "   0.6326683115153027,\n",
       "   0.6326239755522829,\n",
       "   0.6325904735469475,\n",
       "   0.6325625130178897,\n",
       "   0.6325415753990521,\n",
       "   0.6325049678984852,\n",
       "   0.6324900048691361,\n",
       "   0.632478818919229,\n",
       "   0.632467865303372,\n",
       "   0.6324596180676143,\n",
       "   0.6324351122362176,\n",
       "   0.6324296365290781,\n",
       "   0.6324235410845904,\n",
       "   0.6324126341083304,\n",
       "   0.6324085230982983,\n",
       "   0.6324059142895662,\n",
       "   0.6323971347694642,\n",
       "   0.6323908700040867,\n",
       "   0.6323861844903744,\n",
       "   0.6323845184933401,\n",
       "   0.6323811175918561,\n",
       "   0.6323786133969571,\n",
       "   0.6323770492492944,\n",
       "   0.6323732379020703,\n",
       "   0.6323712977989614,\n",
       "   0.6323703962486769,\n",
       "   0.6323695413528718,\n",
       "   0.6323686743525628,\n",
       "   0.6323676874469236,\n",
       "   0.6323668665790928,\n",
       "   0.632365785229038,\n",
       "   0.6323655008817588,\n",
       "   0.6323653479873501,\n",
       "   0.6323651068051575,\n",
       "   0.6323648751848676,\n",
       "   0.6323646425712914,\n",
       "   0.6323645859880188,\n",
       "   0.6323644870768238,\n",
       "   0.6323644491744937,\n",
       "   0.6323644305032745,\n",
       "   0.6323643693921509,\n",
       "   0.6323643527998372,\n",
       "   0.6323643393867429,\n",
       "   0.6323643352581387,\n",
       "   0.6323643241235661,\n",
       "   0.6323643096539769,\n",
       "   0.6323643157397733,\n",
       "   0.6323643006664729,\n",
       "   0.6323643011922857,\n",
       "   0.6323642972097405,\n",
       "   0.6323642863624169,\n",
       "   0.6323642935582626,\n",
       "   0.6323642969176223,\n",
       "   0.6323642917763415,\n",
       "   0.6323642932223267,\n",
       "   0.6323642956030903],\n",
       "  'val_mape': [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  'best_val_rmse': 0.6323642863624169},\n",
       " {'loss': 0.4689771345149566,\n",
       "  'mae': 0.45402440418898077,\n",
       "  'rmse': 0.6848190518144895,\n",
       "  'mape': 135.95087111192962,\n",
       "  'r2': [np.float32(0.4034251)]})"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
