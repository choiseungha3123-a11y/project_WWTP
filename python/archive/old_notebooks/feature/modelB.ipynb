{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d36ea16d",
   "metadata": {},
   "source": [
    "### 강우 기반 파생\n",
    "\n",
    "#### 강수 변화율·집중도\n",
    "\n",
    "- ΔRN_15m, ΔRN_60m, ΔRN_12H\n",
    "\n",
    "- RN_15m / RN_60m (단기 집중도)\n",
    "\n",
    "#### 누적 강수 메모리(Antecedent Rainfall / AR)\n",
    "\n",
    "- AR_3H, AR_6H, AR_12H, AR_24H = Σ RN_15m(최근 x시간)\n",
    "\n",
    "- log(1 + AR_x)\n",
    "\n",
    "#### 무강수 지속시간 + first flush\n",
    "\n",
    "- dry_duration_h (마지막 강수 이후 경과 시간)\n",
    "\n",
    "- rain_start / rain_end 플래그\n",
    "\n",
    "- post_rain_6H 플래그(종료 후 잔류 효과)\n",
    "\n",
    "#### API 지수(감쇠 누적)\n",
    "\n",
    "- API(RN_15m, k, N) = Σ RN_15m(t−i)·exp(−k·i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "22ef301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "20e70b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_rain_features(X, station_ids, rain_cols, rule, antecedent_hours, wet_thr_mm, eps, add_api, api_k, api_hours):\n",
    "    \"\"\"강수 관련 특성 생성\"\"\"\n",
    "    new_cols = {}\n",
    "    \n",
    "    # steps_per_hour 계산\n",
    "    steps_per_hour = int(pd.Timedelta(\"1h\") / pd.Timedelta(rule))\n",
    "    \n",
    "    # Delta (변화율) - 시간을 스텝으로 변환\n",
    "    delta_map = {\"RN_15m\": 3, \"RN_60m\": 12, \"RN_12H\": 144}  # 5분 기준 스텝 수\n",
    "    for sid in station_ids:\n",
    "        for rc in rain_cols[:3]:  # RN_15m, RN_60m, RN_12H만\n",
    "            col = f\"{rc}_{sid}\"\n",
    "            if col in X.columns:\n",
    "                new_cols[f\"d_{col}\"] = X[col].diff(delta_map[rc])\n",
    "    \n",
    "    # Intensity ratio (단기 집중도)\n",
    "    for sid in station_ids:\n",
    "        rn15 = f\"RN_15m_{sid}\"\n",
    "        rn60 = f\"RN_60m_{sid}\"\n",
    "        if rn15 in X.columns and rn60 in X.columns:\n",
    "            new_cols[f\"RN_15m_div_RN_60m_{sid}\"] = X[rn15] / (X[rn60] + eps)\n",
    "    \n",
    "    # Antecedent rainfall (누적 강수)\n",
    "    for sid in station_ids:\n",
    "        col = f\"RN_15m_{sid}\"\n",
    "        if col in X.columns:\n",
    "            for h in antecedent_hours:\n",
    "                win = h * steps_per_hour\n",
    "                ar_col = X[col].rolling(win, min_periods=max(2, win // 10)).sum()\n",
    "                new_cols[f\"AR_{h}H_{sid}\"] = ar_col\n",
    "                new_cols[f\"log1p_AR_{h}H_{sid}\"] = np.log1p(ar_col)\n",
    "    \n",
    "    # Dry duration + first flush\n",
    "    for sid in station_ids:\n",
    "        col = f\"RN_15m_{sid}\"\n",
    "        if col in X.columns:\n",
    "            wet = (X[col].fillna(0) >= wet_thr_mm)\n",
    "            last_wet_ts = pd.Series(X.index.where(wet), index=X.index).ffill()\n",
    "            dry_timedelta = (X.index - last_wet_ts)\n",
    "            \n",
    "            new_cols[f\"dry_duration_min_{sid}\"] = dry_timedelta.dt.total_seconds().fillna(0) / 60.0\n",
    "            new_cols[f\"dry_duration_hr_{sid}\"] = dry_timedelta.dt.total_seconds().fillna(0) / 3600.0\n",
    "            new_cols[f\"is_wet_{sid}\"] = wet.astype(np.int8)\n",
    "            \n",
    "            # First flush 힌트\n",
    "            rain_start = wet & (~wet.shift(1, fill_value=False))\n",
    "            rain_end = (~wet) & (wet.shift(1, fill_value=False))\n",
    "            new_cols[f\"rain_start_{sid}\"] = rain_start.astype(np.int8)\n",
    "            new_cols[f\"rain_end_{sid}\"] = rain_end.astype(np.int8)\n",
    "            \n",
    "            # 종료 후 6시간 잔류\n",
    "            post_win = 6 * steps_per_hour\n",
    "            new_cols[f\"post_rain_6H_{sid}\"] = (\n",
    "                pd.Series(rain_end.values, index=X.index)\n",
    "                .rolling(post_win, min_periods=1).max()\n",
    "                .fillna(0).astype(np.int8)\n",
    "            )\n",
    "    \n",
    "    # API (감쇠 누적) - 선택적\n",
    "    if add_api:\n",
    "        api_steps = api_hours * steps_per_hour\n",
    "        weights = np.exp(-api_k * np.arange(1, api_steps + 1, dtype=np.float32))\n",
    "        for sid in station_ids:\n",
    "            col = f\"RN_15m_{sid}\"\n",
    "            if col in X.columns:\n",
    "                rain = X[col].to_numpy(dtype=np.float32)\n",
    "                api = np.full_like(rain, np.nan, dtype=np.float32)\n",
    "                for t in range(len(rain)):\n",
    "                    start = max(0, t - api_steps)\n",
    "                    seg = rain[start:t]\n",
    "                    if seg.size == 0:\n",
    "                        api[t] = 0.0\n",
    "                    else:\n",
    "                        w = weights[-seg.size:]\n",
    "                        api[t] = float(np.sum(seg[::-1] * w))\n",
    "                new_cols[f\"API_RN_15m_k{api_k}_H{api_hours}_{sid}\"] = api\n",
    "    \n",
    "    X = pd.concat([X, pd.DataFrame(new_cols, index=X.index)], axis=1)\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "85fe41c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_areal_rain_features(X, station_ids, rain_cols, eps=1e-6):\n",
    "    \"\"\"관측소 강수를 면적강수(평균/최대)로 요약\"\"\"\n",
    "    new_cols = {}\n",
    "\n",
    "    for rc in rain_cols:\n",
    "        cols = [f\"{rc}_{sid}\" for sid in station_ids if f\"{rc}_{sid}\" in X.columns]\n",
    "        if not cols:\n",
    "            continue\n",
    "\n",
    "        # 평균/최대 면적강수\n",
    "        new_cols[f\"{rc}_areal_mean\"] = X[cols].mean(axis=1)\n",
    "        new_cols[f\"{rc}_areal_max\"]  = X[cols].max(axis=1)\n",
    "\n",
    "        # 공간 불일치(국지성) 지표: max-mean, std\n",
    "        new_cols[f\"{rc}_areal_max_minus_mean\"] = new_cols[f\"{rc}_areal_max\"] - new_cols[f\"{rc}_areal_mean\"]\n",
    "        new_cols[f\"{rc}_areal_std\"] = X[cols].std(axis=1, ddof=0)\n",
    "\n",
    "    # 면적강수 집중도(areal)\n",
    "    if \"RN_15m_areal_mean\" in new_cols and \"RN_60m_areal_mean\" in new_cols:\n",
    "        new_cols[\"RN_15m_div_RN_60m_areal_mean\"] = new_cols[\"RN_15m_areal_mean\"] / (new_cols[\"RN_60m_areal_mean\"] + eps)\n",
    "\n",
    "    X = pd.concat([X, pd.DataFrame(new_cols, index=X.index)], axis=1)\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a815a4e",
   "metadata": {},
   "source": [
    "### 기상 파생\n",
    "\n",
    "#### 열·습 결합\n",
    "\n",
    "- DewPointDepression = TA − TD (추천)\n",
    "\n",
    "(선택) VPD proxy / HeatIndex (효과는 케이스바이케이스 → uncertain)\n",
    "\n",
    "#### 기상 안정성(변동성)\n",
    "\n",
    "- rolling_std(TA, 3H/6H)\n",
    "\n",
    "- rolling_std(HM, 3H/6H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2b0b9a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_weather_features(X, station_ids, weather_cols, rule, stability_windows, eps):\n",
    "    \"\"\"기상 관련 특성 생성\"\"\"\n",
    "    new_cols = {}\n",
    "    steps_per_hour = int(pd.Timedelta(\"1h\") / pd.Timedelta(rule))\n",
    "    \n",
    "    for sid in station_ids:\n",
    "        ta_col = f\"TA_{sid}\"\n",
    "        td_col = f\"TD_{sid}\"\n",
    "        hm_col = f\"HM_{sid}\"\n",
    "        \n",
    "        # Dew point depression\n",
    "        if ta_col in X.columns and td_col in X.columns:\n",
    "            new_cols[f\"TA_minus_TD_{sid}\"] = X[ta_col] - X[td_col]\n",
    "        \n",
    "        # VPD \n",
    "        if ta_col in X.columns and hm_col in X.columns:\n",
    "            T = X[ta_col]\n",
    "            RH = X[hm_col].clip(0, 100)\n",
    "            e_s = 0.6108 * np.exp((17.27 * T) / (T + 237.3))\n",
    "            new_cols[f\"VPD_kPa_{sid}\"] = e_s * (1 - RH / 100.0)\n",
    "        \n",
    "        # Stability (rolling std)\n",
    "        for c in [ta_col, hm_col]:\n",
    "            if c not in X.columns:\n",
    "                continue\n",
    "            for w in stability_windows:\n",
    "                win_steps = int(pd.Timedelta(w) / pd.Timedelta(rule))\n",
    "                minp = max(2, int(win_steps * 0.1))\n",
    "                new_cols[f\"{c}_std_{w}\"] = X[c].rolling(win_steps, min_periods=minp).std(ddof=0)\n",
    "    \n",
    "    X = pd.concat([X, pd.DataFrame(new_cols, index=X.index)], axis=1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f65cac",
   "metadata": {},
   "source": [
    "### 시계열 메모리: lag & rolling\n",
    "\n",
    "#### Lag features\n",
    "\n",
    "추천 lag:\n",
    "\n",
    "- 10min, 30min, 60min\n",
    "\n",
    "적용 컬럼:\n",
    "\n",
    "- PH_VU, FLUX_VU, SS_VU, TOC_VU, TA, RN_15m(또는 RN_60m)\n",
    "\n",
    "- (선택) TN_lag, TP_lag (누수 아님)\n",
    "\n",
    "#### Rolling 통계량\n",
    "\n",
    "윈도우:\n",
    "\n",
    "- 30min, 60min, 3H\n",
    "\n",
    "통계:\n",
    "\n",
    "- rolling_mean, rolling_std, rolling_max (강우는 rolling_sum도 추가)\n",
    "\n",
    "적용 컬럼:\n",
    "\n",
    "- PH_VU, FLUX_VU, SS_VU, TOC_VU, RN_15m, TA/HM\n",
    "\n",
    "#### 변화율(derivative)\n",
    "\n",
    "- ΔPH, ΔFLUX, ΔSS, ΔTOC, ΔTA\n",
    "\n",
    "- |ΔFLUX| (급변 여부)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "67ae56ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_lag_roll_delta_features(X, process_cols, station_ids, rain_cols, weather_cols, rule, lag_list, roll_windows, eps):\n",
    "    \"\"\"시계열 특성 (lag, rolling, delta) 생성\"\"\"\n",
    "    new_cols = {}\n",
    "    \n",
    "    # 대상 컬럼 구성\n",
    "    base_cols = list(process_cols) + [f\"{wc}_{sid}\" for sid in station_ids for wc in weather_cols]\n",
    "    base_cols += [f\"RN_15m_{sid}\" for sid in station_ids]\n",
    "    base_cols = [c for c in base_cols if c in X.columns]\n",
    "    \n",
    "    # Lag\n",
    "    for c in base_cols:\n",
    "        for L in lag_list:\n",
    "            lag_steps = int(pd.Timedelta(L) / pd.Timedelta(rule))\n",
    "            new_cols[f\"{c}_lag_{L}\"] = X[c].shift(lag_steps)\n",
    "        \n",
    "        # Delta\n",
    "        new_cols[f\"d_{c}\"] = X[c].diff()\n",
    "    \n",
    "    # Abs delta (급변 여부)\n",
    "    if \"FLUX_VU\" in X.columns:\n",
    "        new_cols[\"abs_d_FLUX_VU\"] = X[\"FLUX_VU\"].diff().abs()\n",
    "    \n",
    "    # Rolling\n",
    "    for c in base_cols:\n",
    "        for w in roll_windows:\n",
    "            win_steps = int(pd.Timedelta(w) / pd.Timedelta(rule))\n",
    "            minp = max(2, int(win_steps * 0.1))\n",
    "            r = X[c].rolling(win_steps, min_periods=minp)\n",
    "            new_cols[f\"{c}_roll_mean_{w}\"] = r.mean()\n",
    "            new_cols[f\"{c}_roll_std_{w}\"] = r.std(ddof=0)\n",
    "            new_cols[f\"{c}_roll_max_{w}\"] = r.max()\n",
    "    \n",
    "    X = pd.concat([X, pd.DataFrame(new_cols, index=X.index)], axis=1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931d28e0",
   "metadata": {},
   "source": [
    "### 공정·수질 결합 특성 (누수 없이 재설계)\n",
    "\n",
    "#### 부하(load) 계열 (아주 중요)\n",
    "\n",
    "- SS_load = FLUX_VU × SS_VU\n",
    "\n",
    "- TOC_load = FLUX_VU × TOC_VU\n",
    "\n",
    "- FLUX_VU × (SS_VU + TOC_VU)\n",
    "\n",
    "#### 상호작용(interaction)\n",
    "\n",
    "- RN_15m × FLUX_VU\n",
    "\n",
    "- dry_duration_h × RN_15m\n",
    "\n",
    "- RN_60m × SS_lag (예: SS_lag_10m)\n",
    "\n",
    "- PH_VU × TOC_VU\n",
    "\n",
    "- SS_VU × FLUX_VU\n",
    "\n",
    "#### 비율(ratio) \n",
    "\n",
    "- TOC_VU / SS_VU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "63afa030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_process_features(X, process_cols, rule, spike_z, spike_window, eps):\n",
    "    \"\"\"공정 관련 특성 생성\"\"\"\n",
    "    new_cols = {}\n",
    "    \n",
    "    # Load (부하)\n",
    "    if all(c in X.columns for c in [\"FLUX_VU\", \"SS_VU\"]):\n",
    "        new_cols[\"SS_load\"] = X[\"FLUX_VU\"] * X[\"SS_VU\"]\n",
    "    \n",
    "    if all(c in X.columns for c in [\"FLUX_VU\", \"TOC_VU\"]):\n",
    "        new_cols[\"TOC_load\"] = X[\"FLUX_VU\"] * X[\"TOC_VU\"]\n",
    "    \n",
    "    # Interactions\n",
    "    if all(c in X.columns for c in [\"PH_VU\", \"TOC_VU\"]):\n",
    "        new_cols[\"PH_x_TOC\"] = X[\"PH_VU\"] * X[\"TOC_VU\"]\n",
    "    \n",
    "    if all(c in X.columns for c in [\"SS_VU\", \"FLUX_VU\"]):\n",
    "        new_cols[\"SS_x_FLUX\"] = X[\"SS_VU\"] * X[\"FLUX_VU\"]\n",
    "    \n",
    "    # Ratios\n",
    "    if all(c in X.columns for c in [\"TOC_VU\", \"SS_VU\"]):\n",
    "        new_cols[\"TOC_div_SS\"] = X[\"TOC_VU\"] / (X[\"SS_VU\"] + eps)\n",
    "    \n",
    "    # pH zone\n",
    "    if \"PH_VU\" in X.columns:\n",
    "        ph = X[\"PH_VU\"]\n",
    "        zone = pd.cut(ph, bins=[-np.inf, 6.5, 7.5, np.inf], labels=[0, 1, 2])\n",
    "        new_cols[\"PH_zone\"] = zone.astype(\"float\").fillna(1).astype(np.int8)\n",
    "    \n",
    "    # Spike flags\n",
    "    steps_per_hour = int(pd.Timedelta(\"1h\") / pd.Timedelta(rule))\n",
    "    win_steps = int(pd.Timedelta(spike_window) / pd.Timedelta(rule))\n",
    "    minp = max(5, int(win_steps * 0.1))\n",
    "    \n",
    "    spike_cols = [\"SS_VU\", \"TOC_VU\", \"PH_VU\", \"FLUX_VU\"]\n",
    "    for c in spike_cols:\n",
    "        if c not in X.columns:\n",
    "            continue\n",
    "        mu = X[c].rolling(win_steps, min_periods=minp).mean()\n",
    "        sd = X[c].rolling(win_steps, min_periods=minp).std(ddof=0)\n",
    "        z = (X[c] - mu) / (sd + eps)\n",
    "        new_cols[f\"{c}_spike_z{spike_z:g}\"] = (z > spike_z).astype(np.int8)\n",
    "    \n",
    "    X = pd.concat([X, pd.DataFrame(new_cols, index=X.index)], axis=1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "26f52832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_rain_process_interactions(X, station_ids, eps):\n",
    "    \"\"\"강수-공정 상호작용 특성 생성\"\"\"\n",
    "    new_cols = {}\n",
    "    \n",
    "    for sid in station_ids:\n",
    "        rn15 = f\"RN_15m_{sid}\"\n",
    "        rn60 = f\"RN_60m_{sid}\"\n",
    "        dry = f\"dry_duration_hr_{sid}\"\n",
    "        \n",
    "        if \"FLUX_VU\" in X.columns and rn15 in X.columns:\n",
    "            new_cols[f\"RN_15m_x_FLUX_{sid}\"] = X[rn15] * X[\"FLUX_VU\"]\n",
    "        \n",
    "        if dry in X.columns and rn15 in X.columns:\n",
    "            new_cols[f\"dry_x_RN_15m_{sid}\"] = X[dry] * X[rn15]\n",
    "        \n",
    "        if rn60 in X.columns and f\"{rn15}_lag_10min\" in X.columns:\n",
    "            new_cols[f\"RN_60m_x_RN15lag10_{sid}\"] = X[rn60] * X[f\"{rn15}_lag_10min\"]\n",
    "    \n",
    "    X = pd.concat([X, pd.DataFrame(new_cols, index=X.index)], axis=1)\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b564ce4",
   "metadata": {},
   "source": [
    "### 시간(주기) 특성 (안 넣으면 손해)\n",
    "\n",
    "- hour_sin, hour_cos\n",
    "\n",
    "- is_weekend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e1e4f296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_time_features(X):\n",
    "    \"\"\"시간 관련 특성 생성\"\"\"\n",
    "    new_cols = {}\n",
    "    \n",
    "    new_cols[\"hour\"] = X.index.hour.astype(np.int16)\n",
    "    new_cols[\"dow\"] = X.index.dayofweek.astype(np.int8)\n",
    "    new_cols[\"is_weekend\"] = (X.index.dayofweek >= 5).astype(np.int8)\n",
    "    \n",
    "    # Cyclical encoding\n",
    "    hour_values = X.index.hour\n",
    "    new_cols[\"hour_sin\"] = np.sin(2 * np.pi * hour_values / 24.0)\n",
    "    new_cols[\"hour_cos\"] = np.cos(2 * np.pi * hour_values / 24.0)\n",
    "\n",
    "    # Cyclical encoding (연중)\n",
    "    doy = X.index.dayofyear\n",
    "    new_cols[\"doy_sin\"] = np.sin(2 * np.pi * doy / 365.25)\n",
    "    new_cols[\"doy_cos\"] = np.cos(2 * np.pi * doy / 365.25)\n",
    "    \n",
    "    X = pd.concat([X, pd.DataFrame(new_cols, index=X.index)], axis=1)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ee0bd5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_5min(\n",
    "    df,\n",
    "    time_col=None,\n",
    "    rule=\"5min\",\n",
    "    sum_cols=None,\n",
    "    mean_cols=None,\n",
    "    extra_mean_cols=(),\n",
    "    interp_limit: int = 12,\n",
    "):\n",
    "    \"\"\"\n",
    "    1분(or irregular) -> 5분 리샘플링.\n",
    "    \"\"\"\n",
    "    x = df.copy()\n",
    "\n",
    "    if time_col is not None:\n",
    "        x[time_col] = pd.to_datetime(x[time_col])\n",
    "        x = x.set_index(time_col)\n",
    "    if not isinstance(x.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"df must have a DatetimeIndex or provide time_col.\")\n",
    "    x = x.sort_index()\n",
    "\n",
    "    # 숫자화\n",
    "    all_cols = set(sum_cols or []) | set(mean_cols or []) | set(extra_mean_cols)\n",
    "    for c in all_cols:\n",
    "        if c in x.columns:\n",
    "            x[c] = pd.to_numeric(x[c], errors=\"coerce\")\n",
    "\n",
    "    # 집계 dict\n",
    "    agg = {}\n",
    "    for c in sum_cols or []:\n",
    "        if c in x.columns:\n",
    "            agg[c] = \"sum\"\n",
    "    for c in list(mean_cols or []) + list(extra_mean_cols):\n",
    "        if c in x.columns:\n",
    "            agg[c] = \"mean\"\n",
    "\n",
    "    if not agg:\n",
    "        raise ValueError(\"No columns found to resample.\")\n",
    "\n",
    "    # 리샘플\n",
    "    out = x.resample(rule).agg(agg)\n",
    "\n",
    "    # 결측 처리\n",
    "    for c in sum_cols or []:\n",
    "        if c in out.columns:\n",
    "            out[c] = out[c].fillna(0.0)\n",
    "\n",
    "    for c in list(mean_cols or []) + list(extra_mean_cols):\n",
    "        if c in out.columns:\n",
    "            out[c] = out[c].interpolate(method=\"time\", limit=interp_limit)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "74f09ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_modelB_features(\n",
    "    df,\n",
    "    time_col=None,\n",
    "    do_resample=True,\n",
    "    rule=\"5min\",\n",
    "    station_ids=(\"368\", \"541\", \"569\"),\n",
    "    rain_cols=(\"RN_15m\", \"RN_60m\", \"RN_12H\", \"RN_DAY\"),\n",
    "    weather_cols=(\"TA\", \"HM\", \"TD\"),\n",
    "    process_cols=(\"PH_VU\", \"FLUX_VU\", \"SS_VU\", \"TOC_VU\"),\n",
    "    lag_list=(\"10min\", \"30min\", \"1h\"),\n",
    "    roll_windows=(\"30min\", \"1h\", \"3h\"),\n",
    "    antecedent_hours=(3, 6, 12, 24),\n",
    "    stability_windows=(\"3h\", \"6h\"),\n",
    "    wet_thr_mm=0.1,\n",
    "    spike_z=2.0,\n",
    "    spike_window=\"24h\",\n",
    "    add_api=False,\n",
    "    api_k=0.01,\n",
    "    api_hours=24,\n",
    "    eps=1e-6,\n",
    "):\n",
    "    \n",
    "    # 1. 기본 컬럼 구성\n",
    "    base_cols = []\n",
    "    for sid in station_ids:\n",
    "        base_cols.extend([f\"{wc}_{sid}\" for wc in weather_cols])\n",
    "        base_cols.extend([f\"{rc}_{sid}\" for rc in rain_cols])\n",
    "    base_cols.extend(process_cols)\n",
    "    \n",
    "    # 2. 리샘플링\n",
    "    if do_resample:\n",
    "        sum_cols = tuple(f\"{rc}_{sid}\" for sid in station_ids for rc in rain_cols) + (\"FLUX_VU\",)\n",
    "        mean_cols = (\n",
    "            tuple(f\"{wc}_{sid}\" for sid in station_ids for wc in weather_cols) + \n",
    "            (\"PH_VU\", \"SS_VU\", \"TOC_VU\")\n",
    "        )\n",
    "        df = resample_5min(df, time_col=time_col, rule=rule, sum_cols=sum_cols, mean_cols=mean_cols)\n",
    "        time_col = None\n",
    "    \n",
    "    # 3. 인덱스 설정\n",
    "    x = df.copy()\n",
    "    if time_col is not None:\n",
    "        x[time_col] = pd.to_datetime(x[time_col])\n",
    "        x = x.set_index(time_col)\n",
    "    if not isinstance(x.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"df must have a DatetimeIndex or provide time_col.\")\n",
    "    x = x.sort_index()\n",
    "    \n",
    "    # 4. 컬럼 검증\n",
    "    missing = [c for c in base_cols if c not in x.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns: {missing}\")\n",
    "    \n",
    "    X = x[base_cols].copy()\n",
    "    \n",
    "    # 5. 강수 특성 생성\n",
    "    X = _add_rain_features(X, station_ids, rain_cols, rule, antecedent_hours, wet_thr_mm, eps, add_api, api_k, api_hours)\n",
    "    \n",
    "    # 6. 기상 특성 생성\n",
    "    X = _add_weather_features(X, station_ids, weather_cols, rule, stability_windows, eps)\n",
    "    \n",
    "    # 7. 시계열 특성 (lag, rolling, delta)\n",
    "    X = _add_lag_roll_delta_features(X, process_cols, station_ids, rain_cols, weather_cols, rule, lag_list, roll_windows, eps)\n",
    "    \n",
    "    # 8. 공정 특성 생성\n",
    "    X = _add_process_features(X, process_cols, rule, spike_z, spike_window, eps)\n",
    "    \n",
    "    # 9. 강수-공정 상호작용\n",
    "    X = _add_rain_process_interactions(X, station_ids, eps)\n",
    "    \n",
    "    # 10. 시간 특성\n",
    "    X = _add_time_features(X)\n",
    "    \n",
    "    # 11. 정리\n",
    "    X = X.replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6cb0b346",
   "metadata": {},
   "outputs": [],
   "source": [
    "tms = pd.read_csv(\"../../data/processed/TMS_cleaned.csv\")\n",
    "aws = pd.read_csv(\"../../data/processed/AWS_cleaned.csv\")\n",
    "\n",
    "tms['SYS_TIME'] = pd.to_datetime(tms['SYS_TIME'])\n",
    "aws['SYS_TIME'] = pd.to_datetime(aws['SYS_TIME'])\n",
    "\n",
    "tms = tms.sort_values('SYS_TIME')\n",
    "aws = aws.sort_values('SYS_TIME')\n",
    "\n",
    "df = pd.merge_asof(tms, aws, on='SYS_TIME', direction='backward', tolerance=pd.Timedelta('1min'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5b491a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = make_modelB_features(df, time_col=\"SYS_TIME\", do_resample=True, rule=\"5min\")\n",
    "\n",
    "y_tn = resample_5min(df, time_col=\"SYS_TIME\", extra_mean_cols=(\"TN_VU\",\"TP_VU\"))[\"TN_VU\"].shift(-1)\n",
    "y_tp  = resample_5min(df, time_col=\"SYS_TIME\", extra_mean_cols=(\"TN_VU\",\"TP_VU\"))[\"TP_VU\"].shift(-1)\n",
    "\n",
    "data = X.join(pd.DataFrame({\"y_tn\": y_tn, \"y_tp\": y_tp})).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5f805138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA_368</th>\n",
       "      <th>HM_368</th>\n",
       "      <th>TD_368</th>\n",
       "      <th>RN_15m_368</th>\n",
       "      <th>RN_60m_368</th>\n",
       "      <th>RN_12H_368</th>\n",
       "      <th>RN_DAY_368</th>\n",
       "      <th>TA_541</th>\n",
       "      <th>HM_541</th>\n",
       "      <th>TD_541</th>\n",
       "      <th>...</th>\n",
       "      <th>RN_60m_x_RN15lag10_569</th>\n",
       "      <th>hour</th>\n",
       "      <th>dow</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>doy_sin</th>\n",
       "      <th>doy_cos</th>\n",
       "      <th>y_tn</th>\n",
       "      <th>y_tp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SYS_TIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-08-27 03:05:00</th>\n",
       "      <td>26.10</td>\n",
       "      <td>80.12</td>\n",
       "      <td>22.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.06</td>\n",
       "      <td>84.08</td>\n",
       "      <td>23.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.834370</td>\n",
       "      <td>-0.551205</td>\n",
       "      <td>6.468</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-27 03:10:00</th>\n",
       "      <td>26.08</td>\n",
       "      <td>79.84</td>\n",
       "      <td>22.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.96</td>\n",
       "      <td>84.14</td>\n",
       "      <td>23.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.834370</td>\n",
       "      <td>-0.551205</td>\n",
       "      <td>6.468</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-27 03:15:00</th>\n",
       "      <td>26.00</td>\n",
       "      <td>79.62</td>\n",
       "      <td>22.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.90</td>\n",
       "      <td>84.52</td>\n",
       "      <td>23.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.834370</td>\n",
       "      <td>-0.551205</td>\n",
       "      <td>6.468</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-27 03:20:00</th>\n",
       "      <td>25.98</td>\n",
       "      <td>79.38</td>\n",
       "      <td>22.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.78</td>\n",
       "      <td>85.10</td>\n",
       "      <td>23.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.834370</td>\n",
       "      <td>-0.551205</td>\n",
       "      <td>6.468</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-27 03:25:00</th>\n",
       "      <td>25.90</td>\n",
       "      <td>79.14</td>\n",
       "      <td>22.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.76</td>\n",
       "      <td>85.02</td>\n",
       "      <td>23.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.834370</td>\n",
       "      <td>-0.551205</td>\n",
       "      <td>6.468</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-29 04:55:00</th>\n",
       "      <td>17.48</td>\n",
       "      <td>81.50</td>\n",
       "      <td>14.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.24</td>\n",
       "      <td>95.42</td>\n",
       "      <td>15.52</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.999445</td>\n",
       "      <td>-0.033324</td>\n",
       "      <td>7.645</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-29 05:00:00</th>\n",
       "      <td>17.40</td>\n",
       "      <td>82.10</td>\n",
       "      <td>14.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.26</td>\n",
       "      <td>95.74</td>\n",
       "      <td>15.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-0.999445</td>\n",
       "      <td>-0.033324</td>\n",
       "      <td>7.645</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-29 05:05:00</th>\n",
       "      <td>17.40</td>\n",
       "      <td>82.70</td>\n",
       "      <td>14.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.20</td>\n",
       "      <td>95.76</td>\n",
       "      <td>15.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-0.999445</td>\n",
       "      <td>-0.033324</td>\n",
       "      <td>7.645</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-29 05:10:00</th>\n",
       "      <td>17.40</td>\n",
       "      <td>82.94</td>\n",
       "      <td>14.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.18</td>\n",
       "      <td>95.88</td>\n",
       "      <td>15.48</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-0.999445</td>\n",
       "      <td>-0.033324</td>\n",
       "      <td>7.645</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-29 05:15:00</th>\n",
       "      <td>17.44</td>\n",
       "      <td>82.96</td>\n",
       "      <td>14.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.10</td>\n",
       "      <td>95.74</td>\n",
       "      <td>15.40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-0.999445</td>\n",
       "      <td>-0.033324</td>\n",
       "      <td>7.645</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114651 rows × 334 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     TA_368  HM_368  TD_368  RN_15m_368  RN_60m_368  \\\n",
       "SYS_TIME                                                              \n",
       "2024-08-27 03:05:00   26.10   80.12   22.40         0.0         0.0   \n",
       "2024-08-27 03:10:00   26.08   79.84   22.32         0.0         0.0   \n",
       "2024-08-27 03:15:00   26.00   79.62   22.20         0.0         0.0   \n",
       "2024-08-27 03:20:00   25.98   79.38   22.14         0.0         0.0   \n",
       "2024-08-27 03:25:00   25.90   79.14   22.00         0.0         0.0   \n",
       "...                     ...     ...     ...         ...         ...   \n",
       "2025-09-29 04:55:00   17.48   81.50   14.28         0.0         0.0   \n",
       "2025-09-29 05:00:00   17.40   82.10   14.32         0.0         0.0   \n",
       "2025-09-29 05:05:00   17.40   82.70   14.40         0.0         0.0   \n",
       "2025-09-29 05:10:00   17.40   82.94   14.48         0.0         0.0   \n",
       "2025-09-29 05:15:00   17.44   82.96   14.54         0.0         0.0   \n",
       "\n",
       "                     RN_12H_368  RN_DAY_368  TA_541  HM_541  TD_541  ...  \\\n",
       "SYS_TIME                                                             ...   \n",
       "2024-08-27 03:05:00         2.5         0.0   26.06   84.08   23.16  ...   \n",
       "2024-08-27 03:10:00         2.5         0.0   25.96   84.14   23.06  ...   \n",
       "2024-08-27 03:15:00         2.5         0.0   25.90   84.52   23.10  ...   \n",
       "2024-08-27 03:20:00         2.5         0.0   25.78   85.10   23.10  ...   \n",
       "2024-08-27 03:25:00         2.5         0.0   25.76   85.02   23.06  ...   \n",
       "...                         ...         ...     ...     ...     ...  ...   \n",
       "2025-09-29 04:55:00         0.0         0.0   16.24   95.42   15.52  ...   \n",
       "2025-09-29 05:00:00         0.0         0.0   16.26   95.74   15.56  ...   \n",
       "2025-09-29 05:05:00         0.0         0.0   16.20   95.76   15.50  ...   \n",
       "2025-09-29 05:10:00         0.0         0.0   16.18   95.88   15.48  ...   \n",
       "2025-09-29 05:15:00         0.0         0.0   16.10   95.74   15.40  ...   \n",
       "\n",
       "                     RN_60m_x_RN15lag10_569  hour  dow  is_weekend  hour_sin  \\\n",
       "SYS_TIME                                                                       \n",
       "2024-08-27 03:05:00                     0.0     3    1           0  0.707107   \n",
       "2024-08-27 03:10:00                     0.0     3    1           0  0.707107   \n",
       "2024-08-27 03:15:00                     0.0     3    1           0  0.707107   \n",
       "2024-08-27 03:20:00                     0.0     3    1           0  0.707107   \n",
       "2024-08-27 03:25:00                     0.0     3    1           0  0.707107   \n",
       "...                                     ...   ...  ...         ...       ...   \n",
       "2025-09-29 04:55:00                     0.0     4    0           0  0.866025   \n",
       "2025-09-29 05:00:00                     0.0     5    0           0  0.965926   \n",
       "2025-09-29 05:05:00                     0.0     5    0           0  0.965926   \n",
       "2025-09-29 05:10:00                     0.0     5    0           0  0.965926   \n",
       "2025-09-29 05:15:00                     0.0     5    0           0  0.965926   \n",
       "\n",
       "                     hour_cos   doy_sin   doy_cos   y_tn   y_tp  \n",
       "SYS_TIME                                                         \n",
       "2024-08-27 03:05:00  0.707107 -0.834370 -0.551205  6.468  0.077  \n",
       "2024-08-27 03:10:00  0.707107 -0.834370 -0.551205  6.468  0.077  \n",
       "2024-08-27 03:15:00  0.707107 -0.834370 -0.551205  6.468  0.077  \n",
       "2024-08-27 03:20:00  0.707107 -0.834370 -0.551205  6.468  0.077  \n",
       "2024-08-27 03:25:00  0.707107 -0.834370 -0.551205  6.468  0.077  \n",
       "...                       ...       ...       ...    ...    ...  \n",
       "2025-09-29 04:55:00  0.500000 -0.999445 -0.033324  7.645  0.024  \n",
       "2025-09-29 05:00:00  0.258819 -0.999445 -0.033324  7.645  0.024  \n",
       "2025-09-29 05:05:00  0.258819 -0.999445 -0.033324  7.645  0.024  \n",
       "2025-09-29 05:10:00  0.258819 -0.999445 -0.033324  7.645  0.024  \n",
       "2025-09-29 05:15:00  0.258819 -0.999445 -0.033324  7.645  0.024  \n",
       "\n",
       "[114651 rows x 334 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4efa3921",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"../../data/processed/modelB_dataset.csv\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
